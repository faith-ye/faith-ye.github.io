<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>数据预处理</title>
      <link href="/2022/04/25/shu-ju-yu-chu-li/"/>
      <url>/2022/04/25/shu-ju-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<p>这节我们将简要介绍使用pandas预处理原始数据，并将原始数据转换为张量格式的步骤。</p><h2 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h2><p>首先，我们简单创建一个人工数据集，并存储在csv文件./data/house_tiny.csv中。下面我们将数据集按行写入csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import osos.makedirs('./data', exist_ok=True)data_file = os.path.join('./data', 'house_tiny.csv')with open(data_file, 'w') as f:    f.write('NumRooms,Alley,Price\n') # 列名    f.write('NA,Pave,127500\n') # 每⾏表⽰⼀个数据样本    f.write('2,NA,106000\n')    f.write('4,NA,178100\n')    f.write('NA,NA,140000\n')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>有数据集后，我们可以导入pandas包并调用read_csv函数加载原始数据集。该数据集有四行三列，其中每⾏描述了房间数量（“NumRooms”）、巷⼦类型（“Alley”）和房屋价格（“Price”）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import pandas as pddata = pd.read_csv(data_file)print(data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price0       NaN  Pave  1275001       2.0   NaN  1060002       4.0   NaN  1781003       NaN   NaN  140000</code></pre><h2 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h2><p>有输出结果可以看出，表格中存在缺失的数据。为了避免这些数据对之后的模型搭建存在影响，需对其进行处理，常见的方法有插值法和删除法，插值法是用一个替代值替换缺失值，而删除法则是直接忽略缺失值。</p><p><strong>插值法</strong></p><p>我们一般用同一列的均值替换“NaN”项，可以用fillna()函数实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data1 = data.fillna(data.mean())print(data1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price0       3.0  Pave  1275001       2.0   NaN  1060002       4.0   NaN  1781003       3.0   NaN  140000</code></pre><p><strong>删除法</strong></p><p>一般是删除缺失值所对应的行，用dropna()函数实现</p><ul><li>axis默认值为0，当设置为1时，是删除缺失值所对应的列</li><li>subset是参考某几列（或几行）作为删除一句</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">data2 = data.dropna(axis=0, subset=['NumRooms'])print(data2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price1       2.0   NaN  1060002       4.0   NaN  178100</code></pre><p>除此之外，有时还需要删除重复的数据，可以用drop_duplicates()函数实现。由于一般我们都是用插值法处理缺失值，所以这里我们考虑该方法。</p><p>通过位置索引iloc，我们将data分为inputs和outputs</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]inputs = inputs.fillna(inputs.mean())print(inputs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley0       3.0  Pave1       2.0   NaN2       4.0   NaN3       3.0   NaN</code></pre><p>对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。由于“Alley”列只接受两种类型的类别值“Pave”和“NaN”，pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。类型为“Pave”的⾏会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。类型为“NaN”的⾏会将“Alley_Pave”的值设置为0，“Alley_nan”的值设置为1。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs = pd.get_dummies(inputs, dummy_na=True)print(inputs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms  Alley_Pave  Alley_nan0       3.0           1          01       2.0           0          12       4.0           0          13       3.0           0          1</code></pre><h2 id="转换为张量格式"><a href="#转换为张量格式" class="headerlink" title="转换为张量格式"></a>转换为张量格式</h2><p>现在inputs和outputs中所有数据都是数值类型，我们可以把它们转换为张量格式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import torchX, y = torch.tensor(inputs.values), torch.tensor(outputs.values)X, y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[3., 1., 0.],         [2., 0., 1.],         [4., 0., 1.],         [3., 0., 1.]], dtype=torch.float64), tensor([127500, 106000, 178100, 140000]))</code></pre><p>这节我们主要学习了csv文件数据的预处理，其实以其他格式存储的数据也是通过类似的方式进行处理，最终都得转变成tensor格式。</p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW3-CNN</title>
      <link href="/2022/04/20/hw3-cnn/"/>
      <url>/2022/04/20/hw3-cnn/</url>
      
        <content type="html"><![CDATA[<h2 id="作业介绍"><a href="#作业介绍" class="headerlink" title="作业介绍"></a>作业介绍</h2><p>作业的目标是使用卷积神经网络（我用的是VGG）解决图像分类问题，并用数据扩充的技术提高模型的性能。</p><p>使用的数据集是一个关于食物分类的dataset:food-11。如名字所示，食物的种类有11种，分别为面包、乳制品、甜点、鸡蛋、 油炸食品、肉类、面条、米饭、海鲜、汤和水果蔬菜。其中数据分为训练集（9866张）、验证集（3430张）和测试集（3347张），训练集和验证集中照片的格式为”类别_编号.jpg“，如3_100.jpg为类别3（鸡蛋）的照片，测试集中照片的格式为”编号.jpg“，不包含类别，测试集食物的类别需要用模型预测并保存到.csv文件中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入需要的包</span><span class="token keyword">import</span> os<span class="token keyword">import</span> glob<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">import</span> time<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义一些函数"><a href="#定义一些函数" class="headerlink" title="定义一些函数"></a>定义一些函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your model (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_accuracy</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot accuracy of your model (train &amp; dev acc) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training epochs'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> root<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 只画前16张图片的预测结果</span>    text <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">'面包'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token string">'乳制品'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token string">'甜点'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token string">'鸡蛋'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token string">'油炸食品'</span><span class="token punctuation">,</span>            <span class="token number">5</span><span class="token punctuation">:</span><span class="token string">'肉类'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span><span class="token string">'面条'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span><span class="token string">'米饭'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span><span class="token string">'海鲜'</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span><span class="token string">'汤'</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token string">'水果蔬菜'</span><span class="token punctuation">}</span>        fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 设置子图数量和画布大小   </span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>num<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 设置显示中文字体（黑体）</span>    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.family'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 4行4列的第i+1个子图 </span>        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> plt<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>fnames<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        label <span class="token operator">=</span> preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment"># 在图片(70,120)的位置标出食物类别（是否戴眼镜），字体大小为 24，字体颜色为红色</span>        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token number">70</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> s<span class="token operator">=</span>text<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'fontsize'</span><span class="token punctuation">:</span><span class="token number">48</span> <span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FoodDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 制作Dataset '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fnames<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>fnames <span class="token operator">=</span> fnames        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Finished reading the </span><span class="token interpolation"><span class="token punctuation">{</span>mode<span class="token punctuation">}</span></span><span class="token string"> set(</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>fnames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> samples found)'</span></span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fnames<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> self<span class="token punctuation">.</span>fnames<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        fname <span class="token operator">=</span> fname<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\\'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">)</span>        <span class="token comment"># 加载图片</span>        img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>fname<span class="token punctuation">)</span>        <span class="token comment"># transform</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> img        <span class="token keyword">else</span><span class="token punctuation">:</span>            label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>fname<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>label<span class="token punctuation">)</span>            label <span class="token operator">=</span> label<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> img<span class="token punctuation">,</span> label<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pre_dataloader</span><span class="token punctuation">(</span>root<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 制作DataLoader '''</span>    fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token comment"># 获取当前路径下的所有文件对应的路径</span>    dataset <span class="token operator">=</span> FoodDataset<span class="token punctuation">(</span>fnames<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">)</span>       <span class="token comment"># 生成一个数据集，并输入到指定的dataloader</span>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span>         shuffle <span class="token operator">=</span> <span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>这部分主要自己实现一个VGG网络结构，在这之前我们简单的讲解一下VGG的结构。</p><p>VGG网络主要由两个部分组成：第一部分主要是卷积层和池化层组成，第二部分由全连接层组成。它的特点如下：</p><ul><li>每个卷积层中使用3x3filters，并将它们组合成卷积序列</li><li>多个3x3卷积序列可以模拟更大的接受场的效果</li><li>每次的图像像素缩小一倍，卷积核的数量增加一倍</li></ul><p>VGG有很多个版本，也算是比较稳定和经典的model。它的特点也是连续conv多计算量巨大，这里我们以VGG16为例<br><img src="https://handbook.pytorch.wiki/chapter2/vgg16.png"><br>其中，VGG清一色用小卷积核的优势有：</p><ul><li>3层conv3x3后等同于1层conv7x7的结果； 2层conv3x3后等同于2层conv5x5的结果</li><li>卷积层的参数减少。相比5x5、7x7和11x11的大卷积核，3x3明显地减少了参数量</li><li>通过卷积和池化层后，图像的分辨率降低为原来的一半，但是图像的特征增加一倍，这是一个十分规整的操作，为后面的网络提供了一个标准</li></ul><p>下面我们根据VGG16的特点来实现这个模型：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnVGG16 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">25088</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于我电脑跑不动这个模型，所以在它的基础上进行稍微的修改，本文用的模型如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span>        <span class="token comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span>        <span class="token comment"># input 维度 [3, 128, 128]</span>        self<span class="token punctuation">.</span>cnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [64, 128, 128]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [64, 64, 64]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [128, 64, 64]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [128, 32, 32]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [256, 32, 32]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [256, 16, 16]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 16, 16]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 4, 4]</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>cnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 训练模型 '''</span>    n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>   <span class="token comment"># 最大迭代次数</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer使用Adam</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 损失函数使用CrossEntropyLoss</span>        min_loss <span class="token operator">=</span> <span class="token number">1000</span>             <span class="token comment"># 用于记录验证时最小的loss</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录训练损失</span>    acc_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录预测准确度</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 调整为train模型（开放Dropout等等）</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">)</span><span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 将模型参数的 gradient 至0</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 利用后向传播算出每个参数的gradient</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 更新模型参数</span>                        train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>                        loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                train_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>                <span class="token comment"># 每次迭代后，在验证集中验证你的模型</span>        dev_acc<span class="token punctuation">,</span> dev_loss <span class="token operator">=</span> dev<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_acc<span class="token punctuation">)</span>        loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_loss<span class="token punctuation">)</span>                <span class="token comment"># 将结果打印出来</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%02d/%02d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f'</span> <span class="token operator">%</span> \              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n_epochs<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> dev_acc<span class="token punctuation">,</span> dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># 当模型性能提升时保存模型</span>        <span class="token keyword">if</span> dev_loss <span class="token operator">&lt;</span> min_loss<span class="token punctuation">:</span>            min_loss <span class="token operator">=</span> dev_loss            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">, loss = </span><span class="token interpolation"><span class="token punctuation">{</span>min_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 保存模型到指定路径</span>                <span class="token keyword">return</span> min_loss<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    dev_loss<span class="token punctuation">,</span> dev_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            dev_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            dev_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>    dev_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    dev_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        <span class="token keyword">return</span> dev_acc<span class="token punctuation">,</span> dev_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>                                    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>         <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                              pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> y <span class="token keyword">in</span> pred<span class="token punctuation">:</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">return</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>config中包含模型训练的超参数（可以进行调节）和保存模型的路径</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data_dir <span class="token operator">=</span> <span class="token string">'./food-11'</span><span class="token comment"># 可以进行调节来提升模型性能</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span>                <span class="token comment"># 最大迭代次数</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">,</span>               <span class="token comment"># dataloader的最小批量</span>    <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment"># 模型保存路径</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="加载数据和模型"><a href="#加载数据和模型" class="headerlink" title="加载数据和模型"></a>加载数据和模型</h2><p>这部分需要注意的是我们需要为不同的数据制定不同的transform，因为我们只能对训练数据做数据扩充</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 训练时做数据扩充</span>train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># 随机将图片水平翻转</span>    transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token comment"># 随机旋转图片</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 验证测试时不用做数据扩充</span>test_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tr_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'training'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> train_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dv_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'validation'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> test_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tt_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'testing'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> test_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Finished reading the train set(9866 samples found)Finished reading the dev set(3430 samples found)Finished reading the test set(3347 samples found)</code></pre><p>展示16张训练集的图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_21_0.png" class=""><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">min_loss<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[01/30] 86.74 sec(s) Train Acc: 0.218123 Loss: 0.036563 | Val Acc: 0.262974 loss: 0.032123Saving model (epoch = 01, loss = 0.0321)[02/30] 83.66 sec(s) Train Acc: 0.311372 Loss: 0.030771 | Val Acc: 0.322449 loss: 0.030530Saving model (epoch = 02, loss = 0.0305)[03/30] 83.76 sec(s) Train Acc: 0.369349 Loss: 0.028417 | Val Acc: 0.406122 loss: 0.026898Saving model (epoch = 03, loss = 0.0269)[04/30] 86.88 sec(s) Train Acc: 0.414454 Loss: 0.026027 | Val Acc: 0.411079 loss: 0.025972Saving model (epoch = 04, loss = 0.0260)[05/30] 85.10 sec(s) Train Acc: 0.467971 Loss: 0.023721 | Val Acc: 0.383382 loss: 0.030133[06/30] 84.83 sec(s) Train Acc: 0.507399 Loss: 0.022244 | Val Acc: 0.367055 loss: 0.033233[07/30] 87.24 sec(s) Train Acc: 0.532840 Loss: 0.020973 | Val Acc: 0.514286 loss: 0.023898Saving model (epoch = 07, loss = 0.0239)[08/30] 86.20 sec(s) Train Acc: 0.577944 Loss: 0.019479 | Val Acc: 0.502332 loss: 0.023984[09/30] 88.35 sec(s) Train Acc: 0.591222 Loss: 0.018706 | Val Acc: 0.563848 loss: 0.020785Saving model (epoch = 09, loss = 0.0208)[10/30] 85.91 sec(s) Train Acc: 0.621528 Loss: 0.017443 | Val Acc: 0.557143 loss: 0.021090[11/30] 86.38 sec(s) Train Acc: 0.616562 Loss: 0.017344 | Val Acc: 0.560641 loss: 0.020721Saving model (epoch = 11, loss = 0.0207)[12/30] 87.27 sec(s) Train Acc: 0.648490 Loss: 0.016085 | Val Acc: 0.565015 loss: 0.020585Saving model (epoch = 12, loss = 0.0206)[13/30] 86.36 sec(s) Train Acc: 0.662376 Loss: 0.015385 | Val Acc: 0.609621 loss: 0.018134Saving model (epoch = 13, loss = 0.0181)[14/30] 87.04 sec(s) Train Acc: 0.672816 Loss: 0.014737 | Val Acc: 0.576676 loss: 0.020833[15/30] 86.98 sec(s) Train Acc: 0.691871 Loss: 0.013995 | Val Acc: 0.547230 loss: 0.023204[16/30] 86.17 sec(s) Train Acc: 0.701297 Loss: 0.013776 | Val Acc: 0.516618 loss: 0.024357[17/30] 87.39 sec(s) Train Acc: 0.713866 Loss: 0.012795 | Val Acc: 0.627697 loss: 0.017918Saving model (epoch = 17, loss = 0.0179)[18/30] 87.07 sec(s) Train Acc: 0.733732 Loss: 0.012115 | Val Acc: 0.628280 loss: 0.018558[19/30] 87.39 sec(s) Train Acc: 0.735962 Loss: 0.011708 | Val Acc: 0.623907 loss: 0.019147[20/30] 86.86 sec(s) Train Acc: 0.761200 Loss: 0.010815 | Val Acc: 0.639650 loss: 0.019255[21/30] 87.09 sec(s) Train Acc: 0.779749 Loss: 0.009971 | Val Acc: 0.608455 loss: 0.021485[22/30] 87.64 sec(s) Train Acc: 0.772045 Loss: 0.010318 | Val Acc: 0.633528 loss: 0.019861[23/30] 86.32 sec(s) Train Acc: 0.777215 Loss: 0.009820 | Val Acc: 0.661808 loss: 0.018393[24/30] 87.13 sec(s) Train Acc: 0.810562 Loss: 0.008549 | Val Acc: 0.647230 loss: 0.019221[25/30] 86.26 sec(s) Train Acc: 0.799818 Loss: 0.009009 | Val Acc: 0.655394 loss: 0.019204[26/30] 84.89 sec(s) Train Acc: 0.839955 Loss: 0.007461 | Val Acc: 0.650437 loss: 0.018734[27/30] 88.26 sec(s) Train Acc: 0.839955 Loss: 0.007236 | Val Acc: 0.641399 loss: 0.020359[28/30] 90.81 sec(s) Train Acc: 0.846544 Loss: 0.007010 | Val Acc: 0.643149 loss: 0.020707[29/30] 85.49 sec(s) Train Acc: 0.851105 Loss: 0.006651 | Val Acc: 0.650146 loss: 0.022475[30/30] 86.92 sec(s) Train Acc: 0.871883 Loss: 0.005801 | Val Acc: 0.667055 loss: 0.021603</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_accuracy<span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'cnn model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_25_0.png" class=""><h2 id="模型测试-1"><a href="#模型测试-1" class="headerlink" title="模型测试"></a>模型测试</h2><p>加载最优模型预测测试集上的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 加载你最好的模型</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>preds <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>展示部分预测结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_pred<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'testing'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_29_0.png" class=""> <p>在测试集上的结果将会保存到pred.csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"predict.csv"</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Id,Category\n'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> y <span class="token keyword">in</span>  <span class="token builtin">enumerate</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{}\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Classifier </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW1-Regression</title>
      <link href="/2022/04/19/hw1-regression/"/>
      <url>/2022/04/19/hw1-regression/</url>
      
        <content type="html"><![CDATA[<ul><li>目标：用深度神经网络（DNN）解决一个回归问题，了解训练基础DNN的技巧</li><li>任务描述： 给定美国特定州过去三天有关COVID-19的调查，然后预测第3天新检测阳性病例的百分比</li></ul><h2 id="导入一些包"><a href="#导入一些包" class="headerlink" title="导入一些包"></a>导入一些包</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># PyTorch</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token comment"># For data preprocess</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> csv<span class="token keyword">import</span> os<span class="token comment"># For plotting</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltmyseed <span class="token operator">=</span> <span class="token number">42069</span>  <span class="token comment"># set a random seed for reproducibility</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义一些函数"><a href="#定义一些函数" class="headerlink" title="定义一些函数"></a>定义一些函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your DNN (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> lim<span class="token operator">=</span><span class="token number">35.</span><span class="token punctuation">,</span> preds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot prediction of your DNN '''</span>    <span class="token keyword">if</span> preds <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        preds<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                targets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'ground truth value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'predicted value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Ground Truth v.s. Prediction'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>有三种数据集：训练集、验证集和测试集</p><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>这部分需要实现的功能如下：</p><ul><li>读取.csv文件，将covid.train.csv划分为训练集和验证集</li><li>提取数据特征，并进行归一化处理</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">COVID19Dataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 用于加载并对COVID19数据集进行预处理'''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode                <span class="token comment"># 读取数据为numpy arrays格式</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>            data <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>fp<span class="token punctuation">)</span><span class="token punctuation">)</span>            data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span>   <span class="token comment"># 不读取行列的注释</span>                <span class="token keyword">if</span> <span class="token keyword">not</span> target_only<span class="token punctuation">:</span>                                      feats <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">93</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                 <span class="token comment"># 考虑所有影响因素</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>                                      <span class="token comment"># 作业实现部分</span>            <span class="token comment"># TODO: Using 40 states &amp; 2 tested_positive features (indices = 57 &amp; 75)</span>            feats <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            feats<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">57</span><span class="token punctuation">)</span>            feats<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">75</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>            <span class="token comment"># 测试数据</span>            <span class="token comment"># data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 训练数据，用于划分训练集和验证集</span>            <span class="token comment"># data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))</span>            target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>                        <span class="token comment"># 将训练数据划分为训练集和测试集(9 : 1)</span>            <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'dev'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>                        <span class="token comment"># 将数据转成tensors格式</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>target<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 归一化处理（你可以尝试将这部分去除，看结果会变成什么样子）</span>        self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> \            <span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span> \            <span class="token operator">/</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>std<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'</span>              <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>mode<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 返回数据的长度</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 每次返回一个样本</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># 训练</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>target<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 测试（没有目标值）</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>以小批量的格式从定义好的Dataset中加载数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">prep_dataloader</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> target_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 生成一个数据集，将其输入到指定的dataloader中 '''</span>    dataset <span class="token operator">=</span> COVID19Dataset<span class="token punctuation">(</span>path<span class="token punctuation">,</span> mode<span class="token operator">=</span>mode<span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>      dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span>        shuffle<span class="token operator">=</span><span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><p>模型简单由具有ReLU激活函数的全连接层组成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SimpleNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 实现一个简单由几个全连接层组成的深度神经网络 '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 你可以对这部分的网络结构进行修改</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 二维变成一维，数字对应去除的维度序号（从0开始）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 训练模型 '''</span>        n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>     <span class="token comment"># 最大迭代次数</span>            optimizer <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>        model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'optim_hparas'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 优化算法optimizer    </span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>            <span class="token comment"># 损失函数criterion</span>        min_mse <span class="token operator">=</span> <span class="token number">1000</span>             <span class="token comment"># 用于记录验证时最小的loss</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录训练损失</span>    early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>                       <span class="token comment"># 如果迭代过程中，超过设定迭代次数，模型的最小loss还没更新就停止迭代</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>                      <span class="token comment"># 将模型设置为训练模式</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> tr_set<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token comment"># 将梯度初始为0</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>               <span class="token comment"># 前向传播（计算模型输出）</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>     <span class="token comment"># 计算loss</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment"># 后向传播（计算梯度）</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token comment"># 更新模型参数</span>            loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># 每次迭代后，在验证集中验证你的模型</span>        dev_mse <span class="token operator">=</span> dev<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        <span class="token keyword">if</span> dev_mse <span class="token operator">&lt;</span> min_mse<span class="token punctuation">:</span>            <span class="token comment"># 当模型性能提升时保存模型</span>            min_mse <span class="token operator">=</span> dev_mse            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">, loss = </span><span class="token interpolation"><span class="token punctuation">{</span>min_mse<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 保存模型到指定的路径</span>            early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>               <span class="token comment"># 每次模型性能改进，将该值变为0</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>            early_stop_cnt <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment"># 每次迭代后，模型性能未提升则加1</span>                loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_mse<span class="token punctuation">)</span>        <span class="token keyword">if</span> early_stop_cnt <span class="token operator">&gt;</span> config<span class="token punctuation">[</span><span class="token string">'early_stop'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># 如果你的模型在指定迭代次数后，模型性能仍为改进，则停止训练</span>            <span class="token keyword">break</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Finished training after </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string"> epochs'</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> min_mse<span class="token punctuation">,</span> loss_record<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token comment"># 将模型设置为评估模式</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>   <span class="token comment"># 损失函数criterion</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                   <span class="token comment"># 不允许梯度计算</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment"># 前向传播</span>            mse_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 计算loss</span>        total_loss <span class="token operator">+=</span> mse_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># 总loss</span>    total_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>              <span class="token comment"># 平均loss</span>    <span class="token keyword">return</span> total_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>                                    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>         <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                              pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                                 preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 连接所有预测并转换为numpy数组</span>    <span class="token keyword">return</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>config中包含模型训练的超参数（可以进行调节）和保存模型的路径</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>                 os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#</span>target_only <span class="token operator">=</span> <span class="token boolean">False</span>                   <span class="token comment"># 可以进行调节来提升模型性能</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">3000</span><span class="token punctuation">,</span>                <span class="token comment"># 最大迭代次数</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">270</span><span class="token punctuation">,</span>               <span class="token comment"># dataloader的最小批量</span>    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token string">'SGD'</span><span class="token punctuation">,</span>              <span class="token comment"># 参数优化算法</span>    <span class="token string">'optim_hparas'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                <span class="token comment"># optimizer的超参数</span>        <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>                 <span class="token comment"># SGD的学习率</span>        <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0.9</span>              <span class="token comment"># SGD的momentum</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token string">'early_stop'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>               <span class="token comment"># 自模型上次改进以后的最多迭代次数</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment"># 模型保存路径</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="加载数据和模型"><a href="#加载数据和模型" class="headerlink" title="加载数据和模型"></a>加载数据和模型</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">tr_path <span class="token operator">=</span> <span class="token string">'./data/covid.train.csv'</span>  <span class="token comment"># 训练数据路径</span>tt_path <span class="token operator">=</span> <span class="token string">'./data/covid.test.csv'</span>   <span class="token comment"># 测试数据路径</span>tr_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>dv_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>tt_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tt_path<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>          <span class="token comment"># 构建模型</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_loss<span class="token punctuation">,</span> model_loss_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>Saving model (epoch =    1, loss = 196.5020)Saving model (epoch =    2, loss = 64.4406)Saving model (epoch =    3, loss = 16.0075)Saving model (epoch =    4, loss = 7.1638)Saving model (epoch =    5, loss = 6.9936)Saving model (epoch =    6, loss = 4.3199)Saving model (epoch =    7, loss = 2.8746)Saving model (epoch =    8, loss = 2.3495)Saving model (epoch =    9, loss = 2.0699)Saving model (epoch =   10, loss = 1.8842)Saving model (epoch =   11, loss = 1.7374)Saving model (epoch =   12, loss = 1.6552)Saving model (epoch =   13, loss = 1.5494)Saving model (epoch =   14, loss = 1.4657)Saving model (epoch =   16, loss = 1.3691)Saving model (epoch =   18, loss = 1.2820)Saving model (epoch =   19, loss = 1.2714)Saving model (epoch =   20, loss = 1.2370)Saving model (epoch =   21, loss = 1.2115)Saving model (epoch =   22, loss = 1.1969)Saving model (epoch =   24, loss = 1.1566)Saving model (epoch =   25, loss = 1.1130)Saving model (epoch =   26, loss = 1.0947)Saving model (epoch =   28, loss = 1.0822)Saving model (epoch =   31, loss = 1.0681)Saving model (epoch =   32, loss = 1.0414)Saving model (epoch =   33, loss = 1.0325)Saving model (epoch =   34, loss = 1.0219)Saving model (epoch =   36, loss = 1.0006)Saving model (epoch =   42, loss = 0.9903)Saving model (epoch =   43, loss = 0.9615)Saving model (epoch =   46, loss = 0.9473)Saving model (epoch =   48, loss = 0.9305)Saving model (epoch =   52, loss = 0.9179)Saving model (epoch =   58, loss = 0.9060)Saving model (epoch =   61, loss = 0.9049)Saving model (epoch =   62, loss = 0.8991)Saving model (epoch =   63, loss = 0.8967)Saving model (epoch =   67, loss = 0.8928)Saving model (epoch =   68, loss = 0.8797)Saving model (epoch =   70, loss = 0.8776)Saving model (epoch =   73, loss = 0.8588)Saving model (epoch =   81, loss = 0.8583)Saving model (epoch =   84, loss = 0.8497)Saving model (epoch =   86, loss = 0.8392)Saving model (epoch =   96, loss = 0.8273)Saving model (epoch =   99, loss = 0.8218)Saving model (epoch =  105, loss = 0.8191)Saving model (epoch =  119, loss = 0.8141)Saving model (epoch =  138, loss = 0.8100)Saving model (epoch =  139, loss = 0.7944)Saving model (epoch =  160, loss = 0.7902)Saving model (epoch =  190, loss = 0.7779)Saving model (epoch =  218, loss = 0.7770)Saving model (epoch =  233, loss = 0.7751)Saving model (epoch =  241, loss = 0.7748)Saving model (epoch =  270, loss = 0.7630)Saving model (epoch =  326, loss = 0.7592)Saving model (epoch =  409, loss = 0.7497)Saving model (epoch =  541, loss = 0.7488)Saving model (epoch =  546, loss = 0.7450)Saving model (epoch =  642, loss = 0.7401)Saving model (epoch =  670, loss = 0.7389)Saving model (epoch =  800, loss = 0.7318)Finished training after 1000 epochs</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_learning_curve<span class="token punctuation">(</span>model_loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'deep model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/19/hw1-regression/output_23_0.png" class=""><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 加载你最好的模型</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>plot_pred<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>                  <span class="token comment"># 展示在验证集上的预测结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/19/hw1-regression/output_24_0.png" class=""><h2 id="模型测试-1"><a href="#模型测试-1" class="headerlink" title="模型测试"></a>模型测试</h2><p>在测试集上的结果将会保存到pred.csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 保存预测的结果到指定的文件中 '''</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving results to </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">file</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>fp<span class="token punctuation">)</span>        writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'tested_positive'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> p <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>            writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> p<span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>  <span class="token comment"># 预测</span>save_pred<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token string">'pred.csv'</span><span class="token punctuation">)</span>         <span class="token comment"># 保存预测结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Saving results to pred.csv</code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Regression </tag>
            
            <tag> DNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERT</title>
      <link href="/2022/04/17/bert/"/>
      <url>/2022/04/17/bert/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>BERT的全称是Bidirectional Encoder Representations from Transformers（来自Transformers的双向编码器表示），BERT基于Transformer，Transformer在初始论文中是用于Seq2Seq任务中，其Encoder部分后续被迁移到各种场景，逐渐演化成一种通用的特征提取器。BERT 通过使用预训练的 Transformer编码器，能够基于其双向上下文表示任何词元。在下游任务的监督学习过程中，BERT将输入表示到一个添加的输出层中，根据任务的性质对模型架构进行最小的更改，例如预测每个词元与预测整个序列。同时，BERT对预训练Transformer编码器的所有参数进行微调，而额外的输出层将从头开始训练。</p><p>在BERT的原始论文BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding 中，BERT的描述分为三个部分：输入表示、预训练任务和下游任务。</p><h2 id="BERT的输入表示"><a href="#BERT的输入表示" class="headerlink" title="BERT的输入表示"></a>BERT的输入表示</h2><p>在自然语言处理中，有些任务（如情感分析）以单个文本为输入，而有些任务（如自然语言推断）以一对文本序列作为输入。当输入为单个文本时，BERT输入序列是特殊类别词元“&lt;cls&gt;”、⽂本序列的标记、以及特殊分隔词元“&lt;sep&gt;”的连结。当输入为文本对是，BERT输入序列是“&lt;cls&gt;”、第⼀个⽂本序列的标记、“&lt;sep&gt;”、第⼆个⽂本序列标记、以及“&lt;sep&gt;”的连结。</p><p>BERT选择Transformer编码器作为其双向架构。在Transformer编码器中，位置嵌入被加到输入序列的每个位置。然而，与原始Transformer编码器不同，BERT使用可学习的位置嵌入，其输入为词元嵌入（Token Embeddings）、片段嵌入（Segment Embeddings）和位置嵌入（Position Embeddings）的和。</p><img src="/2022/04/17/bert/image-20220417165237930.png" class=""><h2 id="预训练任务"><a href="#预训练任务" class="headerlink" title="预训练任务"></a>预训练任务</h2><p>前面我们给出了输入文本的每个词元和插入的特殊标记“&lt;cls&gt;”及“&lt;seq&gt;” 的BERT表示。接下来，我们将使⽤这些表⽰来计算预训练BERT的损失函数。预训练包括以下两个任务：掩蔽语言模型和下一句预测。</p><h3 id="掩蔽语言模型（Masked-Language-Modeling-Masked-LM）"><a href="#掩蔽语言模型（Masked-Language-Modeling-Masked-LM）" class="headerlink" title="掩蔽语言模型（Masked Language Modeling, Masked LM）"></a>掩蔽语言模型（Masked Language Modeling, Masked LM）</h3><p>根据直觉，我们有理由相信deep bidirectional model比left-to-right model（如单向LSTM）或者浅级连接的left-to-right model和right-to-left model（如双向LSTM）更加强大。为了双向编码上下文以表示每个词元，BERT随机掩蔽词元并使用来自上下文的词元以自监督（self-supervised）的方式预测掩蔽词元。此任务称为掩蔽语言模型。这个模型可以用下图表示，假设输入是机器学习。</p><img src="/2022/04/17/bert/image-20220417181929265.png" class=""><p>在这个预训练任务中，将随机选择15%的词元作为预测的掩蔽词元。要预测⼀个掩蔽词元而不使⽤标签作弊，<br>⼀个简单的⽅法是总是⽤⼀个特殊的“&lt;mask&gt;”替换输⼊序列中的词元。然而，⼈造特殊词元“&lt;mask&gt;”不<br>会出现在微调中。为了避免预训练和微调之间的这种不匹配，如果为预测而屏蔽词元（例如，在“my dog is hairy ”中选择掩蔽和预测“hairy”），则在输⼊中将其替换为：  </p><ul><li>80%概率为特殊的“&lt;mask&gt;“词元（例如，“my dog is hairy ”变为“my dog is &lt;mask&gt;”）</li><li>10%概率为随机词元（例如，“my dog is hairy ”变为“my dog is apple”）</li><li>10%概率为不变的标签词元（例如，“my dog is hairy ”变为“my dog is hairy”）</li></ul><p>注意在15%的词元中，有10%的概率替换为随机词元。这种偶然的噪声鼓励BERT在其双向上下文编码中不那么偏向于掩蔽词元，而这种影响在标签保持不变时更加深刻。</p><p>总的来说Masked LM的目标是预测出被掩蔽的单词，相当于做一个完形填空，做完形填空的任务有利于BERT学会理解文本的上下文信息。</p><h3 id="下⼀句预测（Next-Sentence-Prediction-NSP）"><a href="#下⼀句预测（Next-Sentence-Prediction-NSP）" class="headerlink" title="下⼀句预测（Next Sentence Prediction, NSP）"></a>下⼀句预测（Next Sentence Prediction, NSP）</h3><p>虽然掩蔽语言模型能够双向上下文来表示单词，但它不能显式地表示文本对之间的逻辑关系，在这一些自然语言处理任务中尤为重要（如QA问答系统和自然语言推断）。为了帮助理解两个文本序列之间的关系，BERT在预训练中考虑了一个二元分类任务——下一句预测。在为预训练生成句子对时，有⼀半的时间它们确实是标签为“Yes”的连续句⼦。但在另⼀半的时间⾥，第⼆个句⼦是从语料库中随机抽取的，标记为“No”。</p><img src="/2022/04/17/bert/image-20220417182324087.png" class=""><p>  这个模型可以用上图表示，输入是两个句子，也就是文本对的输入格式。BERT输出是将特殊词元“&lt;cls&gt;”  编码后的向量，由于Transformer编码器中的自主意力，特殊词元“&lt;cls&gt;”的BERT表⽰已经对输⼊的两个句⼦进⾏了编码。再将编码后的向量输入一个多层感知机来预测第二个句子是否是BERT输入序列中第一个句子的下一句。  </p><h3 id="用于预训练BERT的数据集"><a href="#用于预训练BERT的数据集" class="headerlink" title="用于预训练BERT的数据集"></a>用于预训练BERT的数据集</h3><p>为了预训练BERT模型，我们需要以理想的格式生成数据集，以便于上述两个预训练任务。在论文中，预训练的语料库有两个：BooksCorpus（8亿个单词）、English Wikipedia（25亿个单词）。对于English Wikipedia，只提取文本段落而忽略列表、表格和标题。</p><h2 id="BERT下游任务"><a href="#BERT下游任务" class="headerlink" title="BERT下游任务"></a>BERT下游任务</h2><p>基于预训练后的BERT模型，可以将其融合到各种NLP任务中。BERT中每个词没有固定的词向量，是根据词的上下文来动态产生当前词的词向量。</p><p>在论文中，列出了四大BERT的下游任务：</p><img src="/2022/04/17/bert/image-20220417185625315.png" class=""><p>第一个任务是句子对的分类任务，第二个是单一句子的分类任务，第三个是问答系统，第四个是单一句子的标注任务。它们均可在预训练BERT的输出上接入相应的结构实现，最后基于任务的训练数据进行微调实现。其中任务一和任务二是将特殊词元“&lt;cls&gt;”  编码后的向量输入一个分类器实现，任务四是将单个句子里每个词元经过BERT编码后的向量分别输入一个分类器中实现。</p><img src="/2022/04/17/bert/image-20220417191544227.png" class=""><p>对于任务三，输入是一个问题加一个文件，输出是输入文件对应答案的开始和结束位置。由此可以看出该模型实现的要求是询问的答案可以在文件中找到，那么这个任务怎么实现呢？如上图，我们初始化两个和编码词元后的向量相同长度的vector，图中橙色的向量用于确认答案在文件中开始词元的序号（位置），蓝色的向量用于确认结束词元的序号。将这两个向量分别乘于文件中的词元经过BERT编码的向量，然后通过一个softmax层找到最大值对应的序号即可得到答案。如图中s=2，e=3，如果文件的内容是how to use BERT，则答案为use BERT。因此在这个任务中，我们需要训练的参数是图中的两个向量。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p><p>[2] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[3] <a href="https://arxiv.org/abs/1810.04805">Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” <em>arXiv preprint arXiv:1810.04805</em> (2018).</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> BERT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer</title>
      <link href="/2022/04/11/transformer/"/>
      <url>/2022/04/11/transformer/</url>
      
        <content type="html"><![CDATA[<p>在前面我们学习过<a href="https://faith-ye.github.io/2022/04/02/zi-zhu-yi-li-mo-xing/">自注意力模型</a>，自注意力模型拥有CNN并行运算和RNN挖掘序列中的关系两大优势。因此，使用自注意力模型来设计深度架构是很有吸引力的。对比之前仍然依赖RNN来实现输入表示的类似注意力模型，Transformer模型完全基于自注意力机制，不但实现了快速并行计算，还可以像DNN一样将模型增加到非常深的深度。Transformer由论文<a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>提出，最初是应用于文本数据上的序列到序列学习，但现在已经推⼴到各种现代的深度学习中，例如语⾔、视觉、语⾳和强化学习领域。</p><p>Transformer的整体架构如下图所示，是一个Encoder-Decoder架构。Transformer是由Encoder和Decoder组成，这两个部分是基于自注意力的模块叠加而成的，源序列和目标序列先词向量化(embedding)，然后加上位置编码(positional encoding)，再分别输入到Encoder和Decoder中。</p><img src="/2022/04/11/transformer/image-20220411170353238.png" class=""><h2 id="Encoder和Decoder"><a href="#Encoder和Decoder" class="headerlink" title="Encoder和Decoder"></a>Encoder和Decoder</h2><p>从宏观角度来看，transformer的Encoder是由多个相同的层叠加而成的，每个层都有两个子层(sublayer)。第一个子层是多头自注意力(multi-head self-attention)层；第二个子层是基于位置的前馈网络(position-wise feed-forward network)层。同时受残差网络的启发，每个子层都采用了残差连接(residual connection)，并在残差连接的加法计算之后，使用层规范化(layer normalization)。在计算编码器的自注意力时，查询、键和值都来自前一个layer的输出。由于使用了残差连接，Transformer的每一个layer都将输出一个d维表示向量。</p><p>Transformer的Decoder也是由多个相同的层叠加而成的。除了Encoder中描述的两个子层之外，Decoder还在两个子层之间插入了第三个子层，称为编码器 - 解码器注意力(encoder-decoder attention)层。Decoder的子层同Encoder一样，使用了残差连接和层规范化。在编码器－解码器注意⼒中，查询来⾃前Decoder前一个layer的输出，而键和值来⾃Encoder的输出。在Decoder自主意力中，查询、键和值都来自于Decoder上一个layer的输出。但是和Encoder自主意力不同的是，Decoder的每个位置只能考虑位置之前的所有位置。这种掩蔽(masked)注意力保留了自回归(auto-regressive)属性，确保预测仅依赖于已生成的输出词元。  </p><h2 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h2><p>有关这方面的详细推导请看<a href="https://faith-ye.github.io/2022/04/02/zi-zhu-yi-li-mo-xing/">这篇文章</a>，在这节我们主要讲解编码器 - 解码器注意力层是怎么运作的。</p><img src="/2022/04/11/transformer/image-20220411200918339.png" class=""><p>以语言识别为例，如上图假定Transformer的Encoder将一段声音讯号编码成$a^{1}、a^{2}、a^{3}$三个向量，而Transformer的Decoder获取第一个表示开始的向量，将其输入到掩蔽多头自主意力层，得到一个向量，将该向量的查询q和Encoder得到的三个向量的键、值做self-attention处理得到向量v，再把向量v作为Decoder的基于位置的前馈网络层中，最后得到目标词汇。</p><img src="/2022/04/11/transformer/image-20220411200951752.png" class=""><p>将得到目标词汇对应的向量连同start对应的向量作为Decoder的输出，经过掩蔽多头自主意力层得到另一个向量，将该向量的查询$q^{‘}$和Encoder得到的三个向量的键、值做self-attention处理得到向量$v^{‘}$，反复进行这样的操作直到Decoder输出结束的标志。</p><h2 id="基于位置的前馈网络层"><a href="#基于位置的前馈网络层" class="headerlink" title="基于位置的前馈网络层"></a>基于位置的前馈网络层</h2><p>该层包含两个线性变换，在这两个线性变化之间有一个ReLU激活函数。</p><p>$$FFN(x)=max(0,xW_{1}+b_{1})W_{2}+b_{2}$$</p><h2 id="Embedding和softmax"><a href="#Embedding和softmax" class="headerlink" title="Embedding和softmax"></a>Embedding和softmax</h2><p>与其他序列转换模型类似，我们使用已经学习好的Embedding层将源序列和目标序列转换维度是$d_{model}$的向量。同时在Transformer Decoder的最后，使用线性变换和softmax函数将编码器输出转换为预测目标词汇的概率。</p><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>由于Transformer模型不包含递归和卷积操作，整个运行过程都是应用self-attention实现计算的平行化，因此Transformer没有考虑输入序列的先后顺序。为了让模型利用序列的顺序，我们需要给模型注入一些关于词汇在序列中相对或绝对位置的信息。为此，Transformer在编码器和解码器的输入加入了位置编码。位置编码和Embedding后的词向量具有相同的维度$d_{model}$，将这两个向量相加，就可以获得序列的位置资讯。</p><p>位置编码计算为：</p><p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$$</p><p>$$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$$</p><p>式中，$pos\in postion_{inputs},i\in (0,1,…,d_{model}/2)$</p><h2 id="训练和翻译"><a href="#训练和翻译" class="headerlink" title="训练和翻译"></a>训练和翻译</h2><p>假设有一个英文和其对应的中文元组：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'BOS'</span><span class="token punctuation">,</span><span class="token string">'machine'</span><span class="token punctuation">,</span><span class="token string">'learning'</span><span class="token punctuation">,</span><span class="token string">'EOS'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'BOS'</span><span class="token punctuation">,</span><span class="token string">'机器'</span><span class="token punctuation">,</span><span class="token string">'学习'</span><span class="token punctuation">,</span><span class="token string">'EOS'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>假设我们通过大量的数据训练好了Transformer，数据的格式如下：</p><ul><li>英文部分的输入为：BOS machine learning EOS；</li><li>中文部分的输入为：BOS 机器 学习；</li><li>标签为：机器 学习 EOS                     用于CrossEntropy更新模型参数</li></ul><p>翻译时：</p><ul><li>英文序列作为输入；</li><li>Encoder输出max_output_len个词向量;</li><li>将标志符号BOS作为中文的第一个tokens，结合Encoder的输出输入到Decoder中得到关于目标词汇的概率，取概率最大对应的词汇作为输出结果，再将该词汇对应的词向量作为新的中文输入词向量，这样循环下去一次得到max_output_len个输出结果，即得到输出的中文分词列表；</li><li>顺着列表检查分词，如果出现标志符号<code>EOS</code>就截取前面的分词组成中文结果。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em> 30 (2017).</p><p>[2] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[3] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> Seq2Seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seq2Seq代码实现</title>
      <link href="/2022/04/11/seq2seq-dai-ma-shi-xian/"/>
      <url>/2022/04/11/seq2seq-dai-ma-shi-xian/</url>
      
        <content type="html"><![CDATA[<p>在这章节，我们将用RNN搭建一个seq2seq模型(sequences to sequences)，实现英文到中文的翻译，数据集应用的是由<a href="http://www.manythings.org/anki/">Tatoeba项⽬的双语句⼦对114</a>组成的“英-中文”数据集。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>原始语料需要进行预处理，所以导入必要的包和模块。注意初次安装nltk后，进行分词需要依赖punkt，因此需要对其进行下载</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> jieba<span class="token keyword">import</span> re<span class="token keyword">import</span> random<span class="token keyword">from</span> opencc <span class="token keyword">import</span> OpenCC<span class="token keyword">import</span> nltk<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenizenltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[nltk_data] Downloading package punkt to[nltk_data]     C:\Users\kaxim\AppData\Roaming\nltk_data...[nltk_data]   Package punkt is already up-to-date!True</code></pre><h3 id="词元化"><a href="#词元化" class="headerlink" title="词元化"></a>词元化</h3><p>该部分的作用是将数据词元化，用en，cn两个列表分别用来保存源语言（英语）和目标语言（中文）。在这两个列表中，对应列表索引的内容分别表示英语和其对应的中文翻译。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">cc <span class="token operator">=</span> OpenCC<span class="token punctuation">(</span><span class="token string">'t2s'</span><span class="token punctuation">)</span>   <span class="token comment"># t2s -繁体转简体； s2t -简体转繁体</span>en<span class="token punctuation">,</span> cn <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>data_dir <span class="token operator">=</span> <span class="token string">'./data/cmn-eng/cmn.txt'</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>   <span class="token comment"># sentence[0]为英文句子，sentence[1]为中文句子</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        en_sentence <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            en_sentence <span class="token operator">+=</span> word<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span>        en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>en_sentence<span class="token punctuation">)</span>                cn_sentence <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>sentence<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            word <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[ \n\t\r]'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> word<span class="token punctuation">)</span>            <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">''</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            cn_sentence <span class="token operator">+=</span> cc<span class="token punctuation">.</span>convert<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span>        cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cn_sentence<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Building prefix dict from the default dictionary ...Loading model from cache C:\Users\kaxim\AppData\Local\Temp\jieba.cacheLoading model cost 0.429 seconds.Prefix dict has been built successfully.</code></pre><p>查看词元化后的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">en<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cn<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>('thanks for the memories . ', '感谢 那些 回忆 。 ')</code></pre><h3 id="构建字典"><a href="#构建字典" class="headerlink" title="构建字典"></a>构建字典</h3><p>由于机器翻译数据集由语言对组成，因此我们需分别为源语言和目标语言构建字典，这样就方便之后转为one-hot vector。在该字典中，我们将出现次数少于3的低频率词视为相同未知词元（“&lt;unk&gt;”）。除此之外，我们还指定了额外的特定词元，例如在小批量时⽤于将序列填充到相同⻓度的填充词元（“&lt;pad&gt;”），以及序列的开始词元（“&lt;bos&gt;”）和结束词元（“&lt;eos&gt;”）。这些特殊词元在⾃然语⾔处理任务中⽐较常⽤。<br>构建的字典有以下两种形式：<br>int2word: 将整数转为对应文字<br>word2int: 将文字转为对应整数，该字典和前一个字典是一一对应关系</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 英文</span>words <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> sentence <span class="token keyword">in</span> en<span class="token punctuation">:</span>    _sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r ]'</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    _sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> _sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> word <span class="token keyword">in</span> _sentence<span class="token punctuation">:</span>        words<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>words <span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>words<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> d<span class="token punctuation">:</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#排序</span>words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> count <span class="token keyword">in</span> words <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">]</span>words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> wordsword2int_en<span class="token punctuation">,</span> int2word_en <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> index<span class="token punctuation">,</span>word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>    word2int_en<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> index    int2word_en<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> word<span class="token comment"># 中文</span>words <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> sentence <span class="token keyword">in</span> cn<span class="token punctuation">:</span>    _sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r ]'</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    _sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> _sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> word <span class="token keyword">in</span> _sentence<span class="token punctuation">:</span>        words<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>words <span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>words<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> d<span class="token punctuation">:</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#排序</span>words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> count <span class="token keyword">in</span> words <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">]</span>words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> wordsword2int_cn<span class="token punctuation">,</span> int2word_cn <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>    word2int_cn<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> index    int2word_cn<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> word<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>部分字典展示，由于字典不支持切片功能，因此我们需构建一个函数，实现切片功能</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dict_slice</span><span class="token punctuation">(</span>adict<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>    keys <span class="token operator">=</span> adict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>    dict_slice <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>keys<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> index<span class="token punctuation">]</span><span class="token punctuation">:</span>        dict_slice<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> adict<span class="token punctuation">[</span>k<span class="token punctuation">]</span>    <span class="token keyword">return</span> dict_slice<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>英文字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dict_slice<span class="token punctuation">(</span>word2int_en<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dict_slice<span class="token punctuation">(</span>int2word_en<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>({'&lt;PAD&gt;': 0,  '&lt;BOS&gt;': 1,  '&lt;EOS&gt;': 2,  '&lt;UNK&gt;': 3,  '.': 4,  'i': 5,  'the': 6,  'to': 7,  'you': 8,  'a': 9,  '?': 10,  'is': 11,  'tom': 12,  "n't": 13,  'he': 14}, {0: '&lt;PAD&gt;',  1: '&lt;BOS&gt;',  2: '&lt;EOS&gt;',  3: '&lt;UNK&gt;',  4: '.',  5: 'i',  6: 'the',  7: 'to',  8: 'you',  9: 'a',  10: '?',  11: 'is',  12: 'tom',  13: "n't",  14: 'he'})</code></pre><p>中文字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dict_slice<span class="token punctuation">(</span>word2int_cn<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dict_slice<span class="token punctuation">(</span>int2word_cn<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>({'&lt;PAD&gt;': 0,  '&lt;BOS&gt;': 1,  '&lt;EOS&gt;': 2,  '&lt;UNK&gt;': 3,  '。': 4,  '我': 5,  '的': 6,  '了': 7,  '你': 8,  '他': 9,  '？': 10,  '在': 11,  '汤姆': 12,  '是': 13,  '吗': 14}, {0: '&lt;PAD&gt;',  1: '&lt;BOS&gt;',  2: '&lt;EOS&gt;',  3: '&lt;UNK&gt;',  4: '。',  5: '我',  6: '的',  7: '了',  8: '你',  9: '他',  10: '？',  11: '在',  12: '汤姆',  13: '是',  14: '吗'})</code></pre><h3 id="构建训练资料"><a href="#构建训练资料" class="headerlink" title="构建训练资料"></a>构建训练资料</h3><p>将数据划分成训练集，验证集和测试集</p><ul><li>训练集：25000句</li><li>验证集：1000句</li><li>测试集：1965句</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> en_sentence<span class="token punctuation">,</span> cn_sentence <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>en<span class="token punctuation">,</span> cn<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 去除中英文种出现3个未知词汇以上的句子</span>    tokens <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r  ]'</span><span class="token punctuation">,</span> en_sentence<span class="token punctuation">)</span>    tokens <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>    count <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        index <span class="token operator">=</span> word2int_en<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> index <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>            count <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>        tokens <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r  ]'</span><span class="token punctuation">,</span> cn_sentence<span class="token punctuation">)</span>    tokens <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>    count <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        Index <span class="token operator">=</span> word2int_cn<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> Index <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>            count <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">3</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>    sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>en_sentence <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> cn_sentence<span class="token punctuation">)</span>    sentences <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 去重</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">2022</span><span class="token punctuation">)</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>train_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25000</span><span class="token punctuation">]</span>validation_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token number">25000</span><span class="token punctuation">:</span><span class="token number">26000</span><span class="token punctuation">]</span>test_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token number">26000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>1965</code></pre><h2 id="定义dataset"><a href="#定义dataset" class="headerlink" title="定义dataset"></a>定义dataset</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 首先定义一个函数，它可以将句子扩展到相同长度，以便模型训练</span><span class="token keyword">class</span> <span class="token class-name">LabelTransform</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> size<span class="token punctuation">,</span> pad<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>size <span class="token operator">=</span> size        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad            <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>        label <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>label<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>size <span class="token operator">-</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'constant'</span><span class="token punctuation">,</span> constant_values<span class="token operator">=</span>self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>        <span class="token keyword">return</span> label<span class="token comment"># dataset</span><span class="token keyword">class</span> <span class="token class-name">EN2CNDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_output_len<span class="token punctuation">,</span> set_name<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">,</span> self<span class="token punctuation">.</span>int2word_en <span class="token operator">=</span> word2int_en<span class="token punctuation">,</span> int2word_en        self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">,</span> self<span class="token punctuation">.</span>int2word_cn <span class="token operator">=</span> word2int_cn<span class="token punctuation">,</span> int2word_cn        self<span class="token punctuation">.</span>data <span class="token operator">=</span> set_name                self<span class="token punctuation">.</span>cn_vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>en_vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> LabelTransform<span class="token punctuation">(</span>max_output_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 先将中英文分开</span>        sentences <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        sentences <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[\t\n]'</span><span class="token punctuation">,</span> sentences<span class="token punctuation">)</span>        sentences <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentences<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(sentences)</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span>                <span class="token comment"># 预备特殊字符</span>        BOS <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">]</span>        EOS <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">]</span>        UNK <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span>                <span class="token comment"># 在开头添加 &lt;BOS&gt;，在结尾添加 &lt;EOS&gt; ，不在字典里面的 subword （词）用 &lt;UNK&gt; 代替</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span> <span class="token punctuation">[</span>BOS<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>BOS<span class="token punctuation">]</span>        <span class="token comment"># 将句子拆解为 subword ，并用字典对应的整数取代</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> sentences<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(f'en: {sentence}')</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> UNK<span class="token punctuation">)</span><span class="token punctuation">)</span>        en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS<span class="token punctuation">)</span>                <span class="token comment"># 中文</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> sentences<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(f'cn: {sentence}')</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> UNK<span class="token punctuation">)</span><span class="token punctuation">)</span>        cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS<span class="token punctuation">)</span>                en<span class="token punctuation">,</span> cn <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>        <span class="token comment"># print(en, cn)</span>                <span class="token comment"># 用 &lt;PAD&gt; 将句子补到相同的长度</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>        <span class="token comment"># print(en, cn)</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span>  torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>                <span class="token keyword">return</span> en<span class="token punctuation">,</span> cn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Encoder-Decoder模型"><a href="#Encoder-Decoder模型" class="headerlink" title="Encoder-Decoder模型"></a>Encoder-Decoder模型</h2><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>seq2seq模型的编码器为RNN。对于每个输入，Encoder会输出一个向量和一个隐状态（hidden state），并将隐状态作为Decoder的输入。换句话说，Encoder会逐步读取输入序列，并输出单个向量（最终隐状态）</p><p>参数：</p><ul><li>en_vocab_size是英文字典的大小，也就是英文的subword的个数</li><li>emb_dim是embedding的维度，主要将one-hot vector的单词向量压缩到指定的维度，主要是为了将维和浓缩资讯的功能，可以使用预先训练好的word embedding</li><li>hid_dim是RNN输出和隐状态的维度</li><li>n_layers是RNN要叠多少层</li><li>dropout是决定有多少的概率会将某个节点变为0，主要是为了防止过拟合，一般来说是在训练时使用，测试时则不适用</li></ul><p>Encoder的输入：</p><ul><li>英文的整数序列</li></ul><p>输出：</p><ul><li>outputs：最上层RNN全部的输出，可以用Attention进行处理</li><li>hidden：每层最后的隐状态，将传递到Decoder进行解码</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> en_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>en_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> hid_dim        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> n_layers        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input = [batch size, sequence len, vocab size]</span>        embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># outputs = [batch size, sequence len, hid dim * directions]</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]</span>        <span class="token comment"># outputs 是最上层RNN的输出</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> hidden<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder是另一个RNN，在最简单的seq2seq decoder中， 仅使用Encoder每一层最后的隐状态来进行解码，这个隐状态用作Decoder的初始隐状态，本节先做最简单的Decoder，你也可以尝试将Encoder的输出用于Attention机制加到Decoder的输入中。</p><p>参数：</p><ul><li>cn_vocab_size是中文字典的大小，也就是中文的subword的个数</li><li>emb_dim是embedding的维度，主要将one-hot vector的单词向量压缩到指定的维度，主要是为了将维和浓缩资讯的功能，可以使用预先训练好的word embedding</li><li>hid_dim是RNN输出和隐状态的维度</li><li>n_layers是RNN要叠多少层</li><li>dropout是决定有多少的概率会将某个节点变为0，主要是为了防止过拟合，一般来说是在训练时使用，测试时则不适用</li></ul><p>Decoder的输入：</p><ul><li>前一次解码出来的单词的整数表示</li></ul><p>输出：</p><ul><li>hidden：根据输入和前一次的隐状态，现在的隐状态更新的结果</li><li>output：每个字有多少概率是这次解码的结果</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cn_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cn_vocab_size <span class="token operator">=</span> cn_vocab_size        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> hid_dim <span class="token operator">*</span> <span class="token number">2</span>    <span class="token comment"># Encoder使用双向RNN的缘故</span>        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> n_layers        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cn_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> emb_dim        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding2vocab <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hid_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hid_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input = [batch size, vocab size]</span>        <span class="token comment"># hidden = [batch size, n layers * directions, hid dim]</span>        <span class="token comment"># Decoder 只会是单向的，所以 directions=1</span>        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>                       <span class="token comment"># input(batch_size, 1, vocab_size)</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># embedded(batch_size, 1, embed_dim)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embedded<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>              <span class="token comment"># output(batch_size, 1, hid_dim * 2)  hidden(batch_size, num_layers * 1, hid_dim * 2)</span>                <span class="token comment"># 将 RNN 的输出转为每个词出现的概率</span>        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding2vocab<span class="token punctuation">(</span>output<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># prediction(batch_size, cn_vocab_size)</span>        <span class="token keyword">return</span> prediction<span class="token punctuation">,</span> hidden<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h3><p>这部分是整个seq2seq模型的构建，实现Encoder和Decoder的联合。简单来说就是Encoder接受输入得到输出，将Encoder的输出传给Decoder，然后将Decoder得到的输出传回Decoder进行解码，解码完成后，将Decoder的输出传回，就这样一直到输出中解码出&lt;EOS&gt;</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Seq2Seq</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Seq2Seq<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> encoder        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> decoder        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input  = [batch size, input len, vocab size]</span>        <span class="token comment"># target = [batch size, target len, vocab size]</span>        <span class="token comment"># teacher_forcing_ratio 是有多少概率使用正确答案来计算</span>        batch_size <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_len <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        vocab_size <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>cn_vocab_size                <span class="token comment"># 准备一个储存空间来储存输出</span>        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> target_len<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 输入进入Encoder</span>        encoder_outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token comment"># Encoder 最后的隐状态（hidden state）用来初始化 Decoder</span>        <span class="token comment"># encoder_outputs 主要是使用在 Attention</span>        <span class="token comment"># 因为 Encoder 是双向的RNN，所以需要将同一层两个方向的 hidden state 连接在一起</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]  --&gt; [num_layers, directions, batch size  , hid dim]</span>        hidden <span class="token operator">=</span> hidden<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 取的 &lt;BOS&gt; token</span>        <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> target_len<span class="token punctuation">)</span><span class="token punctuation">:</span>            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>            outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">=</span> output            <span class="token comment"># 决定是否用正确答案来做训练</span>            teacher_force <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> teacher_forcing_ratio            <span class="token comment"># 取出概率最大的单词</span>            top1 <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment"># 如果是 teacher force 则用正解训练，反之用自己预测的单词训练</span>            <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token keyword">if</span> teacher_force <span class="token keyword">and</span> t <span class="token operator">&lt;</span> target_len <span class="token keyword">else</span> top1            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>top1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> preds        <span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input  = [batch size, input len, vocab size]</span>        <span class="token comment"># target = [batch size, target len, vocab size]</span>        batch_size <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_len <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        vocab_size <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>cn_vocab_size                <span class="token comment"># 准备一个储存空间来储存输出</span>        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> target_len<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 输入进入Encoder</span>        encoder_outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token comment"># Encoder 最后的隐状态（hidden state）用来初始化 Decoder</span>        <span class="token comment"># encoder_outputs 主要是使用在 Attention</span>        <span class="token comment"># 因为 Encoder 是双向的RNN，所以需要将同一层两个方向的 hidden state 连接在一起</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]  --&gt; [num_layers, directions, batch size  , hid dim]</span>        hidden <span class="token operator">=</span> hidden<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 取的 &lt;BOS&gt; token</span>        <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> target_len<span class="token punctuation">)</span><span class="token punctuation">:</span>            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>            outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">=</span> output            <span class="token comment"># 取出概率最大的单词</span>            top1 <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token builtin">input</span> <span class="token operator">=</span> top1            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>top1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Utils"><a href="#Utils" class="headerlink" title="Utils"></a>Utils</h2><h3 id="储存模型"><a href="#储存模型" class="headerlink" title="储存模型"></a>储存模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> store_model_path<span class="token punctuation">,</span> step<span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>store_model_path<span class="token punctuation">}</span></span><span class="token string">/model_</span><span class="token interpolation"><span class="token punctuation">{</span>step<span class="token punctuation">}</span></span><span class="token string">.ckpt'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="载入模型"><a href="#载入模型" class="headerlink" title="载入模型"></a>载入模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> load_model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Load model from </span><span class="token interpolation"><span class="token punctuation">{</span>load_model_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>load_model_path<span class="token punctuation">}</span></span><span class="token string">.ckpt'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_model</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> en_vocab_size<span class="token punctuation">,</span> cn_vocab_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 构建模型</span>    encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>en_vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>    decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>cn_vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>    <span class="token keyword">if</span> config<span class="token punctuation">.</span>load_model<span class="token punctuation">:</span>        model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> config<span class="token punctuation">.</span>load_model_path<span class="token punctuation">)</span>        model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optimizer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="数字转句子"><a href="#数字转句子" class="headerlink" title="数字转句子"></a>数字转句子</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokens2sentence</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> int2word<span class="token punctuation">)</span><span class="token punctuation">:</span>    sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> tokens <span class="token keyword">in</span> outputs<span class="token punctuation">:</span>        sentence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        word <span class="token operator">=</span> int2word<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>        sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>    sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>    <span class="token keyword">return</span> sentences<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计算BLEU-score"><a href="#计算BLEU-score" class="headerlink" title="计算BLEU score"></a>计算BLEU score</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> nltk<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> sentence_bleu<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> SmoothingFunction<span class="token keyword">def</span> <span class="token function">computebleu</span><span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>    score <span class="token operator">=</span> <span class="token number">0</span>     <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>targets<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">cut_token</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> token <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            <span class="token keyword">if</span> token <span class="token operator">==</span> <span class="token string">'&lt;UNK&gt;'</span> <span class="token keyword">or</span> token<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">bytes</span><span class="token punctuation">(</span>token<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                tmp <span class="token operator">+=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> token<span class="token punctuation">]</span>        <span class="token keyword">return</span> tmp     <span class="token keyword">for</span> sentence<span class="token punctuation">,</span> target <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>        sentence <span class="token operator">=</span> cut_token<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>        target <span class="token operator">=</span> cut_token<span class="token punctuation">(</span>target<span class="token punctuation">)</span>        score <span class="token operator">+=</span> sentence_bleu<span class="token punctuation">(</span><span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                                                                              <span class="token keyword">return</span> score<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="迭代dataloader"><a href="#迭代dataloader" class="headerlink" title="迭代dataloader"></a>迭代dataloader</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">infinite_iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>    it <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            ret <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>it<span class="token punctuation">)</span>            <span class="token keyword">yield</span> ret        <span class="token keyword">except</span> StopIteration<span class="token punctuation">:</span>            it <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h2><p>实际工作中，训练一个好的机器翻译模型需要大量的语料，训练的周期长。本次实验数据集简单，训练耗时短，定义的训练和测试函数如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss_function<span class="token punctuation">,</span> total_steps<span class="token punctuation">,</span> summary_steps<span class="token punctuation">,</span> train_dataset<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>summary_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> sources<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> preds <span class="token operator">=</span> model<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span>        <span class="token comment"># targets 的第一个 token 是 &lt;BOS&gt; 所以忽略</span>        outputs <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        grad_norm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        loss_sum <span class="token operator">=</span> loss_sum <span class="token operator">/</span> <span class="token number">5</span>        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">"train [{}] loss: {:.3f}, Perplexity: {:.3f} "</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_steps <span class="token operator">+</span> step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> loss_sum<span class="token punctuation">,</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>loss_sum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>        losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_sum<span class="token punctuation">)</span>        loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> losses<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_sum<span class="token punctuation">,</span> bleu_score<span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>    n <span class="token operator">=</span> <span class="token number">0</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> sources<span class="token punctuation">,</span> targets <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> sources<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        batch_size <span class="token operator">=</span> sources<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> preds <span class="token operator">=</span> model<span class="token punctuation">.</span>inference<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        <span class="token comment"># targets 的第一個 token 是 &lt;BOS&gt; 所以忽略</span>        outputs <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 將預測結果轉為文字</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>view<span class="token punctuation">(</span>sources<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_cn<span class="token punctuation">)</span>        sources <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_en<span class="token punctuation">)</span>        targets <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_cn<span class="token punctuation">)</span>        <span class="token keyword">for</span> source<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> target <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>sources<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>            result<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>source<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 計算 Bleu Score</span>        bleu_score <span class="token operator">+=</span> computebleu<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        n <span class="token operator">+=</span> batch_size    <span class="token keyword">return</span> loss_sum <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> bleu_score <span class="token operator">/</span> n<span class="token punctuation">,</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h3><p>先训练后测试</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_process</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 准备训练资料</span>    train_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> train_set<span class="token punctuation">)</span>    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    train_iter <span class="token operator">=</span> infinite_iter<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>    <span class="token comment"># 准备验证资料</span>    val_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> validation_set<span class="token punctuation">)</span>    val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 构建模型</span>    model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> build_model<span class="token punctuation">(</span>config<span class="token punctuation">,</span> train_dataset<span class="token punctuation">.</span>en_vocab_size<span class="token punctuation">,</span> train_dataset<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span>    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    total_steps <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>total_steps <span class="token operator">&lt;</span> config<span class="token punctuation">.</span>num_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 训练模型</span>        model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss_function<span class="token punctuation">,</span> total_steps<span class="token punctuation">,</span> config<span class="token punctuation">.</span>summary_steps<span class="token punctuation">,</span> train_dataset<span class="token punctuation">,</span> config<span class="token punctuation">.</span>teacher_forcing_ratio<span class="token punctuation">)</span>        train_losses <span class="token operator">+=</span> loss        <span class="token comment"># 验证模型</span>        val_loss<span class="token punctuation">,</span> bleu_score<span class="token punctuation">,</span> result <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span>        val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>        bleu_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>bleu_score<span class="token punctuation">)</span>        total_steps <span class="token operator">+=</span> config<span class="token punctuation">.</span>summary_steps        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}  "</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span><span class="token punctuation">,</span> bleu_score<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 储存模型的结果</span>        <span class="token keyword">if</span> total_steps <span class="token operator">%</span> config<span class="token punctuation">.</span>store_steps <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> total_steps <span class="token operator">&gt;=</span> config<span class="token punctuation">.</span>num_steps<span class="token punctuation">:</span>            save_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> config<span class="token punctuation">.</span>store_model_path<span class="token punctuation">,</span> total_steps<span class="token punctuation">)</span>            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>config<span class="token punctuation">.</span>store_model_path<span class="token punctuation">}</span></span><span class="token string">/output_</span><span class="token interpolation"><span class="token punctuation">{</span>total_steps<span class="token punctuation">}</span></span><span class="token string">.txt'</span></span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>                <span class="token keyword">for</span> line <span class="token keyword">in</span> result<span class="token punctuation">:</span>                    <span class="token keyword">print</span> <span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>f<span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test_process</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 准备测试资料</span>    test_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> test_set<span class="token punctuation">)</span>    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 构建模型</span>    model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> build_model<span class="token punctuation">(</span>config<span class="token punctuation">,</span> test_dataset<span class="token punctuation">.</span>en_vocab_size<span class="token punctuation">,</span> test_dataset<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span>    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Finish build model"</span><span class="token punctuation">)</span>    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 测试模型</span>    test_loss<span class="token punctuation">,</span> bleu_score<span class="token punctuation">,</span> result <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span>    <span class="token comment"># 储存结果</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'./log/cmn-eng/test_output.txt'</span></span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> result<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>f<span class="token punctuation">)</span>    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> bleu_score<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><ul><li>实验的参数设定表</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">configurations</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>        self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> <span class="token number">256</span>        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> <span class="token number">512</span>        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> <span class="token number">2</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> <span class="token number">0.5</span>        self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> <span class="token number">0.00005</span>        self<span class="token punctuation">.</span>teacher_forcing_ratio <span class="token operator">=</span> <span class="token number">0.8</span>        self<span class="token punctuation">.</span>max_output_len <span class="token operator">=</span> <span class="token number">40</span>              <span class="token comment"># 最后输出句子的最大长度</span>        self<span class="token punctuation">.</span>num_steps <span class="token operator">=</span> <span class="token number">12000</span>                <span class="token comment"># 总训练次数</span>        self<span class="token punctuation">.</span>store_steps <span class="token operator">=</span> <span class="token number">300</span>                <span class="token comment"># 训练多少次后需存模型</span>        self<span class="token punctuation">.</span>summary_steps <span class="token operator">=</span> <span class="token number">300</span>              <span class="token comment"># 训练多少次后需检验是否有过拟合</span>        self<span class="token punctuation">.</span>load_model <span class="token operator">=</span> <span class="token boolean">False</span>               <span class="token comment"># 是否需载入模型</span>        self<span class="token punctuation">.</span>store_model_path <span class="token operator">=</span> <span class="token string">"./log/ckpt"</span>      <span class="token comment"># 储存模型的位置</span>        self<span class="token punctuation">.</span>load_model_path <span class="token operator">=</span> <span class="token string">"./log/ckpt/model_12000"</span>           <span class="token comment"># 载入模型的位置 e.g. "./ckpt/model_{step}" </span>        self<span class="token punctuation">.</span>data_path <span class="token operator">=</span> <span class="token string">"./data/cmn-eng"</span>          <span class="token comment"># 资料存放的位置</span>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> <span class="token boolean">False</span>                <span class="token comment"># 是否使用 Attention Mechanism</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练模型:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">config <span class="token operator">=</span> configurations<span class="token punctuation">(</span><span class="token punctuation">)</span>train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores <span class="token operator">=</span> train_process<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>Seq2Seq(  (encoder): Encoder(    (embedding): Embedding(4397, 256)    (rnn): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)    (dropout): Dropout(p=0.5, inplace=False)  )  (decoder): Decoder(    (embedding): Embedding(6798, 256)    (rnn): GRU(256, 1024, num_layers=2, batch_first=True, dropout=0.5)    (embedding2vocab): Sequential(      (0): Linear(in_features=1024, out_features=4096, bias=True)      (1): Linear(in_features=4096, out_features=6798, bias=True)    )    (dropout): Dropout(p=0.5, inplace=False)  ))Adam (Parameter Group 0    amsgrad: False    betas: (0.9, 0.999)    eps: 1e-08    lr: 5e-05    weight_decay: 0) train [300] loss: 0.911, Perplexity: 2.488   val [300] loss: 5.124, Perplexity: 168.024, blue score: 0.186   val [600] loss: 4.827, Perplexity: 124.873, blue score: 0.233   val [900] loss: 4.643, Perplexity: 103.901, blue score: 0.278   val [1200] loss: 4.538, Perplexity: 93.484, blue score: 0.291   val [1500] loss: 4.514, Perplexity: 91.273, blue score: 0.288   val [1800] loss: 4.457, Perplexity: 86.216, blue score: 0.307   val [2100] loss: 4.504, Perplexity: 90.364, blue score: 0.313   val [2400] loss: 4.392, Perplexity: 80.830, blue score: 0.333   val [2700] loss: 4.389, Perplexity: 80.539, blue score: 0.329   val [3000] loss: 4.380, Perplexity: 79.800, blue score: 0.342   val [3300] loss: 4.319, Perplexity: 75.126, blue score: 0.357   val [3600] loss: 4.245, Perplexity: 69.757, blue score: 0.358   val [3900] loss: 4.262, Perplexity: 70.927, blue score: 0.371   val [4200] loss: 4.241, Perplexity: 69.500, blue score: 0.375   val [4500] loss: 4.234, Perplexity: 68.983, blue score: 0.387   val [4800] loss: 4.186, Perplexity: 65.791, blue score: 0.385   val [5100] loss: 4.122, Perplexity: 61.675, blue score: 0.396   val [5400] loss: 4.162, Perplexity: 64.201, blue score: 0.399   val [5700] loss: 4.148, Perplexity: 63.323, blue score: 0.410   val [6000] loss: 4.065, Perplexity: 58.286, blue score: 0.404   val [6300] loss: 4.089, Perplexity: 59.695, blue score: 0.410   val [6600] loss: 4.076, Perplexity: 58.931, blue score: 0.417   val [6900] loss: 4.103, Perplexity: 60.544, blue score: 0.423   val [7200] loss: 4.102, Perplexity: 60.452, blue score: 0.426   val [7500] loss: 4.092, Perplexity: 59.838, blue score: 0.429   val [7800] loss: 4.029, Perplexity: 56.186, blue score: 0.433   val [8100] loss: 4.057, Perplexity: 57.809, blue score: 0.440   val [8400] loss: 4.023, Perplexity: 55.880, blue score: 0.440   val [8700] loss: 4.025, Perplexity: 55.962, blue score: 0.445   val [9000] loss: 4.043, Perplexity: 57.014, blue score: 0.450   val [9300] loss: 4.020, Perplexity: 55.690, blue score: 0.453   val [9600] loss: 4.030, Perplexity: 56.256, blue score: 0.460   val [9900] loss: 4.032, Perplexity: 56.365, blue score: 0.465   val [10200] loss: 4.056, Perplexity: 57.730, blue score: 0.454   val [10500] loss: 4.001, Perplexity: 54.639, blue score: 0.465   val [10800] loss: 4.055, Perplexity: 57.664, blue score: 0.461   val [11100] loss: 4.007, Perplexity: 55.003, blue score: 0.470   val [11400] loss: 4.063, Perplexity: 58.153, blue score: 0.468   val [11700] loss: 4.042, Perplexity: 56.917, blue score: 0.474   val [12000] loss: 4.072, Perplexity: 58.686, blue score: 0.475  </code></pre><p>测试模型：</p><p>在执行这步之前，请先去config设定所要载入模型的位置，并将load_model设置为True</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">config<span class="token punctuation">.</span>load_model <span class="token operator">=</span> <span class="token boolean">True</span>test_loss<span class="token punctuation">,</span> bleu_score <span class="token operator">=</span> test_process<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'test loss: </span><span class="token interpolation"><span class="token punctuation">{</span>test_loss<span class="token punctuation">}</span></span><span class="token string">, bleu_score: </span><span class="token interpolation"><span class="token punctuation">{</span>bleu_score<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>Seq2Seq(  (encoder): Encoder(    (embedding): Embedding(4397, 256)    (rnn): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)    (dropout): Dropout(p=0.5, inplace=False)  )  (decoder): Decoder(    (embedding): Embedding(6798, 256)    (rnn): GRU(256, 1024, num_layers=2, batch_first=True, dropout=0.5)    (embedding2vocab): Sequential(      (0): Linear(in_features=1024, out_features=4096, bias=True)      (1): Linear(in_features=4096, out_features=6798, bias=True)    )    (dropout): Dropout(p=0.5, inplace=False)  ))Adam (Parameter Group 0    amsgrad: False    betas: (0.9, 0.999)    eps: 1e-08    lr: 5e-05    weight_decay: 0)Load model from ./log/ckpt/model_12000Finish build modeltest loss: 4.043186987083377, bleu_score: 0.470621067287946</code></pre><h2 id="图形化训练过程"><a href="#图形化训练过程" class="headerlink" title="图形化训练过程"></a>图形化训练过程</h2><h3 id="训练的loss变化趋势"><a href="#训练的loss变化趋势" class="headerlink" title="训练的loss变化趋势"></a>训练的loss变化趋势</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'train loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_49_1.png" class="">    <h2 id="验证的loss变化趋势"><a href="#验证的loss变化趋势" class="headerlink" title="验证的loss变化趋势"></a>验证的loss变化趋势</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>val_losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'validation loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_51_0.png" class=""><h2 id="BLEU-score"><a href="#BLEU-score" class="headerlink" title="BLEU score"></a>BLEU score</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>bleu_scores<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'BLEU score'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'BLEU score'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_53_0.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2020-spring.php">李宏毅 机器学习2020</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Seq2Seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于GAN的多水库径流序列的随机生成</title>
      <link href="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/"/>
      <url>/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="基于GAN的多水库径流序列的随机生成"><a href="#基于GAN的多水库径流序列的随机生成" class="headerlink" title="基于GAN的多水库径流序列的随机生成"></a>基于GAN的多水库径流序列的随机生成</h1><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404135935711-16490728909091.png" class=""><p>该文将DCGAN和WGAN结合起来组成一个新的方法DC-WGAN，并用于径流序列的随机生成。该方法可以同时捕捉径流序列在时间和空间维度上的相关性，解决了传统方法（如Copula等）在径流序列随机生成中时空相关性表现不足的问题。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>隐式随机优化(implicit stochastic optimization, ISO)模型是一种已广泛应用于水库系统中长期优化运行的方法。在实际工程中，水库历史序列的长度只有几十年，难以反映未来径流变化的随机性。因此径流序列的生成是弥补历史径流样本代表性和可靠性差的关键技术，是保证ISO模型准确性的前提。</p><p>对于单个水库，现有径流序列的样本时间长度能满足ISO的操作要求。但对于具有时空相关性的径流序列，当前样本的代表性和可靠性不足以满足。而具有时空相关性的径流序列的产生给水库系统联合优化运行的精细化管理带来了巨大的挑战。然而现有径流序列生成方法并没有体现水库间的时空相关性，它们有以下缺点：</p><ul><li>难以扩展到高维，不适合多时间尺度的多水库系统的径流随机生成</li><li>径流序列的概率分布应事先假定，这在实际中不适用</li><li>难于捕捉高维数据的非线性特点，无法满足水库系统径流生成的要求</li></ul><p>为解决上述问题，作者提出了一种基于GAN的径流序列的随机生成。GAN的特征有：①可以直接学习历史数据的分布，无需预先进行数据概率分布的假定；②无监督学习的模式避免繁琐的人工标注，适用于学习和生成大规模的数据集。作者将GAN的这些特点应用于径流系统的随机生成，创新点有：</p><ul><li>从模型学习能力和泛化能力两个方面探索DC-WGAN在水库系统径流随机生成领域的随机性</li><li>与Copula方法相比，分析DC-WGAN径流样本的时空相关性</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p>生成式对抗网络(Generative adversarial network , GAN)在2014年被Goodfellow提出，已广泛用于计算机视觉和自然语言处理等领域。GAN通过生成器(generator)和判别器(discriminator)的对立实现了很好的生成效果。这两个网络的不同点在于，生成器的输入是一组随机噪音，作用是生成和目标数据分布相似的数据。而判别器的输入有真实数据和生成器生成的数据，输出是一个概率值，表示输入数据是历史数据的置信度。比如输出为1代表输入数据为真实数据，输出为0代表是生成数据。</p><p>假设我们有M个水库，每个水库拥有N年的历史径流数据，每年的径流数据被划分为T个时期。历史径流数据可以表示为</p><p>$${x^{t}_{i,j}},i=1,2,…,M;j=1,2,…,N;t=1,2,…,T$$</p><p>真实数据用$P_{data}(x)$表示，GAN的两个网络结构：生成器$G(z;\theta^{G})$，判别器$D(x;\theta^{D})$，其中$\theta^{G}$和$\theta^{D}$是这两个网络结构的权重参数（需要通过训练得到）,z是一个已知分布的随机噪音。生成器的目标是产生的数据的分布要尽可能和真实数据的分布相似，用于<strong>“欺骗”</strong>判别器。而判别器的目标是区分数据是来源于真实数据还是生成数据。这两个网络在迭代过程中相互竞争以提高模型性能，最终生成的数据与真实数据基本一致。</p><p>在确定网络训练的目标后，我们需要分别为生成器和判别器制定损失函数(loss function)来训练这个模型。生成器的目标是“欺骗”判别器，因此生成器的目标是最大化$D(G(z))$。判别器的目标是区分数据，因此我们最小化$D(G(z))$并最大化$D(x),x\in P_{data}(x)$。因此损失函数$L_{G}和L_{D}$可以表示为：</p><p>$$L_{G}=E_{z\in p_{z}(z)}[log(1-D(G(z)))]$$</p><p>$$L_{D}=-E_{z\in p_{z}(z)}[log(1-D(G(z)))]-E_{x\in p_{data}(x)}[log(D(x))]$$</p><p>结合以上两个式子，则整个模型变成一个minimax游戏，其目标函数变为：</p><p>$$\underset{\theta_{G}}{min}\underset{\theta_{D}}{max}V(G,D)=E_{z\in p_{z}(z)}[log(1-D(G(z)))]+E_{x\in p_{data}(x)}[log(D(x))]$$</p><h3 id="改进的GAN"><a href="#改进的GAN" class="headerlink" title="改进的GAN"></a>改进的GAN</h3><h4 id="原始生成式对抗网络存在的缺点"><a href="#原始生成式对抗网络存在的缺点" class="headerlink" title="原始生成式对抗网络存在的缺点"></a><strong>原始生成式对抗网络存在的缺点</strong></h4><ul><li>很难同时使两个网络同时收敛到最优，这就会影响模型训练的稳定性。举个简单例子，假设判别器的损失函数很短时间就收敛到0，那么生成器的参数就很难更新，这就导致生成器梯度消失的问题。</li><li>通过一定的数学假设，可以用JS散度来表示上面的目标函数，而JS散度存在一个问题，就是真实数据$P_{data}$和生成数据$P_{G}$没有数据重叠的话，不断真实数据和生成数据之间的距离多远，JS散度计算出来的值都是log2，这就导致了生成器梯度消失的问题。</li></ul><p>大部分改进的GAN都是为了解决上述两个问题，其中DCGAN和WGAN是最有效且使用较为广泛的。</p><h4 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h4><p>深度卷积生成式网络(deep convolutional generative adversarial network, DCGAN)在原始GAN模型的基础上，将生成器和判别器的网络结构换成了当时已经十分成熟的卷积神经网络结构，并对卷积神经网络结构进行一定的调整，克服了原始GAN训练不稳定和梯度消失的问题。具体改变有：</p><ul><li>取消所有的pooling层。生成器中使用fractionally strided convolution代替pooling层，判别器中使用strided convolution代替pooling层。</li><li>在生成器和判别器中都使用批量标准化</li><li>去除了全连接层</li><li>生成器中使用ReLU作为激活函数，最后一层使用tanh激活函数</li><li>判别器中使用LeakyReLU作为激活函数</li></ul><p>DCGAN的网络结构如下：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404182400171-16490728909102.png" class=""><h4 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h4><p>Wasserstein生成式对抗网络使用Wasserstein Distance来替换掉JS-Divergence，解决了当生成数据和真实数据没有重叠时，JS散度为log2，从而导致生成器梯度消失的问题。WGAN的优点有：</p><ul><li>判别器训练的越好，生成器就越好，这大大提高了原始GAN的稳定性</li><li>避免了模型在训练过程中崩溃，一定程度上提升了模型的鲁棒性</li></ul><h4 id="DC-WGAN"><a href="#DC-WGAN" class="headerlink" title="DC-WGAN"></a>DC-WGAN</h4><p>结合DCGAN和WGAN，作者提出了DC-WGAN模型，它的结构图如下：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404183358982-16490728909103.png" class=""><p>DC-WGAN的模型架构和算法流程分别看左图和右图：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404183813487-16490728909104.png" class=""><h2 id="研究区域"><a href="#研究区域" class="headerlink" title="研究区域"></a>研究区域</h2><p>作者以中国下游金沙江梯级水库和三峡梯级水库为研究案例，包括溪洛渡、向家坝、三峡和葛洲坝四个水库。它们的地理位置如下图所示：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404184312072-16490728909106.png" class=""><p>DC-WGAN模型的实验数据为这四个水库从1940到2010的径流序列，其中90%的径流序列（64年）被用于模型训练，10%（10年）被用于模型的验证。径流序列的时间尺度为10天，模型经过训练后产生3000个10天径流序列。</p><p>同时，用相同的数据，作者还用copula方法产生对应的径流序列，并将结果与DC_WGAN进行比较。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="学习能力"><a href="#学习能力" class="headerlink" title="学习能力"></a>学习能力</h3><p>为了验证DC-WGAN的学习能力，原始径流序列和DC-WGAN生成的径流序列的频率曲线如下图所示。图中DC-WGAN生成的径流样本是随机从3000个生成样本随机选择了64个（和原始数据数量一样），频率曲线使用对数正态分布函数绘制。从图中可以看出两个频率曲线几乎完全重叠，说明DC-WGAN生成了正确分布的径流序列。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404190906074-16490728909105.png" class=""><h3 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h3><p>为了进一步验证DC-WGAN的泛化能力，作者使用欧几里得距离(Euclidean distance)在DC-WGAN生成的3000条径流数据中找出和7个验证数据最相似的。其中三个径流序列如下图所示。由图可以看出DC-WGAN可以生成与验证集相似形态的样本，说明模型具有很强的泛化能力，图中的自相关系数曲线也验证了DC-WGAN可以捕捉径流序列的时间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404191726339-16490728909107.png" class=""><h3 id="时间相关性"><a href="#时间相关性" class="headerlink" title="时间相关性"></a>时间相关性</h3><p>为了验证径流序列的时间相关性，作者分别绘制了原始样本和分别从DC-WGAN和Copula生成样本的相关系数热力图。从下图可以看出Copula生成序列的相关性弱于原始序列和DC-WGAN生成的序列，且基于Copula的生成方法无法捕捉到弱相关性，表明DC-WGAN可以更好地学习序列的时间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404192738463-16490728909108.png" class=""><h3 id="空间相关性"><a href="#空间相关性" class="headerlink" title="空间相关性"></a>空间相关性</h3><p>为了验证径流序列的空间相关性，基于原始样本、DC-WGAN和Copula生成样本，计算溪洛渡和三峡水库10天径流的空间相关系数，如下图所示。基于三种样本的平均年径流相关系数分别为0.67、0.65和-0.01。同时可以明显地看出，溪洛渡径流系列与三峡水库径流序列呈现出较强的空间相关性。DC-WGAN可以学习到水库间径流序列的空间相关性，但基于Copula的生成方法无法捕捉到不同水库间径流序列的空间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404194104273-16490728909109.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022169421013767?via=ihub">Ma Y, Zhong P, Xu B, et al. Stochastic generation of runoff series for multiple reservoirs based on generative adversarial networks[J]. Journal of Hydrology, 2022, 605: 127326.</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> 径流序列的随机生成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自注意力模型</title>
      <link href="/2022/04/02/zi-zhu-yi-li-mo-xing/"/>
      <url>/2022/04/02/zi-zhu-yi-li-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>前面我们学习过LSTM、GRU，它们都可以挖掘序列之间的某种联系。举个简单的例子——I saw a saw（我看见了一把锯子），句中两个saw无论在词义还是词性中都有所不同。如果将这句话简单做词向量处理，然后丢进一个全连接模型的话，那么两个saw输出的结果是一样的。因为对于这种模型而言的话，它是挖掘不出词与词之间的关系。而对于LSTM，GRU来说，它通过一定的机制可以学习到句子和句子之间的联系。</p><p>那么注意力机制是怎么学习这种联系的呢？这还得从我们人类的视觉说起。当我们在看到图片或风景的时候，我们会将注意力集中到我们关注的那些事物上。比如你在绘画的过程中，你会持续地关注你构思到画板上的元素（比如蓝天，白云），而不会太多关注那些其他的元素，比如风，虫鸣，阳光等等。这种有意识的聚焦就被称为注意力机制。那么机器是怎么将这种机制应用到模型中呢？这也是这篇文章要学习的内容。</p><h2 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h2><p>仍然以I saw a saw为例，如下图所示，我们设置一个window，该window只考虑了周围三个输入，此时模型当前的输出就和周围三个输入有关。那么我们将window覆盖整个文本，是不是可以考虑整个句子中单词与单词之间的联系？</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402122749713-16488871089911.png" class=""><p>自注意力机制借鉴了这个想法，用一个结构实现上述Window中的操作，从而可以考虑句中每个单词之间的联系，进而区别出这两个saw。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402124424005-16488871089922.png" class=""><p>Attention机制通常有Bahdanau Attention（右图）与Luong Attention（左图），两种注意力的理论相似，Luong Attention的使用范围更广泛，因此本文主要讲解Luong Attention。在讲解Luong Attention前，我们先来讲解三个概念——查询、键和值。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402125443414-16488871089923.png" class=""><h3 id="查询、键和值"><a href="#查询、键和值" class="headerlink" title="查询、键和值"></a>查询、键和值</h3><p>在注意力机制的背景下，我们将自主性提示称为查询（query）。给定任何查询，注意力机制通过注意力汇聚将选择引导至感官输入。在注意力机制中，这些感官输入被称为值（value）。对于每个值都有一个键（key）与之配对，这可以想象成感官输入的非自主提示。通过注意力汇聚，每个查询（自主性提示）都可以与键（非自主性提示）进行匹配，这将引导得出最匹配的值（感官输入）。下面我们来看看查询、键和值是怎样在self-attention中运作的。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402132249578-16488871089924.png" class=""><p>  假设输入是：${a^{1},a^{2},a^{3},a^{4}}$。每个输入都对应查询、键和值。查询$q^{i}=W^{q}a^{i}$，键$k^{i}=W^{k}a^{i}$以及值$v^{i}=W^{v}a^{i}$。对于查询query，我们需要找所对应的键与之进行匹配，这样就可以得出那些信息比较重要。对应计算$a_{1,i}=q^{1}k^{i}$，再经过softmax层就可以算出每个信息对应的比重:</p><p>$$a^{’}<em>{1,i}=exp(a</em>{1,i}/ \sum_{j}(a_{1,j}))$$</p><p>进而可以求出$a^{1}$对应的输出$b^{1}=\sum_{i}a^{‘}_{1,i}v^{i}$，同理我们可以计算出$b^{2},b^{3},b^{4}$。如果计算机也这样一个接一个计算，那计算效率太低。其实我们可以通过矩阵运算实现平行运算，具体操作如下：</p><p>查询：$$q^{i}=W^{q}a^{i}\Rightarrow (q^{1},q^{2},q^{3},q^{4})=W^{q}(a^{1},a^{2},a^{3},a^{4})$$</p><p>键：$$k^{i}=W^{k}a^{i}\Rightarrow (k^{1},k^{2},k^{3},k^{4})=W^{k}(a^{1},a^{2},a^{3},a^{4})$$</p><p>值：$$v^{i}=W^{v}a^{i}\Rightarrow (v^{1},v^{2},v^{3},v^{4})=W^{v}(a^{1},a^{2},a^{3},a^{4})$$</p><p>对于中间部分的计算可以用下图表示：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402144505171-16488871089925.png" class=""><p>从而可以得到输出：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402144618597-16488871089926.png" class=""><p>整理一下可得：</p><p>查询、键和值：$$Q,K,v=W^{q}I,W^{k}I,W^{v}I$$</p><p>注意力矩阵：$$A^{‘}\Leftarrow A=K^{T}Q$$</p><p>输出：$$O=VA^{‘}$$</p><p>由此可以看出 self-attention 需要率定的参数有$W^{q},W^{k},W^{v}$</p><h3 id="多头自注意力模型"><a href="#多头自注意力模型" class="headerlink" title="多头自注意力模型"></a>多头自注意力模型</h3><p>多头注意力（Multi-head Self-attention）模型是建立在自注意力模型的基础上。它模拟的是序列中存在不止一种的联系，这时单靠一个head是无法捕捉序列中的完整信息。以2 head为例，利用两组$W^{q},W^{k},W^{v}$对应输入$a^{i}$分别单独计算出两个输出$b^{i,1},b^{i,2}$，然后通过一个输出矩阵可以得出$b^{i}$：</p><p>$$b^{i}=W^{o}(b^{i,1},b^{i,2})^{T}$$</p><p>由此可以看出2 head带来了两倍以上的参数，虽然模型的准确度得到了提升，但是以损失计算能力为代价。</p><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>self-attention虽然考虑了输入序列中每个成分之间的联系，但并没考虑输入序列的先后顺序。这是因为self-attention中的计算是平行计算，无论序列中两个成分相隔多远，对self-attention的整个计算没有什么影响。而对于某些实际应用，序列的顺序对模型影响很大或者可以一定程度上提升模型性能。举个例子，在词性标注中，我们知道动词是很少出现在一个句子的开头。所以当一个单词出现在句子的开头时，我们有很大的把握判断这个单词不是动词。</p><p>为了改进self-attention这个弱点，我们可以对输入进行一定的操作——位置编码，从而使得self-attention考虑到序列的顺序。这个操作其实很简单，我们只需在每个输入对应的位置加一个独一无二的位置向量即可实现：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402153801462-16488871089927.png" class=""><p>这时你就会有一个疑问，位置编码是怎么确定的？具体可以看这篇论文：<a href="https://arxiv.org/abs/2003.09229">Learning to Encode Position for Transformer with Continuous Dynamical Model</a></p><h2 id="Self-attention-vs-RNN"><a href="#Self-attention-vs-RNN" class="headerlink" title="Self-attention vs RNN"></a>Self-attention vs RNN</h2><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402155319292-16488871089928.png" class=""><p>上图展示的是循环神经网络和自注意力模型的简易结构，由此可以看出self-attention相对RNN的结构优点：</p><ul><li>self-attention是平行计算，单次迭代计算速度块</li><li>self-attention可以方便地考虑两个相隔较远的单词之间的联系，而RNN虽然也能考虑到，但RNN在传递的过程中，这种联系会消失。因此self-attention在处理序列中含有较大关联的模型中更有优势。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seq2Seq</title>
      <link href="/2022/03/29/seq2seq/"/>
      <url>/2022/03/29/seq2seq/</url>
      
        <content type="html"><![CDATA[<p><strong>写在前面：</strong>这个部分主要记录一些关于深度学习相关论文的阅读，由于个人还是刚接触深度学习不久，所以前面需要补充一些很早的论文以巩固自己知识的不足。今天记录最近学的一篇论文<a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>。这篇论文研究的是机器翻译领域，作者使用的方法是利用一个多层的 LSTM 将输入文本编码成一个向量，这个向量可以视为整个输入句子的抽象表示。然后用另一个 LSTM 将前面编码的向量解码成目标句子。作者将其应用在 WMT’14 数据集上英语到法语的翻译任务，并在整个测试集上得到的 BLEU score 为34.8。下面我门结合<a href="https://d2l.ai/">Dive into Deep Learning</a>这本书的相关章节和这篇论文了解 seq2seq 的一般概念，并陈述构建模型时需要用的一些方法。</p><h2 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h2><p>最常用的 seq2seq 模型其实就是encoder-decoder模型。encoder-decoder模型通常使用 RNN 将一段文本作为输入编码（encoder）成一个向量，这个向量可以视为整个输入句子的抽象表示。然后，该向量通过第二个 RNN 解码（decoder），该 RNN 通过一次生成一个单词来学习目标句子（也就是另一种语言的句子）。下图演示了将 seq2seq 模型用于英文到中文的翻译。</p><img src="/2022/03/29/seq2seq/seq2seq.png" class=""><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>图中展示了一个简单的翻译模型，模型中用&lt;bos&gt;和&lt;eos&gt;分别表示开始词元和结束词元。它的输入句子是”good morning“，它首先通过embedding层转换为对应的词向量，然后再进入编码器（encoder）。在每一个时间步，进入编码器RNN含有embedding$x_{t}$和上一时间步隐状态$h_{t-1}$，然后编码器RNN产生新的隐状态$h_{t}$。我们可以抽象地把这个隐状态代表为前面的词元。该时间步的计算可以用以下公式表达：<br>$$h_{t}=EncoderRNN(e(x_{t},h_{t-1}))$$</p><p>在这里，我们通常使用LSTM或GRU这样的term RNN。假设，输入$X={x_{1},x_{2},…,x_{T}}$，式中 $x_{1}$=&lt;bos&gt;，$x_{2}$=good，etc 。编码器初始的隐状态 $h_{0}$ 通常初始化为0或者已经学习好的参数。一旦最后的词元 $x_{T}$ 通过embedding层进入编码器RNN，我们利用最后的隐状态 $h_{T}$ 来作为文本向量，并把它赋值给z :$h_{T}=z$</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>现在我们拥有文本向量z，我们可以开始将其解码成目标句子——”早上好“。同样我们用<sos>和<eos>分别表示目标句子的开始词元和结束词元。在每一个时间步，解码器RNN的输入是当前词元$y_{t}$的embedding $d$和上一时间步的隐状态$s_{t-1}$。在解码器RNN，初始隐状态$s_{0}=z=h_{T}$，即解码器初始隐状态就是编码器的最终隐状态。我们同样用一个公式表示该时间步解码器的操作：<br>$$s_{t}=DecoderRNN(d(y_{t},s_{t-1}))$$<br>在解码器中，我们需要将隐状态转换为对应的单词，因此在每一个时间步，我们通过一个线性层通过$s_{t}$去预测下一个在文本出现的单词$\overset{-}{y_{t}}$<br>$$\overset{-}{y_{t}}=f(s_{t})$$<br>解码器中的单词是随着时间步一个接一个地生成。我们通常使用&lt;bos&gt;作为解码器的第一个输入$y_{1}$，但是对于接下来的输入$y_{t&gt;1}$，我们有时使用在目标句子中下一个单词，有时也会使用经解码器预测的下一个单词$\overset{-}{y_{t}}$，这在机器翻译中被叫做teacher forcing。使用teacher-forcing，在训练过程中，可以加快模型的训练，使得模型会有较好的效果。但是在测试的时候因为不能得到目标句子的支持，存在训练测试偏差，模型会变得脆弱。<br>训练模型时，我们通常知道目标句子有多少单词，一旦解码器输入目标单词，模型就会停止生成单词。但在测试模型时，解码器会不断生成单词，直到模型输出&lt;eos&gt;或生成一定数量的单词之后，模型就停止生成单词。</eos></sos></p><p>一旦模型得到了预测目标句子$\overset{-}{Y}={\overset{-}{y_{1}},\overset{-}{y_{2}},…,\overset{-}{y_{t}}}$，我们将其和目标句子$Y={y_{1},y_{2},…,y_{t}}$进行比较，计算出误差，利用该误差就可以更新模型的所有参数。</p><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ul><li>将文本词元化，在机器翻译中我们更喜欢单词级词元化。对训练数据的文本序列进行词元，其中每个词元要么是一个词，要么是一个标点符号。</li><li>分别为源语言和目标语言构建两个字典——int2word 和 word2int （这两个字典将单词和整数一一对应）。同时为了减少数据噪声的影响，我们将出现次数少于2次的低频率词元视为未知 &lt;unk&gt; 词元。除此之外，我们还指定一些额外的特定词元，例如在小批量时用于将序列填充到相同长度的填充词元 &lt;pad&gt; ，以及序列的开始词元 &lt;bos&gt; 和结束词元 &lt;eos&gt; 。</li><li>为了提高计算效率，我们可以通过截断和填充方式实现每个序列都具有相同的长度。当文本序列词元数目少于规定数据时，我们将继续在其末尾添加特定的 &lt;pad&gt; 词元。反之，我们将截断文本序列，只取前指定数目个词元，丢弃剩余词元。</li></ul><h3 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h3><p>这一部分可以参考论文</p><img src="/2022/03/29/seq2seq/1.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>门控循环单元</title>
      <link href="/2022/03/25/men-kong-xun-huan-dan-yuan/"/>
      <url>/2022/03/25/men-kong-xun-huan-dan-yuan/</url>
      
        <content type="html"><![CDATA[<p>门控循环单元（gated recurrent units, GRU）于2014被Cho等人提出。GRU和LSTM一样有专门的机制来确定应该何时更新隐状态，以及应该何时重置隐状态，但GRU没有单独的存储单元，即LSTM的记忆元。GRU是LSTM的一个变体，它结构更加简单，却能够提供和LSTM同等的效果，并且计算的速度明显更快。</p><p>现在我们从GRU的内部结构开始解读：</p><h2 id="重置门和更新门"><a href="#重置门和更新门" class="headerlink" title="重置门和更新门"></a>重置门和更新门</h2><p>我们首先介绍重置门（reset gate）和更新门（update gate）。重置门控制着我们还想记住过去状态的数量；更新门决定着新状态保存旧状态信息的程度。这两个门的输入和LSTM一样，是当前时间步的输入和上一时间步的隐状态，它们的输出是由使用sigmoid激活函数的两个全连接层给出。因此它们的数学表达为：</p><p>$$R_{t}=\sigma({X_{t}W_{xr}+H_{t-1}W_{hr}+b_{r}})$$</p><p>$$Z_{t}=\sigma({X_{t}W_{xz}+H_{t-1}W_{hz}+b_{z}})$$</p><p>式中：$X_{t}\in R^{nxd}$是输入（样本个数：n，维度：d）；$H_{t-1}\in R^{nxh}$是上一时间步的隐状态；$R_{t}\in R^{nxd}$和$Z_{t}\in R^{nxd}$分别是重置门和更新门；$W_{xr},W_{xz}\in R^{dxh}$和$W_{hr},W_{hz}\in R^{hxh}$是权重参数，$b_{r},b_{z}\in R^{1xh}$是偏置项。</p><h2 id="候选隐状态"><a href="#候选隐状态" class="headerlink" title="候选隐状态"></a>候选隐状态</h2><p>候选隐状态（candidate hidden state）$\overset{-}{H_{t}}\in R^{nxh}$的计算公式如下：</p><p>$$\overset{-}{H_{t}}=tanh(X_{t}W_{xh}+(R_{t}\bigodot H_{t-1})W_{hh}+b_{h})$$</p><p>式中$W_{xh}\in R^{dxh}$和$W_{hh}\in R^{hxh}$是权重参数，$b_{h}\in R^{1xh}$是偏置项，符号$\bigodot$是Hadamard积（按元素乘积）运算符。</p><p>重置门$R_{t}$可以控制以往状态的影响程度， 当$R_{t}$中所有项接近1时，保留前一隐状态所有影响。当$R_{t}$中所有项接近0时，候选隐状态是以$X_{t}$作为输入的多层感知机的结果。</p><p>以上计算流程可以用下图表示：</p><img src="/2022/03/25/men-kong-xun-huan-dan-yuan/1.png" class=""><h2 id="隐状态"><a href="#隐状态" class="headerlink" title="隐状态"></a>隐状态</h2><p>隐状态$H_{t}\in R^{nxh}$通过更新门$Z_{t}$来确定它多大程度上来自与旧的状态$H_{t-1}$和当前候选状态$\overset{-}{H_{t}}$，它的具体公式为：</p><p>$$H_{t}=Z_{t}\bigodot H_{t-1}+(1-Z_{t})\bigodot \overset{-}{H_{t}}$$</p><p>每当更新门$Z_{t}$中所有项接近1时，模型就倾向于只保存旧状态。此时，来自$X_{t}$的信息基本上被忽略。相反，当$Z_{t}$中所有项接近0时，新的隐状态$H_{t}$就会接近候选隐状态$\overset{-}{H_{t}}$这些设计可以帮助我们处理循环神经⽹络中的梯度消失问题，并更好地捕获时间步距离很⻓的序列的依赖关系。 </p><p>此时GRU一个神经元一个完整的内部结构就可以用下图表示：</p><img src="/2022/03/25/men-kong-xun-huan-dan-yuan/2.png" class=""><p>用LSTM，我们最后将最新的隐状态作为输入进入另一个网络，则可实现分类或回归等模型。</p><h2 id="GRU网络代码"><a href="#GRU网络代码" class="headerlink" title="GRU网络代码"></a>GRU网络代码</h2><p>同LSTM我们可以调用pytorch里面的API实现一个简单的GRU网络</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">GRU_Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        embedding: 词典        embedding_dim: 词向量的维度        hidden_dim: GRU神经元个数        num_layers: GRU的层数        output_dim: 隐藏层输出的维度(分类的数量)        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU_Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 制作 embedding layer</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span>        <span class="token comment"># 如果 fix_embedding 为 False，在训练过程中，embedding 也会跟着被训练</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token keyword">if</span> fix_embedding <span class="token keyword">else</span> <span class="token boolean">True</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 句子最后时刻的hidden state</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用LSTM同样的例子，经过这个网络得出在验证集中准确率最高为0.9024，和LSTM模型的准确度差不多，但运行时间个人明显感觉短了很多。</p><h2 id="与LSTM间的异同"><a href="#与LSTM间的异同" class="headerlink" title="与LSTM间的异同"></a>与LSTM间的异同</h2><p>两者相似之处：引用了门结构，并在t-１时刻到ｔ时刻信息的传递引用了新的成分（候选隐状态，在LSTM中是记忆元），不再像传统RNN只利用了当前时刻的输入和上一时刻的隐状态。这个相同之处带来了两个好处：</p><p>①能够保存长期序列中的信息，且不会随时间而清除或因为与预测不相关而移除。</p><p>②有效创建了绕过多个时间步骤的快捷路径。这些捷径允许误差更容易反向传播，不至于像传统RNN那样迅速消散，从而解决了梯度消失的问题。</p><p>两者不同之处：</p><p>①对记忆内容传递程度的控制。LSTM用output gate控制传递程度，传递给下一个unit；而GRU是完全传递给下一个unit，不做任何控制。</p><p>②对候选内容的控制；LSTM计算候选记忆元不对上一信息做任何控制；而GRU计算候选隐状态时利用reset gate对上一时刻的信息进行控制。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1412.3555">Chung J, Gulcehre C, Cho K H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling[J]. arXiv preprint arXiv:1412.3555, 2014.</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>长短期记忆网络</title>
      <link href="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/"/>
      <url>/2022/03/22/chang-duan-qi-ji-yi-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p><strong>长短期记忆神经网路</strong>（long short-term memory，LSTM）是一种RNN特殊类型，现在我们见到的RNN模型除了特别强调，一般都是LSTM。LSTM的设计灵感来源于计算机的逻辑门，它引入了记忆元（memory cell），记忆元的作用是用于记录附加的信息。为了控制记忆元，我们需要许多门。其中一个门用来从单元中输出条目，我们将其称为输出门（output gate）。另一个门用来决定何时将数据读入单元，我们将其称为输入门（input gate）。我们还需要一个门来决定什么时候记忆或忽略隐状态中的输入，我们将其称为遗忘门（forget gate）。除此之外还有一个候选记忆元（candidate memory cell），它用来控制输入门的状态。现在让我们看看这在实践中是怎么运作的。<br>LSTM当前时间步的输⼊和前⼀个时间步的隐状态作为数据送⼊⻓短期记忆⽹络的⻔中，它们由三个具有sigmiod激活函数的全连接层处理，以计算输入门、输出门和遗忘门的值。候选记忆元的结构与前面三个门相似，只是使用tanh函数来作为激活函数。</p><img src="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/1.png" class=""><p>现在我们来细化一下长短期记忆网络的数学表达。假设输入为$X_{t}\in R^{nxd}$，隐藏单元的个数是h，则前一时间步的隐状态为$H_{t-1}\in R^{nxh}$。相应地，输入门是$I_{t}\in R^{nxh}$，遗忘门是$F_{t}\in R^{nxh}$，输出们是$O_{t}\in R^{nxh}$，候选记忆元是$\overset{-}{C_{t}}\in R^{nxh}$。它们的计算方法如下：<br>$$I_{t}=\sigma(X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i}),$$<br>$$F_{t}=\sigma(X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f}),$$<br>$$O_{t}=\sigma(X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o}),$$<br>$$\overset{-}{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c}),$$<br>式中$W_{xi},W_{xf},W_{xo},W_{xc}\in R^{dxh}$和$W_{hi},W_{hf},W_{ho},W_{hc}\in R^{hxh}$是权重参数，$b_{i},b_{f},b_{o},b_{c}\in R^{1xh}$是偏置参数。<br>在LSTM中，有两个来控制输入或遗忘：输入门$I_{t}$控制采用多少来自$\overset{-}{C_{t}}$的新数据，而遗忘门$F_{t}$控制保留多少过去的记忆元$C_{t-1}\in R^{nxh}$的内容。它们之间使用Hadamard积，有：<br>$$C_{t}=F_{t}\bigodot C_{t-1}+I_{t}\bigodot \overset{-}{C_{t}}$$<br>如果遗忘⻔始终为1且输⼊⻔始终为0，则过去的记忆元$C_{t}$将随时间被保存并传递到当前时间步。引⼊这种设计是为了缓解梯度消失问题，并更好地捕获序列中的⻓距离依赖关系。<br>现在，我们还需要定义如何计算隐状态$H_{t}\in R_{nxh}$，这就是输出门发挥作用的地方。在LSTM中，它将记忆元经过tanh激活函数，并于输出之间做Hadamard积：<br>$$H_{t}=O_{t}\bigodot tanh(C_{t})$$<br>这样我们就得到LSTM一个神经元完整的内部结构：</p><img src="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/2.png" class=""><p>最后只需将最新的隐状态作为输入经过另一个网络，则可实现分类或回归等模型。</p><p>这只是LSTM单个神经元的内部结构，而事实上LSTM可以将多层网络结构堆叠在一起，每层网络结构含有多个神经元结构。通过对几个层进行组合，我们就可以产生一个灵活的网络结构。</p><h2 id="LSTM应用"><a href="#LSTM应用" class="headerlink" title="LSTM应用"></a>LSTM应用</h2><p>现在我们以一个新闻标题分类的例子来实现LSTM，本次实验应用的是清华NLP组提供的THUCNews文本分类数据集，它包含十个新闻主题，分别是财经、房产、股票、教育、科技、社会、时政、体育、游戏。训练集中总共有180000条数据，每个类别有200000条数据。验证集中总共有10000条数据，每个类别有1000条数据。</p><h3 id="分词及去除停用词"><a href="#分词及去除停用词" class="headerlink" title="分词及去除停用词"></a>分词及去除停用词</h3><p>由于训练数据是中文，因此需要对文本进行分词处理，分词采用的是python中的jieba工具。同时为了减少停用词对文本有效信息造成噪音干扰，减少模型复杂程度，我们对文本进行去除停用词处理。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> jieba<span class="token keyword">import</span> os<span class="token keyword">import</span> re<span class="token comment"># 数据所在路径</span>data_dir <span class="token operator">=</span> <span class="token string">'E:\软件包\Chrome\机器学习数据\THUCNews'</span><span class="token comment"># 停用词表对应路径</span>stopwords_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'中文停用词库.txt'</span><span class="token punctuation">)</span><span class="token comment"># 将停用词转换为python列表</span>stopwords_list <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>stopwords_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 定义一个函数，用于对文本分词和去除停用词处理</span><span class="token keyword">def</span> <span class="token function">text_preprocessing</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 去除文本额外信息</span>    text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'(图)'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>    <span class="token comment"># 只保留数字、字母、中文</span>    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[^a-zA-Z0-9\u3002\uff1b\uff0c\uff1a\u201c\u201d\uff08\uff09\u3001\uff1f\u300a\u300b\u4e00-\u9fa5]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>    <span class="token comment"># 分词</span>    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span>word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> words <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords_list <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> text_list<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 把 training 时需要的资料读进来</span>    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>    lines <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    x <span class="token operator">=</span> <span class="token punctuation">[</span>text_preprocessing<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding</h3><p>这里采用的时gensim中word2vec的skip-gram，相关使用请看<a href="https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Text8Corpus">官网</a>，关于Gensim 4.0的相关更新请看<a href="https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4">这里</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec<span class="token keyword">def</span> <span class="token function">train_word2vec</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 训练 word to vector 的 word embedding</span>    model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>x<span class="token punctuation">,</span> vector_size<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> sg<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading training data ..."</span><span class="token punctuation">)</span>    train_x<span class="token punctuation">,</span> train_y <span class="token operator">=</span> load_data<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'train.txt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading testing data ..."</span><span class="token punctuation">)</span>    test_x<span class="token punctuation">,</span> test_y <span class="token operator">=</span> load_data<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'test.txt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># model</span>    model <span class="token operator">=</span> train_word2vec<span class="token punctuation">(</span>train_x <span class="token operator">+</span> test_x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"saving model ..."</span><span class="token punctuation">)</span>    save_path <span class="token operator">=</span> <span class="token string">'./logs/w2v.model'</span>    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>loading training data ...loading testing data ...saving model ...</code></pre><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">Preprocess</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentences<span class="token punctuation">,</span> sen_len<span class="token punctuation">,</span> w2v_path<span class="token operator">=</span><span class="token string">'w2v.model'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>w2v_path <span class="token operator">=</span> w2v_path        self<span class="token punctuation">.</span>sentences <span class="token operator">=</span> sentences        self<span class="token punctuation">.</span>sen_len <span class="token operator">=</span> sen_len        self<span class="token punctuation">.</span>idx2word <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>word2idx <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">get_w2v_model</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把之前训练好的 word to vector 模型读进来</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w2v_path<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>vector_size            <span class="token keyword">def</span> <span class="token function">add_embedding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把 word 加进 embedding，并赋予它一个随机生成的具有代表性的 vector</span>        <span class="token comment"># word 只会是 "&lt;PAD&gt;" 或 "&lt;UNK&gt;"</span>        vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>embedding_dim<span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>vector<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">,</span> vector<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">make_embedding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> load<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Get embedding ..."</span><span class="token punctuation">)</span>        <span class="token comment"># 取出训练好的 Word2vec word embedding</span>        <span class="token keyword">if</span> load<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading word to vec model ..."</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>get_w2v_model<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> NotImplementedError                <span class="token comment"># 制作一个 word2idx 的 dictionary</span>        <span class="token comment"># 制作一个 idx2word 的 list</span>        <span class="token comment"># 制作一个 word2vector 的 list</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>get_vector<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">)</span>        <span class="token comment"># 将 "&lt;PAD&gt;" 跟 "&lt;UNK&gt;" 加进 embedding 里面</span>        self<span class="token punctuation">.</span>add_embedding<span class="token punctuation">(</span><span class="token string">"&lt;PAD&gt;"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_embedding<span class="token punctuation">(</span><span class="token string">"&lt;UNK&gt;"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"total words: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>embedding_matrix        <span class="token keyword">def</span> <span class="token function">pad_sequence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 将每个句子变成一样的长度</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>sen_len<span class="token punctuation">:</span>            sentence <span class="token operator">=</span> sentence<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>sen_len<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            pad_len <span class="token operator">=</span> self<span class="token punctuation">.</span>sen_len <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pad_len<span class="token punctuation">)</span><span class="token punctuation">:</span>                sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span><span class="token string">"&lt;PAD&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>sen_len        <span class="token keyword">return</span> sentence        <span class="token keyword">def</span> <span class="token function">sentence_word2idx</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把句子里面的字转成对应的 index</span>        sentence_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> sen <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sentences<span class="token punctuation">)</span><span class="token punctuation">:</span>            sentence_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> word <span class="token keyword">in</span> sen<span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>word <span class="token keyword">in</span> self<span class="token punctuation">.</span>idx2word<span class="token punctuation">)</span><span class="token punctuation">:</span>                    sentence_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    sentence_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span><span class="token string">"&lt;UNK&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token comment"># 将每个句子变成一样的长度</span>            sentence_idx <span class="token operator">=</span> self<span class="token punctuation">.</span>pad_sequence<span class="token punctuation">(</span>sentence_idx<span class="token punctuation">)</span>            sentence_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence_idx<span class="token punctuation">)</span>        <span class="token keyword">return</span> sentence_list<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSTM_Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        embedding: 词典        embedding_dim: 词向量的维度        hidden_dim: GRU神经元个数        num_layers: GRU的层数        output_dim: 隐藏层输出的维度(分类的数量)        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM_Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 制作 embedding layer</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span>        <span class="token comment"># 如果 fix_embedding 为 False，在训练过程中，embedding 也会跟着被训练</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token keyword">if</span> fix_embedding <span class="token keyword">else</span> <span class="token boolean">True</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 句子最后时刻的hidden state</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>制作dataset以便dataloader能够使用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">class</span> <span class="token class-name">NewsTitleDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>在定义dataloder前我们先定义一些模型超参数，该参数可以自行调节</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sen_len <span class="token operator">=</span> <span class="token number">12</span>batch_size <span class="token operator">=</span> <span class="token number">128</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">0.001</span>train_preprocess <span class="token operator">=</span> Preprocess<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> sen_len<span class="token punctuation">,</span> w2v_path<span class="token operator">=</span>save_path<span class="token punctuation">)</span>embedding <span class="token operator">=</span> train_preprocess<span class="token punctuation">.</span>make_embedding<span class="token punctuation">(</span>load<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_x <span class="token operator">=</span> train_preprocess<span class="token punctuation">.</span>sentence_word2idx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 将 data 划分为 training data 和 validation data</span>X_train<span class="token punctuation">,</span> X_val<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_val <span class="token operator">=</span> train_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">180000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_x<span class="token punctuation">[</span><span class="token number">180000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">180000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token number">180000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 将 data 做成 dataset 供 dataloader 使用</span>train_dataset <span class="token operator">=</span> NewsTitleDataset<span class="token punctuation">(</span>X<span class="token operator">=</span>X_train<span class="token punctuation">,</span> y<span class="token operator">=</span>y_train<span class="token punctuation">)</span>val_dataset <span class="token operator">=</span> NewsTitleDataset<span class="token punctuation">(</span>X<span class="token operator">=</span>X_val<span class="token punctuation">,</span> y<span class="token operator">=</span>y_val<span class="token punctuation">)</span><span class="token comment"># 将 data 转成 batch of tensor</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Get embedding ...loading word to vec model ...total words: 30360</code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 加载模型</span>model <span class="token operator">=</span> LSTM_Net<span class="token punctuation">(</span>embedding<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># optimizer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment"># Training</span>best_acc <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    epoch_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    val_acc<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 训练模式</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 前向传播</span>        train_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 后向传播</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>train_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>           model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 评估模型</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>val_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            val_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>val_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                        val_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>val_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            val_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 展示结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>epoch_start_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> sec(s) Train Acc: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span>train_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span>train_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string"> | Val Acc: </span><span class="token interpolation"><span class="token punctuation">{</span>val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>val_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>        best_acc <span class="token operator">=</span> val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'./logs/lstm_cl.model'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'saving model with acc </span><span class="token interpolation"><span class="token punctuation">{</span>best_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Epoch [1/10] 12.5952 sec(s) Train Acc: 0.8458 Loss: 0.003683 | Val Acc: 0.8786 Loss: 0.003035saving model with acc 0.8786Epoch [2/10] 12.6020 sec(s) Train Acc: 0.8907 Loss: 0.002629 | Val Acc: 0.8906 Loss: 0.002654saving model with acc 0.8906Epoch [3/10] 12.5632 sec(s) Train Acc: 0.8991 Loss: 0.002396 | Val Acc: 0.8902 Loss: 0.002658Epoch [4/10] 12.5930 sec(s) Train Acc: 0.9050 Loss: 0.002251 | Val Acc: 0.8951 Loss: 0.002480saving model with acc 0.8951Epoch [5/10] 12.5931 sec(s) Train Acc: 0.9102 Loss: 0.002110 | Val Acc: 0.8978 Loss: 0.002456saving model with acc 0.8978Epoch [6/10] 12.7861 sec(s) Train Acc: 0.9154 Loss: 0.001967 | Val Acc: 0.8989 Loss: 0.002452saving model with acc 0.8989Epoch [7/10] 12.8262 sec(s) Train Acc: 0.9212 Loss: 0.001838 | Val Acc: 0.9004 Loss: 0.002465saving model with acc 0.9004Epoch [8/10] 12.7670 sec(s) Train Acc: 0.9252 Loss: 0.001716 | Val Acc: 0.9012 Loss: 0.002431saving model with acc 0.9012Epoch [9/10] 14.5936 sec(s) Train Acc: 0.9303 Loss: 0.001590 | Val Acc: 0.9006 Loss: 0.002502Epoch [10/10] 19.8384 sec(s) Train Acc: 0.9358 Loss: 0.001462 | Val Acc: 0.9018 Loss: 0.002567saving model with acc 0.9018</code></pre><p>经过10次迭代后，模型在验证集中的准确度达到0.9018，说明模型还不错，大家可以尝试改动模型参数，看看预测准确度会不会进一步提高。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>序列模型</title>
      <link href="/2022/03/20/xu-lie-mo-xing/"/>
      <url>/2022/03/20/xu-lie-mo-xing/</url>
      
        <content type="html"><![CDATA[<p>假设某个序列我们可以使用$x_{t-1},…,x_{t-\tau}$而不是$x_{t-1},…,x_{1}$来估计$x_{t}$，我们就说该序列满足马尔可夫条件。用数学公式表示为：<br>$$P(x_{1},…,x_{T})=\underset{t=1}{\overset{T}{\Pi}}P(x_{t}|x_{t-1},…,x_{t-\tau})$$<br>而$\tau=1$，我们就得到一个一阶马尔可夫模型，则上式变为：<br>$$P(x_{1},…,x_{T})=\underset{t=1}{\overset{T}{\Pi}}P(x_{t}|x_{t-1})$$<br>利用这一事实，我们只需要考虑过去观察中的一个非常短的历史：$P(x_{t}|x_{t-1},…,x_{1})=P(x_{t}|x_{t-1})$就能近似得出当前状态。</p><p>现在我们做一个简单的实验，来探讨一下满足马尔可夫条件的模型预测的准确性，以及它的最大预测能力。</p><h2 id="生成数据"><a href="#生成数据" class="headerlink" title="生成数据"></a>生成数据</h2><p>首先，我们生成一些数据：使用正弦函数和一些可加性噪声来生成序列模型，时间步长为1000。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchT <span class="token operator">=</span> <span class="token number">1000</span>    <span class="token comment"># 总共产生1000个点</span>time_epoch <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> T <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token number">0.01</span> <span class="token operator">*</span> time_epoch<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>绘制图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_3_1.png" class=""><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>接下来我们对序列进行一定的处理，使这个序列转换为模型的“特征-标签”对，这里我们使用的$\tau=4$，由于前4个数据没有历史数据来描述它们，因此我们将其舍去。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset<span class="token keyword">class</span> <span class="token class-name">DigitDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y    tau <span class="token operator">=</span> <span class="token number">4</span>features <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>T <span class="token operator">-</span> tau<span class="token punctuation">,</span> tau<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span>i<span class="token punctuation">:</span> T <span class="token operator">-</span> tau <span class="token operator">+</span> i<span class="token punctuation">]</span>labels <span class="token operator">=</span> y<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># print(features.shape, labels.shape)</span>batch_size<span class="token punctuation">,</span> n_train <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">600</span>          <span class="token comment"># 仅使用前600个数据进行模型训练</span>train_set <span class="token operator">=</span> DigitDataset<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train<span class="token punctuation">]</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><p>在这里我们构建一个十分简单的网络来训练模型：一个拥有两个全连接层的多层感知机，ReLU激活函数，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment"># 初始化网络权重参数</span><span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>设置超参数以及optimizer， criterion，并进行训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型</span>model <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token comment"># optimizer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment"># criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Training</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 前向传播</span>        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># 后向传播</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                total_loss <span class="token operator">+=</span> loss <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token comment"># 结果展示</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">] Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>total_loss <span class="token operator">/</span> n_train<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Epoch [1/10] Loss: 0.054475486278533936Epoch [2/10] Loss: 0.015365694649517536Epoch [3/10] Loss: 0.011502934619784355Epoch [4/10] Loss: 0.006994950119405985Epoch [5/10] Loss: 0.007959885522723198Epoch [6/10] Loss: 0.008115933276712894Epoch [7/10] Loss: 0.009392841719090939Epoch [8/10] Loss: 0.008084502071142197Epoch [9/10] Loss: 0.0074587250128388405Epoch [10/10] Loss: 0.006592489313334227</code></pre><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>由训练误差可知，模型运行的效果不错，现在让我们检验模型的预测能力，首先检验模型预测下一个时间步的能力</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">onestep_preds <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> onestep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">'r'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'1-step preds'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_11_1.png" class=""><p>由图可以看出。单步预测效果不错。即使预测的时间步超过了600+4（n_train + tau)，其预测结果看起来仍然不错。但如果数据观察序列只到了604，后面的都需要我们进行预测，那么这个模型的结果将会成为什么样子？还会有这么好的预测效果吗？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">multistep_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>T<span class="token punctuation">)</span>multistep_preds<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train <span class="token operator">+</span> tau<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train <span class="token operator">+</span> tau<span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_train <span class="token operator">+</span> tau<span class="token punctuation">,</span> T<span class="token punctuation">)</span><span class="token punctuation">:</span>    multistep_preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">(</span>multistep_preds<span class="token punctuation">[</span>i <span class="token operator">-</span> tau<span class="token punctuation">:</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># 绘图</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> onestep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> multistep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'1-step preds'</span><span class="token punctuation">,</span> <span class="token string">'multistep preds'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_13_1.png" class=""><p>由图可以看出绿线的预测显然不是很理想，经过几个预测步骤之后，预测的结果很快就会衰减到一个常数。这其实是错误累积的结果，因此后面误差会相当快地偏离真实的观测结果。<br>现在我们将预测步数分别设置为1，4，16，64，通过对比比较，看看k步预测的困难。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">max_steps <span class="token operator">=</span> <span class="token number">64</span>features <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>T <span class="token operator">-</span> tau <span class="token operator">-</span> max_steps <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> tau <span class="token operator">+</span> max_steps<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 列i（i&lt;tau）是来⾃x的观测，其时间步从（i+1）到（i+T-tau-max_steps+1）</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span>i <span class="token punctuation">:</span> T <span class="token operator">-</span> tau <span class="token operator">-</span>max_steps <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> i<span class="token punctuation">]</span><span class="token comment"># 列i（i&gt;=tau）是来⾃（i-tau+1）步的预测，其时间步从（i+1）到（i+T-tau-max_steps+1）</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">,</span> tau <span class="token operator">+</span> max_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i <span class="token operator">-</span> tau<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>steps <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token comment"># 绘图</span><span class="token keyword">for</span> i <span class="token keyword">in</span> steps<span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau <span class="token operator">+</span> i <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span> T <span class="token operator">-</span> max_steps <span class="token operator">+</span> i<span class="token punctuation">]</span> <span class="token punctuation">,</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> tau <span class="token operator">+</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">-step preds'</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> steps<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_15_1.png" class=""><p>以上例子清楚地说明随着预测步数的增加，预测的结果逐渐变坏。虽然“4步预测”看起来仍然不错，但超过这个跨度的任何预测几乎都是无用的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 序列模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据操作</title>
      <link href="/2022/03/18/shu-ju-cao-zuo/"/>
      <url>/2022/03/18/shu-ju-cao-zuo/</url>
      
        <content type="html"><![CDATA[<p>首先，我们介绍n维数组，也称为张量（tensor）。在python中数组通过调用Numpy计算包实现，但在pyTorch中为Tensor。虽然这两者相似，但Tensor比Numpy多一些重要的功能：①GPU算力比CPU高，而Numpy仅支持CPU计算；②Tensor类支持自动微分，更适合深度学习。</p><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><p>这节主要介绍一个基本数值计算工具torch的一些操作，首先我们导入torch，并使用arange创建一个行向量。这个⾏向量包含以0开始的前12个整数，它们默认创建为整数。张量中的每个值都称为张量的 元素（element）。例如，张量 x 中有 12 个元素。除⾮额外指定，新的张量将存储在内存中，并采⽤基于CPU的计算。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</code></pre><p>可以通过张量的shape属性来访问张量的形状。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>torch.Size([12])</code></pre><p>下面通过numel()函数获取张量中元素的数量</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>12</code></pre><p>在一些场景中，我们需要改变一个张量的形状而不改变元素数量和元素值，这可以通过reshape()函数实现。例如，可以把张量x从形状为(12,)的行向量转换为形状为(3,4)的矩阵。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11]])</code></pre><p>如果在改变张量形状前，我们知道目标矩阵的行数或列数，那么可以通过-1来调用reshape()函数自动计算出维度的功能。即我们可以⽤x.reshape(-1,4)或x.reshape(3,-1)来取x.reshape(3,4)。</p><p>有时，我们希望使⽤全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。我们可以创建⼀个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],        [[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]]])</code></pre><p>同样，我们可以创建⼀个形状为(2,3,4)的张量，其中所有元素都设置为1。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]],        [[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]]])</code></pre><p>有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值，可以通过randn()函数实现。如以下代码创建⼀个形状为（3,4）的张量，其中的每个元素都从均值为0、标准差为1的标准正态分布中随机采样。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[ 1.1445,  0.5344,  1.7990,  0.1128],        [-0.5328,  0.4657,  0.7276,  0.2435],        [ 0.0553,  0.2340,  0.8917, -0.5017]])</code></pre><p>我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[2, 1, 4, 3],        [1, 2, 3, 4],        [4, 3, 2, 1]])</code></pre><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><p>常⻅的标准算术运算符（+、 -、 *、 /和**），该运算符用于任意具有相同形状的张量间的计算。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x <span class="token operator">+</span> y<span class="token punctuation">,</span> x <span class="token operator">-</span> y<span class="token punctuation">,</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> x <span class="token operator">/</span> y<span class="token punctuation">,</span> x <span class="token operator">**</span> y <span class="token comment"># **运算符是求幂运算</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([ 3.,  4.,  6., 10.]), tensor([-1.,  0.,  2.,  6.]), tensor([ 2.,  4.,  8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1.,  4., 16., 64.]))</code></pre><p>“按元素”⽅式可以应⽤更多的计算，包括像求幂这样的⼀元运算符torch.exp(x)，求正弦值torch.sin(x)等等。</p><p>除按元素计算外，还可以执行线性代数运算，包括向量点积和矩阵乘法。我们也可以把多个张量连接（concatenate）在一起形成一个更大的张量。我们只需要提供张量列表，并给出沿哪个轴连接（沿行轴用dim=0，沿列轴用dim=1），这里需要注意张量的形状。下面我们用代码实现张量连接操作：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[ 0.,  1.,  2.,  3.],         [ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.],         [ 2.,  1.,  4.,  3.],         [ 1.,  2.,  3.,  4.],         [ 4.,  3.,  2.,  1.]]), tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</code></pre><p>通过sum()函数对张量中的所有元素进⾏求和，会产⽣⼀个单元素张量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(66.)</code></pre><h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p>在上⾯的部分中，我们看到了如何在相同形状的两个张量上执⾏按元素操作。在某些情况下，即使形状不同，我们仍然可以通过调⽤ ⼴播机制（broadcasting mechanism）来执⾏按元素操作。这种机制的⼯作⽅式如下：⾸先，通过适当复制元素来扩展⼀个或两个数组，以便在转换之后，两个张量具有相同的形状。其次，对⽣成的数组执⾏按元素操作。如下：a和b分别是3 × 1和1 × 2矩阵，如果让它们相加，它们的形状不匹配。我们将两个矩阵⼴播为⼀个更⼤的3 × 2矩阵，矩阵a将复制列，矩阵b将复制⾏，然后再按元素相加。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>a<span class="token punctuation">,</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[0],         [1],         [2]]), tensor([[0, 1]]))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">+</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[0, 1],        [1, 2],        [2, 3]])</code></pre><h2 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h2><p>就像python数组一样，张量中的元素可以通过索引访问。与python数组一样，张量中第一个元素的索引是0，最后一个元素的索引是-1。<br>如下所⽰，我们可以⽤[-1]选择最后⼀个元素，可以⽤[1:3]选择第⼆个和第三个元素（对于矩阵是默认对行进行操作）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor([ 8.,  9., 10., 11.]), tensor([[ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.]]))</code></pre><p>如果你想实现矩阵中列的索引，可以通过X[:, a:b]实现，同样对行索引可以通过X[a:b, :]实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor([[ 1.,  2.],         [ 5.,  6.],         [ 9., 10.]]), tensor([[ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.]]))</code></pre><p>除读取外，我们还可以通过指定索引来将元素写入矩阵</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">9</span>X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 0.,  1.,  2.,  3.],        [ 4.,  5.,  9.,  7.],        [ 8.,  9., 10., 11.]])</code></pre><h2 id="转换为其他python对象"><a href="#转换为其他python对象" class="headerlink" title="转换为其他python对象"></a>转换为其他python对象</h2><p>将深度学习框架定义的张量转换为Numpy很容易，反之也同样容易。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> X<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>B <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token builtin">type</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(numpy.ndarray, torch.Tensor)</code></pre><p>要将⼤小为1的张量转换为Python标量，我们可以调⽤item函数或Python的内置函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>a<span class="token punctuation">,</span> a<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>(tensor([3.5000]), 3.5, 3.5, 3)</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo插入图片</title>
      <link href="/2022/03/17/hexo-cha-ru-tu-pian/"/>
      <url>/2022/03/17/hexo-cha-ru-tu-pian/</url>
      
        <content type="html"><![CDATA[<h2 id="typora设置"><a href="#typora设置" class="headerlink" title="typora设置"></a>typora设置</h2><p>打开typora，选择：文件 - 偏好设置 - 图像 - 插入图片，做如下更改：</p><img src="/2022/03/17/hexo-cha-ru-tu-pian/image-20220331152841489.png" class=""><p>该设置会使得当你插入图片时，会生成一个和文件名相同的文件夹，并将图片存入这个文件夹内。</p><h2 id="Hexo设置"><a href="#Hexo设置" class="headerlink" title="Hexo设置"></a>Hexo设置</h2><ul><li>更换插件</li></ul><p>用插件 <code>Hexo-renderer-markdown-it</code> （推荐）代替 <code>Hexo-renderer-marked</code>，执行以下代码：</p><pre class="line-numbers language-none"><code class="language-none">npm uninstall hexo-renderer-marker --save  #卸载 markednpm install hexo-renderer-markdown-it --save  #安装markdown-it<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>更改根目录下的_config.yml 配置</li></ul><pre class="line-numbers language-none"><code class="language-none">post_asset_folder: true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>安装插件<code>hexo-image-link</code></li></ul><pre class="line-numbers language-none"><code class="language-none">npm install hexo-image-link --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该插件可以实现路径转换，假设：</p><p>文件名: <code>./test.md</code></p><p>图片路径: <code>./test/test.jpg</code></p><p>当插入图片 test.jpg 到 test.md 中时，typora 的引用路径为：</p><pre class="line-numbers language-none"><code class="language-none">![](test/test.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>而在Hexo发布后的引用路径为：</p><pre class="line-numbers language-none"><code class="language-none">![](test.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此，typora的md文件引入hexo时，应转换路径，即删掉图片路径中的 <code>"test/"</code>部分。若在md文件做上述操作，则md文件不能正常显示图片，而</p><p>hexo部署后可正常显示。为了书写方便，引入插件<code>hexo-image-link</code>即可帮助实现了这种路径转换。实现typora 文件中正常显示的图片，在hexo发布后依旧能正常显示。</p>]]></content>
      
      
      <categories>
          
          <category> 生命在于折腾 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生成式对抗网络</title>
      <link href="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/"/>
      <url>/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>GAN的全称为Generative Adversarial Network，翻译成中文就是生成式对抗网络。 在github有个<a href="https://github.com/hindupuravinash/the-gan-zoo">GAN Zoo</a>，它记录了GAN的发展并提供了相关GAN的论文来源和部分GAN模型的实现。下图为GAN的论文数量随时间的变化，由图可以看出自2014年第一篇GAN的论文问世，GAN的数量就以指数增长形式迅速壮大。虽然GAN的种类千变万化，但它们的结构类似，都含有一个生成器（generator）和一个判别器（discriminator）。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313134629440.jpg" class=""><p>判别器和生成器都是一个神经网络结构，也就是一个黑箱模型。判别器相对比较好理解，就像一个二分类模型，有一个判别界限去区分样本，从概率的角度分析就是获得样本x属于类别y的概率，是一个条件概率P(y|x)。而生成器是需要生成数据的概率分布，就像高斯分布一样，需要去拟合整个分布，从概率角度分析就是样本x在整个分布中对应的概率。</p><h1 id="GAN的相关理论"><a href="#GAN的相关理论" class="headerlink" title="GAN的相关理论"></a>GAN的相关理论</h1><p>GAN本质上是在做什么事情呢？</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313134650100.png" class=""><p>以图像生成为例，我们假设吧每一个图片看作二维空间中的一个点，并且现有图片会满足于某个数据分布，我们记作$P_{data}(x)$。那么在这个图像分布空间中，实际上只有很小一部分的区域是人脸图像。如上图所示，只有在蓝色区域采样出的点才会看起来像人脸，而在蓝色区域外采样出来的点就不是人脸。而在GAN中我们需要做的就是让机器找到人脸的分布函数，这也是GAN本质上做的事情。</p><h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p>如下图所示，我们需要训练出这样一个生成器，对于一个已知分布的数据z，我们可以通过生成器把数据转化成一个高维向量，它可以表示为一个图片、文本、声音等。只要我们随机输入多个z，就可以生成一个关于数据x的分布，我们把它称作$P_{G}(x)$。而真实数据也对应一个分布$P_{data}(x)$，生成器的目标是使$P_{G}(x)$和$P_{data}(x)$这两个分布越相似越好。我们知道对于回归和分类模型，都有对应的目标函数，我们只需使这个目标函数达到最优，即可得出一个比较好的回归或分类模型。那么对于两个分布，我们可以利用散度（Divergence，简称Div）这个评价指标来衡量两个分布之间的相似性。Div越小就表示两个分布越相似。那么我们可以将Div作为训练G的目标函数，我们的目标是使Div最小。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135023130.png" class=""><h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>现在有一个最关键的问题是，两个分布之间的Div要如何计算出来呢？理论上来说我们不知道$P_{G}(x)$和$P_{data}(x)$是什么，因此Div我们是无法计算的。因此我们需要构建一个新的网络，它的作用是衡量$P_{G}(x)$和$P_{data}(x)$之间的Div，因此我们有了这样一个网络——判别器。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135053706.png" class=""><p>图中，蓝色星星是从$P_{data}$（真实数据）中采样出的数据，黄色星星是从$P_{G}$（生成的数据）中采样出的数据，现在我们将这两组数据交给判别器，判别器的功能是判别读入的数据是来自$P_{data}$还是$P_{G}$。如果输入数据是$P_{data}$，那么经过判别器后就输出一个较大的值（可以近似理解为输出1）。如果输入数据是$P_{G}$，那么经过判别器后就输出一个较小的值（可以近似理解为输出0）。熟悉分类模型的同学可能就会说判别器不就相当于是一个二分类模型吗？而前面不是说我们是以Div的大小来判断两个分布之间的相似程度。现在我们就用公式推导出Div和二分类模型的目标函数之间的相关性。<br>我们先来看一下判别器的目标函数：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135121210.png" class=""><p>从式子本身理解的话，数据来源于$P_{data}$，D(x)要尽可能大，数据来源于$P_{G}$，D(x)要尽可能小。这样的话$V(G,D)$就越大。以最大化$V(G,D)$为目标函数，就可以使得输入数据是$P_{G}$，经过判别器后就输出一个较小的值，相反则输入一个较大的值。这样就达到了区分读入的数据是来自$P_{data}$还是$P_{G}$的目的。接下来我们将目标函数展开：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135206860.png" class=""><p>假设判别器十分强大，它模拟出的D(x)可以表示任何函数，给定一个x，都有一个D(x)使得表达式$P_{data}(x)logD(x)+P_{G}(x)log(1-D(x))$最大，求导令其为0可以得出：<br>$$D^{<em>}(x)=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}$$<br>现在把$D^{</em>}(x)$带入到目标函数中得到：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135318679.png" class=""><p>将表达式中分子分母都除于2可得：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135338407.png" class=""><p>这个表达式等价为：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135404583.png" class=""><p>至此我们可以得知通过一定的假设，得出散度的计算类似于二分类器的目标函数的计算。因此可以看出判别器的本质就是一个二分类器，这样就有利于我们后面代码的实现。<br>现在我们再回到生成器，生成器的目的是让生成数据$P_{G}$和真实数据$P_{data}$之间的Div最小，本来Div是没办法计算的，但是现在有了判别器之后，Div变得可以计算了，于是生成器新的目标函数变为：<br> $$G^{*}=arg\underset{G}{min}\underset{D}{V(G,D)}$$<br>至此，GAN就变成了一个求解最小最大值的问题，接下来就可以用最基本的梯度下降法求解这个问题。<br>下面我们用一个完整的伪算法来回顾一下GAN模型训练的整个流程。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135516142.png" class=""><p>这段伪代码的意思是，首先我们初始化生成器和判别器的参数，接下来规定一个总迭代次数，每轮训练的迭代次数也确定（这个根据数据量大小确定，一般是3-5次为一轮），在每轮训练中，我们先训练判别器，先从真实数据分布$P_{data}(x)$中抽样x，然后从先验分布中抽样z，并通过生成器产生数据$\overset{-}{x}$，接着把x和$\overset{-}{x}$丢入判别器中训练，使得目标函数$\overset{-}{V}$最大；接下来我们训练生成器，从先验分布中抽样新的z，接下来把z丢进生成器中训练，使得目标函数$\overset{-}{V}$最小，其实这一步就是让这一轮训练好的判别器认为生成器生成的是真实的数据。这样循环交替，最终生成器产生的数据$\overset{-}{x}$就会越来越接近真实数据x。</p><h2 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h2><p>这部分我将用GAN实现一个动画人脸的生成，利用的模型是DCGAN，它在原始GAN模型的基础上，将生成器和判别器的网络结构换成了当时已经十分成熟的卷积神经网络结构，并对卷积神经网络结构进行一定的调整，克服了原始GAN训练不稳定和梯度消失的问题。具体改变有：</p><ul><li><p>取消所有的pooling层。生成器中使用fractionally strided convolution代替pooling层，判别器中使用strided convolution代替pooling层。</p></li><li><p>在生成器和判别器中都使用批量标准化</p></li><li><p>去除了全连接层</p></li><li><p>生成器中使用ReLU作为激活函数，最后一层使用tanh激活函数</p></li><li><p>判别器中使用LeakyReLU作为激活函数<br>DCGAN的网络结构如下图所示：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135543883.png" class=""><p>现在让我们来实现这一部分，首先我们设置随机种子的个数（这部分直接复制粘贴就好)</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> random<span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来我们对图片数据进行处理，这里需要调用一些包</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> glob<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token comment"># DataSet</span><span class="token keyword">class</span> <span class="token class-name">AnimeDataSet</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fnames<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>fnames <span class="token operator">=</span> fnames        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fnames<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> self<span class="token punctuation">.</span>fnames<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token comment"># 加载图片</span>        img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>fname<span class="token punctuation">)</span>        <span class="token comment"># 使用transform对图片进行修改和归一化处理</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span class="token comment"># 获取数据</span>dataset_dir <span class="token operator">=</span> <span class="token string">r'E:\软件包\Chrome\机器学习数据\AnimeDataset\faces'</span>fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dataset_dir<span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 1. 修改图片尺寸为(64, 64)</span><span class="token comment"># 2. 将数值从 [0, 1] 线性映射到 [-1, 1]</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dataset <span class="token operator">=</span> AnimeDataSet<span class="token punctuation">(</span>fnames<span class="token punctuation">,</span>transform<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>展示一组图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltimages <span class="token operator">=</span> <span class="token punctuation">[</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_5_2.png" class=""><p>注意我们数据的范围是[-1,1]，因此我们需要将其转换为[0,1]，才能展示出正确的图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_7_1.png" class=""><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>现在实现模型的部分，这里实现的是DCGAN。下图为论文中DCGAN的模型架构，为了加快运行速度，我们起始为512，减少模型的参数，这一部分也可以自行修改</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token comment"># 模型参数初始化</span><span class="token keyword">def</span> <span class="token function">weights_init</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    classname <span class="token operator">=</span> m<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__    <span class="token keyword">if</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'Conv'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>  <span class="token comment"># 均值为0，标准差为0.02的正态分布</span>    <span class="token keyword">elif</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'BatchNorm'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>        m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>             <span class="token comment"># 均值为1，标准差为0.02的正态分布</span><span class="token comment"># 生成器</span><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">dconv_bn_relu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2_5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l2_5<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token keyword">return</span> y<span class="token comment"># 判别器</span><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">conv_bn_lrelu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ls <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>ls<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> y    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>设定好超参数，准备好dataloader，model，loss criterion，optimizer</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置一些超参数</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>z_dim <span class="token operator">=</span> <span class="token number">100</span>z_sample <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># 随机生成100个样本，用于检测模型的训练结果</span>lr <span class="token operator">=</span> <span class="token number">1e-4</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span><span class="token comment"># 生成一个文件目录，用于保存模型结果</span>save_dir <span class="token operator">=</span> <span class="token string">'./logs'</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># dataloader</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># model</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span>z_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>D <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>D<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># loss criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># optimizer</span>opt_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>opt_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        imgs <span class="token operator">=</span> data<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                bs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>                <span class="token triple-quoted-string string">"""训练D"""</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        g_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>                      <span class="token comment"># 生成的概率分布</span>        r_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 真实数据的概率分布</span>                <span class="token comment"># 对两种数据打标签，真实为1，生成的为0</span>        g_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        r_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 两种数据经过判别器</span>        g_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>g_imgs<span class="token punctuation">)</span>        r_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>r_imgs<span class="token punctuation">)</span>                <span class="token comment"># 计算D的loss</span>        g_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>g_logits<span class="token punctuation">,</span> g_label<span class="token punctuation">)</span>        r_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>r_logits<span class="token punctuation">,</span> r_label<span class="token punctuation">)</span>        loss_D <span class="token operator">=</span> <span class="token punctuation">(</span>g_loss <span class="token operator">+</span> r_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>                <span class="token comment"># 后向传播更新D的模型参数</span>        D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_D<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opt_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token triple-quoted-string string">"""训练G"""</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        g_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>                <span class="token comment"># 生成数据经过判别器</span>        g_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>g_imgs<span class="token punctuation">)</span>                <span class="token comment"># 计算loss</span>        loss_G <span class="token operator">=</span> criterion<span class="token punctuation">(</span>g_logits<span class="token punctuation">,</span> r_label<span class="token punctuation">)</span>     <span class="token comment"># 生成器的目的是生成和真实数据一样的分布，因此用的是r_label</span>                <span class="token comment"># 后向传播更新G的模型参数</span>        G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_G<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opt_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 打印当前模型训练的状态</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'\rEpoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> Loss_D: </span><span class="token interpolation"><span class="token punctuation">{</span>loss_D<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss_G: </span><span class="token interpolation"><span class="token punctuation">{</span>loss_G<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>    <span class="token comment"># 每进行一次epoch，生成一组图片，用于评估模型训练的情况</span>    G<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    g_imgs_sample <span class="token operator">=</span> <span class="token punctuation">(</span>G<span class="token punctuation">(</span>z_sample<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>    filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'Epoch_</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">03d</span><span class="token punctuation">}</span></span><span class="token string">.jpg'</span></span><span class="token punctuation">)</span>    torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>save_image<span class="token punctuation">(</span>g_imgs_sample<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f' | save samples to </span><span class="token interpolation"><span class="token punctuation">{</span>filename<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>        <span class="token comment"># 展示生成的图片</span>    grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>g_imgs_sample<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 将G转换成训练模型</span>    G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 模型保存</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>G<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'dcgan_g.pth'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>D<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'dcgan_d.pth'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">Epoch [1/10] 1115/1115 Loss_D: 0.1780 Loss_G: 3.8462 | save samples to ./logs\Epoch_001.jpg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_1.png" class=""><pre><code>Epoch [2/10] 1115/1115 Loss_D: 0.2923 Loss_G: 3.1647 | save samples to ./logs\Epoch_002.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_3.png" class=""><pre><code>Epoch [3/10] 1115/1115 Loss_D: 0.1190 Loss_G: 4.1651 | save samples to ./logs\Epoch_003.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_5.png" class=""><pre><code>Epoch [4/10] 1115/1115 Loss_D: 0.1803 Loss_G: 4.8173 | save samples to ./logs\Epoch_004.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_7.png" class=""><pre><code>Epoch [5/10] 1115/1115 Loss_D: 0.3816 Loss_G: 5.1071 | save samples to ./logs\Epoch_005.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_9.png" class=""><pre><code>Epoch [6/10] 1115/1115 Loss_D: 0.3021 Loss_G: 5.8084 | save samples to ./logs\Epoch_006.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_11.png" class=""><pre><code>Epoch [7/10] 1115/1115 Loss_D: 0.1996 Loss_G: 1.8779 | save samples to ./logs\Epoch_007.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_13.png" class=""><pre><code>Epoch [8/10] 1115/1115 Loss_D: 0.1340 Loss_G: 2.7159 | save samples to ./logs\Epoch_008.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_15.png" class=""><pre><code>Epoch [9/10] 1115/1115 Loss_D: 0.1774 Loss_G: 3.6487 | save samples to ./logs\Epoch_009.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_17.png" class=""><pre><code>Epoch [10/10] 1115/1115 Loss_D: 0.0604 Loss_G: 4.6149 | save samples to ./logs\Epoch_010.jpg</code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_13_19.png" class=""><p>现在我们就可以利用我们训练好的Generator来随机生成图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型加载</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span>z_dim<span class="token punctuation">)</span>G<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span><span class="token string">'dcgan_g.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>n_output <span class="token operator">=</span> <span class="token number">20</span>z_sample <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_output<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>imgs_sample <span class="token operator">=</span> <span class="token punctuation">(</span>G<span class="token punctuation">(</span>z_sample<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span>filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'result.jpg'</span></span><span class="token punctuation">)</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>save_image<span class="token punctuation">(</span>imgs_sample<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token comment"># show image</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>imgs_sample<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/output_15_0.png" class=""><p>虽然图中的动画人物看起来很怪，但也有几分和动画人物相似，并且有的已经非常像了。由于电脑原因，我只把n_epoch设置为10，如果将n_epoch设置大点，我想结果会好点。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1406.2661">Goodfellow, Ian, et al. “Generative adversarial nets.”Advances in neural information processing systems27 (2014).</a></p><p>[2] <a href="https://arxiv.org/abs/1511.06434">Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised representation learning with deep convolutional generative adversarial networks.”arXiv preprint arXiv:1511.06434(2015).</a></p><p>[3] <a href="https://www.youtube.com/watch?v=DMA4MrNieWo">李宏毅youtube课程</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
