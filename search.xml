<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>笔记五：Collection集合</title>
      <link href="/2022/08/06/bi-ji-wu-collection-ji-he/"/>
      <url>/2022/08/06/bi-ji-wu-collection-ji-he/</url>
      
        <content type="html"><![CDATA[<h2 id="集合">集合</h2><p>集合包含Collection集合和Map集合，Collection是单列集合，每个元素（数据）只包含一个值。Map是双列集合，每个元素包含两个值（键值对）。这里我们主要掌握<font color="Red">Collection集合体系的使用</font>。</p><h3 id="与数组之间的比较">与数组之间的比较</h3><ul><li>不像数组一样，集合的类型和长度都不固定</li><li>适合元素个数不确定，且需要做元素的增删操作的场景</li><li>集合提供的种类特别丰富，功能也是十分强大，开发中集合用的更多</li></ul><h3 id="Collection集合特点">Collection集合特点</h3><ul><li><p><font color="Red">List系列集合</font>：添加的元素是有序、可重复、有索引。</p><ul><li>如ArrayList、LinekdList ：有序、可重复、有索引。</li></ul></li><li><p><font color="Red">Set系列集合</font>：添加的元素是无序、不重复、无索引。</p><ul><li><p>HashSet: 无序、不重复、无索引；LinkedHashSet: <font color="Red">有序</font>、不重复、无索引。</p></li><li><p>TreeSet：<font color="Red">按照大小默认升序排序</font>、不重复、无索引。</p></li></ul></li></ul><p><strong>注意：</strong></p><ul><li>集合都是泛型的形式，可以在编译阶段约束集合只能操作某种数据类型</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> lists <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> lists <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// JDK 1.7开始后面的泛型类型申明可以省略不写</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>集合和泛型都只能支持<font color="Red">引用数据类型</font>，不支持基本数据类型，所以集合中存储的元素都认为是对象，如果集合中要存储基本数据类型，就必须使用包装类，也就是基本数据类型对应的引用数据类型</li></ul><h3 id="Collection常用API">Collection常用API</h3><table><thead><tr><th>方法名称</th><th>说明</th></tr></thead><tbody><tr><td>public  boolean add(E e)</td><td>把给定的对象添加到当前集合中</td></tr><tr><td>public  void clear()</td><td>清空集合中所有的元素</td></tr><tr><td>public  boolean remove(E e)</td><td>把给定的对象在当前集合中删除</td></tr><tr><td>public  boolean contains(Object obj)</td><td>判断当前集合中是否包含给定的对象</td></tr><tr><td>public  boolean isEmpty()</td><td>判断当前集合是否为空</td></tr><tr><td>public  int size()</td><td>返回集合中元素的个数。</td></tr><tr><td>public  Object[] toArray()</td><td>把集合中的元素，存储到数组中</td></tr></tbody></table><h3 id="Collection集合的遍历方式">Collection集合的遍历方式</h3><p>①<font color="Red">迭代器</font>遍历</p><ul><li>遍历就是一个一个的把容器中的元素访问一遍</li><li>迭代器在Java中的代表是<font color="Red">Iterator</font>，迭代器是集合的专用的遍历方式</li></ul><p>获取迭代器：<code>Iterator&lt;\E&gt;  iterator() </code>，  返回集合中的迭代器对象，该迭代器对象默认指向当前集合的0索引</p><p>Iterator中的常用方法：<code>boolean hasNext()</code>，询问当前位置是否有元素存在，存在返回true ，不存在返回false；<code>E next()</code>，获取当前位置的元素，并同时将迭代器对象移向下一个位置，注意防止取出越界，否则会出现<code>NoSuchElementException</code>异常</p><p>②<font color="Red">增强for循环</font>：既可以遍历集合也可以遍历数组</p><p>使用格式如下：</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">for(元素数据类型 变量名 : 数组或者Collection集合) {         //在此处使用变量即可，该变量就是元素}// 举例：Collection&lt;String&gt; list = new ArrayList&lt;&gt;();...for(String str : list) {    System.out.println(str);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>③<font color="Red">Lambda表达式</font>遍历集合</p><p>方法：<code>default void forEach(Consumer&lt;? super T&gt; action): </code>，结合Lambda遍历集合</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> lists <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>lists<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Consumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">accept</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 上面可以用Lambda表达式简化为：</span>lists<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>s <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 进一步可以简化为： </span>lists<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>s <span class="token operator">-&gt;</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Collection集合存储自定义类型的对象">Collection集合存储自定义类型的对象</h3><p>以一个电影对象为例子，代码如下：</p><p>①定义一个Movie类</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Movie</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">double</span> score<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> acotr<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">,</span> <span class="token keyword">double</span> score<span class="token punctuation">,</span> <span class="token class-name">String</span> acotr<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>score <span class="token operator">=</span> score<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>acotr <span class="token operator">=</span> acotr<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment">// ... getter + setter}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>②定义一个Movie类型的Collection集合，调用遍历方法</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Demo</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">Collection</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Movie</span><span class="token punctuation">&gt;</span></span> movies <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        movies<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span>“《肖生克的救赎》”<span class="token punctuation">,</span> <span class="token number">9.7</span> <span class="token punctuation">,</span>  “罗宾斯”<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        movies<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span>“《霸王别姬》”<span class="token punctuation">,</span> <span class="token number">9.6</span> <span class="token punctuation">,</span>  “张国荣、张丰毅”<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        movies<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span>“《阿甘正传》”<span class="token punctuation">,</span> <span class="token number">9.5</span> <span class="token punctuation">,</span>  “汤姆、汉克斯”<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Movie</span> movie <span class="token operator">:</span> movies<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"片名："</span> <span class="token operator">+</span> movie<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"评分："</span> <span class="token operator">+</span> movie<span class="token punctuation">.</span><span class="token function">getScore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"主演："</span> <span class="token operator">+</span> movie<span class="token punctuation">.</span><span class="token function">getAcotr</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据结构">数据结构</h2><p>**定义：**数据结构是<font color="Red">计算机底层存储、组织数据</font>的方式。是指数据相互之间是以什么方式排列在一起的。通常情况下，精心选择的数据结构可以带来更高的运行或者存储效率</p><p>**常见的数据结构：**栈、队列、数组、链表、二叉树、二叉查找树、平衡二叉树、红黑树…</p><ul><li>队列：先进先出，后进后出</li><li>栈：后进先出，先进后出</li><li>数组：内存连续区域，<font color="Red">查询快，增删慢</font></li><li>链表：元素是游离的，<font color="Red">查询慢，首尾操作极快</font></li><li>二叉树：永远只有一个根节点, 每个结点不超过2个子节点的树</li><li>查找二叉树：<font color="Red">小的左边，大的右边</font>，但是可能树很高，查询性能变差</li><li>平衡查找二叉树：让树的高度差不大于1，增删改查都提高了</li><li>红黑树（就是基于红黑规则实现了自平衡的排序二叉树）</li></ul><h2 id="List系列集合">List系列集合</h2><p>**特点：**ArrayList、LinekdList ：<font color="Red">有序，可重复，有索引</font></p><ul><li>ArrayList底层是基于<font color="Red">数组</font>实现的，查询元素快，增删相对慢</li><li>LinkedList底层基于<font color="Red">双链表</font>实现的，查询元素慢，增删首尾元素是非常快的</li></ul><p>**特有方法：**List集合因为支持索引，所以多了很多<font color="Red">索引操作的独特API</font>，其他Collection的功能List也都继承了</p><table><thead><tr><th>方法名称</th><th>说明</th></tr></thead><tbody><tr><td>void add(int  index,E element)</td><td>在此集合中的指定位置插入指定的元素</td></tr><tr><td>E remove(int  index)</td><td>删除指定索引处的元素，返回被删除的元素</td></tr><tr><td>E set(int index,E  element)</td><td>修改指定索引处的元素，返回被修改的元素</td></tr><tr><td>E get(int  index)</td><td>返回指定索引处的元素</td></tr></tbody></table><p><strong>注意：</strong></p><ul><li>由于List集合存在索引，因此List集合的遍历方式在Collection集合遍历方式的基础上多了<font color="Red">for循环</font></li><li>LinkedList集合由于底层数据结构是双链表，所以多了很多<font color="Red">首尾操作的特有API</font></li></ul><table><thead><tr><th>方法名称</th><th>说明</th></tr></thead><tbody><tr><td>public  void addFirst(E e)</td><td>在该列表开头插入指定的元素</td></tr><tr><td>public  void addLast(E e)</td><td>将指定的元素追加到此列表的末尾</td></tr><tr><td>public  E getFirst()</td><td>返回此列表中的第一个元素</td></tr><tr><td>public  E getLast()</td><td>返回此列表中的最后一个元素</td></tr><tr><td>public  E removeFirst()</td><td>从此列表中删除并返回第一个元素</td></tr><tr><td>public  E removeLast()</td><td>从此列表中删除并返回最后一个元素</td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>笔记四：包装类和Lambda表达式</title>
      <link href="/2022/07/20/bi-ji-si-bao-zhuang-lei-he-lambda-biao-da-shi/"/>
      <url>/2022/07/20/bi-ji-si-bao-zhuang-lei-he-lambda-biao-da-shi/</url>
      
        <content type="html"><![CDATA[<h2 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h2><h3 id="Date"><a href="#Date" class="headerlink" title="Date"></a>Date</h3><ul><li>Date类代表当前所在系统的日期时间信息</li></ul><p><strong>获取时间毫秒值</strong></p><ul><li><p>无参构造器：<code>public Date()</code>，创建一个Data对象，代表的是系统当前时刻的日期时间</p></li><li><p>调用方法：<code>public long getTime()</code>，返回从<font color="Red">1970年1月1日00:00:00</font>走到此刻的总的毫秒数</p></li></ul><p><strong>时间毫秒值到日期</strong></p><ul><li>有参构造器：<code>public Date(long time)</code>，把时间毫秒值转换成Date日期对象</li><li>使用无参构造器对象的方法：<code>public long setTime()</code>，设置日期对象的时间为当前时间毫秒值对应的时间</li></ul><h3 id="SimpleDateFormat"><a href="#SimpleDateFormat" class="headerlink" title="SimpleDateFormat"></a>SimpleDateFormat</h3><ul><li>代表简单日期格式化，可以用来把日期时间格式化成为我们想要的形式，也可以把字符串的时间形式解析成Date日期对象</li></ul><p><strong>格式化</strong></p><ul><li>构造器：<code>public SimpleDateFormat(String pattern)</code>，创建简单日期格式化对象，并封装格式化的形式信息，对应设置pattern的格式如下</li></ul><p><code>2020-11-11 13:27:06 </code>$\Rightarrow$<code>yyyy-MM-dd HH:mm:ss </code></p><p><code>2020年11月11日 13:27:06 </code>$\Rightarrow$<code>yyyy年MM月dd日 HH:mm:ss </code></p><ul><li>常用方法：①<code>public final String format(Date date)</code>，将日期格式化成日期/时间字符串；②<code>public final String format(Object time)</code>，将时间毫秒值格式化成日期/时间字符串</li></ul><p><strong>解析方法：</strong><code>public Date parse(String source)</code>，从给定字符串的开始解析文本以生成日期，字符串的格式要和定义的pattern相同，否则会报错</p><h3 id="Calendar"><a href="#Calendar" class="headerlink" title="Calendar"></a>Calendar</h3><p><strong>定义：</strong>Calendar代表了系统此刻日期对应的日历对象。Calendar是一个<font color="Red">抽象类</font>，不能直接创建对象。Calendar是可变日期对象，一旦修改后其对象本身表示的时间将产生变化</p><p><strong>创建日历对象的方法：</strong><code>public static Calendar getInstance()--&gt;Calendar cal = Calendar.getInstance()</code>，获取当前日历对象</p><p><strong>常用方法：</strong></p><table><thead><tr><th>方法名</th><th>说明</th></tr></thead><tbody><tr><td>public int get(int field)</td><td>取日期中的某个字段信息。</td></tr><tr><td>public void set(int field,int value)</td><td>修改日历的某个字段信息。</td></tr><tr><td>public void add(int field,int amount)</td><td>为某个字段增加/减少指定的值</td></tr><tr><td>public final Date getTime()</td><td>拿到此刻日期对象。</td></tr><tr><td>public long getTimeInMillis()</td><td>拿到此刻时间毫秒值</td></tr></tbody></table><h3 id="JDK8新增日期类"><a href="#JDK8新增日期类" class="headerlink" title="JDK8新增日期类"></a>JDK8新增日期类</h3><p>从<font color="Red">Java 8</font>开始，java.time包提供了新的日期和时间API，主要涉及的类型有以下几个，具体使用请查找Java API文档。</p><img src="/2022/07/20/bi-ji-si-bao-zhuang-lei-he-lambda-biao-da-shi/image-20220720104711148.png" class=""><p>新增的API严格区分了时刻、本地日期、本地时间，并且，对日期和时间进行运算更加方便。其次，新API的类型几乎全部是不变类型（和String的使用类似），可以放心使用不必担心被修改。</p><h2 id="包装类"><a href="#包装类" class="headerlink" title="包装类"></a>包装类</h2><p><strong>定义：</strong>包装类其实就是8种基本数据类型对应的引用数据类型</p><table><thead><tr><th>基本数据类型</th><th>引用数据类型</th></tr></thead><tbody><tr><td>byte</td><td>Byte</td></tr><tr><td>short</td><td>Short</td></tr><tr><td>int</td><td>Integer</td></tr><tr><td>long</td><td>Long</td></tr><tr><td>char</td><td>Character</td></tr><tr><td>float</td><td>Float</td></tr><tr><td>double</td><td>Double</td></tr><tr><td>boolean</td><td>Boolean</td></tr></tbody></table><p><strong>提供包装类的原因：</strong></p><ul><li><p>Java为了实现一切皆对象，为8种基本类型提供了对应的引用类型</p></li><li><p>后面的<font color="Red">集合和泛型</font>其实也只能支持包装类型，不支持基本数据类型</p></li></ul><p><strong>自动装箱：</strong>基本类型的数据和变量可以直接赋值给包装类型的变量</p><p><strong>自动拆箱：</strong>包装类型的变量可以直接赋值给基本数据类型的变量</p><p><strong>包装类特有功能：</strong>①包装类的变量的默认值可以是<font color="Red">null</font>，容错率更高。②可以把基本类型的数据转换成字符串类型(用处不大)。③可以把字符串类型的数值转换成真实的数据类型</p><ul><li><strong>方法：</strong>调用<code>toString()</code>方法得到字符串结果，也调用<code>Integer.toString(基本类型的数据)</code>；调用<code>Integer.parseInt()</code>得到“字符串类型的整数”；调用<code>Double.parseDouble()</code>得到“字符串类型的小数”。</li></ul><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p><strong>作用：</strong>可以用一些规定的字符来制定规则，并用来校验数据格式的合法性</p><p><strong>字符串对象提供了匹配正则表达式的方法：</strong><code>public boolean matches(String regex)</code>，判断是否匹配正则表达式，匹配返回true，不匹配返回false</p><p><strong>语法：</strong>这里就列举一些常用的，具体可以查看<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/regex/Pattern.html">API文档</a></p><table><thead><tr><th>字符</th><th>说明</th></tr></thead><tbody><tr><td>[abc]</td><td>只能是a, b, 或c</td></tr><tr><td>[^abc]</td><td>除了a, b, c之外的任何字符</td></tr><tr><td>[a-zA-Z]</td><td>a到z A到Z，包括（范围）</td></tr><tr><td>[a-d[m-p]]</td><td>a到d，或m通过p：（[a-dm-p]联合）</td></tr><tr><td>[a-z&amp;&amp;[def]]</td><td>d, e, 或f(交集)</td></tr><tr><td>[a-z&amp;&amp;[^bc]]</td><td>a到z，除了b和c</td></tr><tr><td>.</td><td>任何字符</td></tr><tr><td>\d</td><td>一个数字：[0-9]</td></tr><tr><td>\D</td><td>非数字：[^0-9]</td></tr><tr><td>\s</td><td>一个空白字符：[ \t\n\x0B\f\r]</td></tr><tr><td>\S</td><td>非空白字符：[^\s]</td></tr><tr><td>\w</td><td>[a-zA-Z_0-9] 英文、数字、下划线</td></tr><tr><td>\W</td><td>[^\w] 一个非单词字符</td></tr><tr><td>X?</td><td>X , 一次或根本不</td></tr><tr><td>X*</td><td>X，零次或多次</td></tr><tr><td>X+</td><td>X , 一次或多次</td></tr><tr><td>X {n}</td><td>X，正好n次</td></tr><tr><td>X {n, }</td><td>X，至少n次</td></tr><tr><td>X {n,m}</td><td>X，至少n但不超过m次</td></tr></tbody></table><p><strong>如：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">System.out.println("a".matches("[abc]"));    // trueSystem.out.println("z".matches("[abc]"));    // falseSystem.out.println("ab".matches("[abc]"));   // falseSystem.out.println("ab".matches("[abc]+"));  // true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>正则表达式在字符串方法中的使用：</strong></p><table><thead><tr><th align="left">方法名</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">public String replaceAll(String regex,String newStr)</td><td align="left">按照正则表达式匹配的内容进行替换</td></tr><tr><td align="left">public String[] split(String regex)：</td><td align="left">按照正则表达式匹配的内容进行分割字符串，反回一个字符串数组</td></tr></tbody></table><h2 id="Arrays类"><a href="#Arrays类" class="headerlink" title="Arrays类"></a>Arrays类</h2><p><strong>定义：</strong><font color="Red">数组操作工具类</font>，专门用于操作数组元素的</p><p><strong>Arrays类的常用API：</strong></p><table><thead><tr><th>方法名</th><th>说明</th></tr></thead><tbody><tr><td>public static String toString(类型[] a)</td><td>返回数组的内容（字符串形式）</td></tr><tr><td>public  static void sort(类型[] a)</td><td>对数组进行默认升序排序</td></tr><tr><td>public  static &lt;T&gt; void sort(类型[] a, Comparator&lt;?  super T&gt; c)</td><td>使用比较器对象自定义排序</td></tr><tr><td>public  static int binarySearch(int[] a,  int key)</td><td>二分搜索数组中的数据，存在返回索引，不存在返回-1，使用该方法数组需先排好序</td></tr></tbody></table><p><strong>自定义排序规则：</strong>设置Comparator接口对应的比较器对象，来定制比较规则</p><ul><li><p>如果认为左边数据 大于 右边数据 返回正整数</p></li><li><p>如果认为左边数据 小于 右边数据 返回负整数</p></li><li><p>如果认为左边数据 等于 右边数据 返回0</p></li></ul><h2 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h2><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p><strong>思想：</strong>每次依次从数组第一个位置开始比较，若当前位置大于后一个位置则交换数据，依次进行到后面，这样每次结束后都将最大值放到数组的后面去。</p><p><strong>规则：</strong>假定数组长度为n</p><ul><li>总共需要做多少轮：n-1</li><li>比较的总次数：$(n-1)+(n-2)+…+1=\frac{n(n-1)}{2}$</li></ul><img src="/2022/07/20/bi-ji-si-bao-zhuang-lei-he-lambda-biao-da-shi/image-20220720152813271.png" class=""><h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><p><strong>思想：</strong>每轮选择当前位置，开始找出后面的更小值与该位置交换</p><p><strong>规则：</strong>假定数组长度为n</p><ul><li>总共需要做多少轮：n-1</li><li>控制每轮从以前位置为基准，与后面元素选择几次</li></ul><img src="/2022/07/20/bi-ji-si-bao-zhuang-lei-he-lambda-biao-da-shi/image-20220720152832927.png" class=""><h3 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h3><p><strong>需求：</strong>用于数组元素的基本查询，查询数组中的元素在哪个索引</p><p><strong>规则：</strong></p><ul><li>二分查找性能好，二分查找的前提是必须是排好序的数据</li><li>二分查找相当于每次去掉一半的查找范围</li></ul><p><strong>实现步骤：</strong></p><ul><li><p>定义变量记录左边和右边位置。</p></li><li><p>使用while循环控制查询（条件是左边位置&lt;=右边位置）</p></li><li><p>循环内部获取中间元素索引</p></li><li><p>判断当前要找的元素如果大于中间元素，左边位置=中间索引+1</p></li><li><p>判断当前要找的元素如果小于中间元素，右边位置=中间索引-1</p></li><li><p>判断当前要找的元素如果等于中间元素，返回当前中间元素索引</p></li></ul><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p><strong>定义：</strong>Lambda表达式是JDK 8开始后的一种新语法形式</p><p><strong>作用：</strong>简化匿名内部类的代码写法</p><p><strong>简化格式：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">(匿名内部类被重写方法的形参列表) -&gt; {    被重写方法的方法体代码;}// 注：-&gt; 是语法形式，无实际含义<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong>Lambda表达式只能简化<font color="Red">函数式接口的匿名内部类的写法形式</font></p><p><strong>函数式接口：</strong>首先必须是<font color="Red">接口</font>，其次接口中有且仅有<font color="Red">一个抽象方法</font>的形式</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">public class LambdaDemo1 {    public static void main(String[] args) {                goSwimming( new Swimming() {            @Override            public void swim() {                System.out.println("铁汁, 我们去游泳吧~");            }        } );    }    public static void goSwimming(Swimming swimming) {        swimming.swim();    }}// 使用Lambda表达式之后，可以看出代码更少，关注点更加明确了public class LambdaDemo1 {    public static void main(String[] args) {                goSwimming( () -&gt; {System.out.println("铁汁, 我们去游泳吧~")         } );            }    public static void goSwimming(Swimming swimming) {        swimming.swim();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>进一步在Lambda表达式的基础上继续简化：</strong></p><ul><li><p><font color="Red">参数类型</font>可以省略不写。</p></li><li><p>如果只有一个参数，参数类型可以省略，同时()也可以省略。</p></li><li><p>如果Lambda表达式的方法体代码只有<font color="Red">一行代码</font>。可以省略大括号不写,同时要省略分号！</p></li><li><p>如果Lambda表达式的方法体代码只有<font color="Red">一行代码</font>。可以省略大括号不写。此时，如果这行代码是return语句，必须省略return不写，同时也必须省略”;”不写</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaSE进阶 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>笔记三：接口和内部类</title>
      <link href="/2022/07/20/bi-ji-san-jie-kou-he-nei-bu-lei/"/>
      <url>/2022/07/20/bi-ji-san-jie-kou-he-nei-bu-lei/</url>
      
        <content type="html"><![CDATA[<h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p><strong>定义：</strong>接口其实就是代码的一种规范。JDK8之前接口中只能是抽象方法和常量，没有其他成分了。接口不能实例化，接口中的成员都是public修饰，写不写都是，因为规范的目的是为了公开化。</p><p><strong>格式：</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 接口用关键字interface来定义</span><span class="token keyword">public</span> <span class="token keyword">interface</span> 接口名 <span class="token punctuation">{</span>       <span class="token comment">// 常量</span>       <span class="token comment">// 抽象方法</span><span class="token punctuation">}</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>用法：</strong>接口是用来被类实现（<code>implements</code>）的，实现接口的类称为<font color="Red">实现类</font>。实现类可以理解成所谓的子类。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 实现的关键字：implements</span>修饰符 <span class="token keyword">class</span> 实现类 <span class="token keyword">implements</span> 接口<span class="token number">1</span><span class="token punctuation">,</span> 接口<span class="token number">2</span><span class="token punctuation">,</span> 接口<span class="token number">3</span> <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">{</span>    <span class="token comment">// 重写抽象方法</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>从上面可以看出，接口可以被类单实现，也可以被类多实现，<font color="Red">接口不能创建对象</font></li></ul><p><strong>类、接口之间的关系：</strong></p><ul><li>类和类之间的关系：单继承</li><li>类和接口之间的关系：多实现</li><li><font color="Red">接口和接口之间的关系：多继承，一个接口可以同时继承多个接口</font></li></ul><p><strong>接口多继承的作用：</strong>规范合并，整合多个接口为同一个接口，便于子类实现</p><p><strong>JDK8开始接口新增的方法</strong></p><p><strong>作用：</strong>防止项目开发时需要对接口丰富，加入新的抽象方法。此时若没有新增的方法就要所有实现类实现这些方法，而引入新增的方法可以在丰富接口功能的同时又不对子类代码进行更改。</p><p><strong>默认方法</strong>：类似之前写的普通<font color="Red">实例方法</font>：必须用default修饰。默认会用public修饰，<font color="Red">需要用接口实现类的对象来调用</font></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">default void run(){    System.out.println("--开始跑--");}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>静态方法：</strong>默认会public修饰，必须static修饰。<font color="Red">接口的静态方法必须用本身的接口名来调用</font></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">inAddr</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"我们在学习Java!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>私有方法：</strong>私有的实例方法，必须用private修饰，从<font color="Red">JDK 1.9才开始有的</font>，只能<font color="Red">接口中</font>被其他默认方法或者私有方法访问。</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">private void go(){    System.out.println("--准备--");}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>JDK8新增的3种方法我们自己在开发中很少使用，通常是<font color="Red">Java源码</font>涉及到的，我们需要理解、识别语法、明白调用关系即可</p><p><strong>注意事项：</strong></p><ul><li>一个类实现接口，必须<font color="Red">重写</font>完全部接口的全部抽象方法，否则这个类需要定义成抽象类</li><li>一个类实现多个接口，多个接口的规范不能冲突</li><li>一个类实现多个接口，多个接口中有同样的静态方法不冲突。</li><li>一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用<font color="Red">父类</font>的。</li><li>一个类实现了多个接口，多个接口中存在同名的默认方法，可以不冲突，这个类重写该方法即可。</li><li>一个接口继承多个接口，是没有问题的，如果多个接口中存在<font color="Red">规范冲突</font>则不能多继承。</li></ul><h2 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h2><p><strong>定义：</strong>内部类就是定义在一个类里面的类，里面的类可以理解成”寄生“，外部类可以理解成”宿主“</p><p><strong>使用场景：</strong>当一个事物的内部还有一个部分需要一个完整的结构进行描述时</p><p><strong>基本作用：</strong></p><ul><li><p>内部类通常可以方便访问外部类的成员，包括私有的成员。</p></li><li><p>内部类提供了更好的封装性，内部类本身就可以用private ，protectecd等修饰，封装性可以做更多控制</p></li></ul><p><strong>类别：</strong>静态内部类、成员内部类、局部内部类、<font color="Red">匿名内部类（重点）</font></p><p><strong>静态内部类</strong></p><p><strong>定义：</strong>有static修饰，属于外部类本身。它的特点和使用与普通类是完全一样的，类有的成分他都有，只是位置在别人里面而已。</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">public class Outer{        // 静态成员内部类    public static class Inner{    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>创建对象的格式：</strong><code>外部类名.内部类名 对象名 = new 外部类名.内部类构造器();</code>如：<code>Outer.Inner in =  new Outer.Inner();</code></p><p><strong>注意：</strong></p><ul><li>静态内部类中<font color="Red">可以直接</font>访问外部类的静态成员，因为外部类的静态成员只有一份可以被共享访问。</li><li>但<font color="Red">不能直接访问外部类的实例成员</font>，因为外部类的实例成员必须用外部类的对象访问</li></ul><p><strong>成员内部类</strong></p><p><strong>定义：</strong>无static修饰，属于外部类的对象。JDK16之前，成员内部类中不能定义静态成员，JDK16开始也可以定义静态成员了。</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">public class Outer {    // 成员内部类    public class Inner {    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建对象的格式：<code>外部类名.内部类名 对象名 = new 外部类构造器.new 内部类构造器();</code>如：<code>Outer.Inner in =  new Outer().new Inner();</code></p><p><strong>注意：</strong></p><ul><li>成员内部类中<font color="Red">可以直接</font>访问外部类的静态成员，因为外部类的静态成员只有一份可以被共享访问。</li><li>成员内部类的实例方法中<font color="Red">也可以直接</font>访问外部类的实例成员，因为成员内部类必须先有外部类对象，才能有成员内部类对象，因此能访问。</li><li>在成员内部类中访问所在外部类对象，格式：<code>外部类名.this</code>，<font color="Red">如下面代码</font></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">People</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> heartbeat <span class="token operator">=</span> <span class="token number">150</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Heart</span><span class="token punctuation">{</span>        <span class="token keyword">private</span> <span class="token keyword">int</span> heartbeat <span class="token operator">=</span> <span class="token number">110</span><span class="token punctuation">;</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">int</span> heartbeat <span class="token operator">=</span> <span class="token number">78</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>heartbeat<span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token comment">// 78</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>heartbeat<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment">// 110</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">People</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span>heartbeat<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment">// 150</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>局部内部类：</strong>放在<font color="Red">方法、代码块、构造器等</font>执行体中。局部内部类的类文件名为：<code>外部类$N内部类.class</code></p><p><font color="Red"><strong>匿名内部类（重点）</strong></font></p><p><strong>定义：</strong>本质上是一个没有名字的局部内部类。</p><p><strong>作用：</strong>方便创建子类对象，最终目的是为了<font color="Red">简化代码编写</font></p><p><strong>格式：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">new 类|抽象类名|或者接口名() {    重写方法;};// 如：Employee a = new Employee() {    public void work() {    }};a. work();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>特点：</strong></p><ul><li><p>匿名内部类是一个没有名字的内部类，同时也代表一个<font color="Red">对象</font></p></li><li><p>匿名内部类产生的对象 类型，相当于是当前new类型的子类类型</p></li><li><p>匿名内部类通常是在开发中<font color="Red">调用别人的方法时，别人需要我们写的时候</font>才会定义出来使用</p></li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p><strong>定义：</strong>API的全称是Application Programming Interface，应用程序编程接口。其实就是Java写好的功能代码，可以直接调用</p><p><strong>Object类</strong></p><ul><li><p>一个类要么默认继承了Object类，要么间接继承了Object类，Object类是Java中的<font color="Red">祖宗类</font></p></li><li><p>Object作为所有类的父类，提供了很多常用的方法给每个子类对象拿来使用</p></li></ul><p><strong>常用方法：</strong></p><table><thead><tr><th align="left">方法名</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">public String toString()</td><td align="left">默认是返回当前对象在堆内存中的地址信息:类的全限名@内存地址</td></tr><tr><td align="left">public boolean equals(Object o)</td><td align="left">默认是比较当前对象与另一个对象的地址是否相同，相同返回true，不同返回false</td></tr></tbody></table><p><strong>注意：</strong></p><ul><li>父类toString()方法存在的意义就是为了被子类重写，以便返回对象的内容信息，而不是地址信息</li><li>父类equals()方法存在的意义也是为了被子类重写，以便子类自己来定制比较规则（如比较对象内容）</li></ul><p><strong>Objects</strong></p><ul><li>Objects是一个工具类，提供了一些方法去完成一些功能</li></ul><p><strong>常用方法：</strong></p><table><thead><tr><th>方法名</th><th>说明</th></tr></thead><tbody><tr><td>public  static boolean equals(Object a,  Object b)</td><td>比较两个对象的，底层会先进行非空判断，从而可以避免空指针异常。再进行equals比较</td></tr><tr><td>public  static boolean isNull(Object obj)</td><td>判断变量是否为null  ,为null返回true  ,反之</td></tr></tbody></table><p><strong>注意：</strong>官方在进行字符串比较时，没有用字符串对象的的equals方法，而是选择了Objects的equals方法来比较，因为<font color="Red">使用Objects的equals方法在进行对象的比较会更安全。</font></p><p><strong>StringBuilder</strong></p><ul><li>StringBuilder是一个可变的字符串的操作类，我们可以把它看成是一个对象容器</li><li>使用StringBuilder的核心作用：操作字符串的性能比String要更高（如拼接、修改等）</li><li>最终要用<code>toString()</code>方法转为String类型</li></ul><p><strong>构造器</strong></p><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>public  StringBuilder()</td><td>创建一个空白的可变的字符串对象，不包含任何内容</td></tr><tr><td>public  StringBuilder(String str)</td><td>创建一个指定字符串内容的可变字符串对象</td></tr></tbody></table><p><strong>常用方法</strong></p><table><thead><tr><th>方法名称</th><th>说明</th></tr></thead><tbody><tr><td>public StringBuilder append(任意类型)</td><td>添加数据并返回StringBuilder对象本身</td></tr><tr><td>public StringBuilder reverse()</td><td>将对象的内容反转</td></tr><tr><td>public int length()</td><td>返回对象内容长度</td></tr><tr><td>public String toString()</td><td>通过toString()就可以实现把StringBuilder转换为String</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> JavaSE进阶 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>笔记二：包和多态</title>
      <link href="/2022/07/18/bi-ji-er-bao-he-duo-tai/"/>
      <url>/2022/07/18/bi-ji-er-bao-he-duo-tai/</url>
      
        <content type="html"><![CDATA[<h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><p><strong>定义：</strong>包是用来分门别类的管理各种不同类的，类似于文件夹、建包利于程序的管理和维护。</p><ul><li><p>建包的语法格式：<code>package 公司域名倒写.技术名称</code>。包名建议全部英文小写，且具备意义</p></li><li><p>建包语句必须在第一行，一般IDEA工具会帮助创建</p></li><li><p>相同包下的类可以直接访问，不同包下的类必须导包，才可以使用！导包格式：<code>import 包名.类名</code>;</p></li><li><p>假如一个类中需要用到不同类，而这个两个类的名称是一样的，那么默认只能导入一个类，另一个类要带包名访问。</p></li></ul><h2 id="权限修饰符"><a href="#权限修饰符" class="headerlink" title="权限修饰符"></a>权限修饰符</h2><p><strong>定义：</strong>是用来控制一个成员能够被访问的范围。可以修饰成员变量，方法，构造器，内部类，不同权限修饰符修饰的成员能够被访问的范围将受到限制。</p><p><strong>分类和具体作用范围：</strong></p><table><thead><tr><th align="center"><strong>修饰符</strong></th><th align="center"><strong>同一 个类中</strong></th><th align="center"><strong>同一个包中其他类</strong></th><th align="center"><strong>不同包下的子类</strong></th><th align="center"><strong>不同包下的无关类</strong></th></tr></thead><tbody><tr><td align="center">private</td><td align="center">√</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">缺省</td><td align="center">√</td><td align="center">√</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">protected</td><td align="center">√</td><td align="center">√</td><td align="center">√</td><td align="center"></td></tr><tr><td align="center">public</td><td align="center">√</td><td align="center">√</td><td align="center">√</td><td align="center">√</td></tr></tbody></table><p><strong>自己定义成员（方法，成员变量，构造器等）一般需要满足如下要求：</strong></p><ul><li><p>成员变量一般私有，方法一般公开。</p></li><li><p>如果该成员只希望本类访问，使用private修饰。</p></li><li><p>如果该成员只希望本类，同一个包下的其他类和子类访问，使用protected修饰。</p></li></ul><h2 id="final"><a href="#final" class="headerlink" title="final"></a>final</h2><p><strong>作用：</strong></p><ul><li><p>final 关键字是最终的意思，可以修饰类、方法、变量。</p></li><li><p>修饰类：表明该类是最终类，<font color="Red">不能被继承</font>。</p></li><li><p>修饰方法：表明该方法是最终方法，<font color="Red">不能被重写</font>。</p></li><li><p>修饰变量：表示该变量第一次赋值后，<font color="Red">不能再次被赋值</font>(有且仅能被赋值一次)。</p></li></ul><p><strong>修饰变量需注意：</strong></p><ul><li>final修饰的变量是基本类型：那么变量存储的<font color="Red">数据值</font>不能发生改变。</li><li>final修饰的变量是引用类型：那么变量存储的<font color="Red">地址值</font>不能发生改变，但是地址指向的对象内容是可以发生变化的。</li></ul><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><p><strong>定义：</strong>常量是使用了<code>public static final</code>修饰的成员变量，必须有初始化值，而且执行的过程中其值不能被改变</p><p><strong>命名规范：</strong>英文单词全部大写，多个单词下划线连接起来</p><p><strong>作用：</strong><font color="Red">通常用来记录系统的配置数据</font></p><p><strong>常量做信息配置的原理、优势</strong></p><ul><li><p>在编译阶段会进行“宏替换”：把使用常量的地方全部替换成真实的字面量。</p></li><li><p>维护系统容易，可读性更好。</p></li></ul><h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><p>枚举是Java中的一种特殊类型</p><p><strong>作用：</strong>是为了做信息的标志和信息的分类</p><p><strong>格式：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">修饰符 enum 枚举名称{第一行都是罗列枚举类实例的名称;}// 如：enum Season{    SPRING, SUMMER, AUTUMN, WINTER;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>反编译后枚举的特征：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">Compiled from "Season.java"public final class Season extends java.lang.Enum&lt;Season&gt; {    public static final Season SPRING = new Season();    public static final Season SUMMER = new Season();    public static final Season AUTUMN = new Season();    public static final Season WINTER = new Season();    public static Season[] values();    public static Season valueOf(java.lang.String);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>特征：</strong></p><ul><li><p>枚举类都是继承了枚举类型：java.lang.Enum</p></li><li><p>枚举都是最终类，不可以被继承</p></li><li><p>构造器都是私有的，枚举对外不能创建对象</p></li><li><p>枚举类的第一行默认都是罗列枚举对象的名称的</p></li><li><p>枚举类相当于是多例模式</p></li></ul><h2 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h2><p><strong>定义：</strong>在Java中abstract是抽象的意思，可以修饰类、成员方法。<font color="Red">abstract</font>修饰类，这个类就是抽象类；修饰方法，这个方法就是抽象方法。</p><p><strong>格式：</strong></p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">修饰符 abstract class 类名{ 修饰符 abstract 返回值类型 方法名称(形参列表);}//如：public abstract class Animal{    public abstract void run();}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意事项：</strong></p><ul><li><p>抽象方法只有方法签名，不能声明方法体。</p></li><li><p>一个类中如果定义了抽象方法，这个类必须声明成抽象类，否则报错</p></li></ul><p><strong>使用场景：</strong></p><ul><li><p>抽象类可以理解成不完整的设计图，一般作为父类，让子类来继承。</p></li><li><p>当父类知道子类一定要完成某些行为，但是<font color="Red">每个子类该行为的实现又不同</font>，于是该父类就把该行为定义成抽象方法的形式，具体实现交给子类去完成。此时这个类就可以声明成抽象类。</p></li></ul><p><strong>特征：</strong></p><ul><li><p>类有的成员（成员变量、方法、构造器）抽象类都具备</p></li><li><p>抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类</p></li><li><p>一个类继承了抽象类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类。</p></li><li><p>不能用abstract修饰<font color="Red">变量、代码块、构造器</font>。</p></li><li><p><strong>最重要的特征：</strong>得到了抽象方法，失去了创建对象的能力</p></li></ul><p><strong>与final间：</strong></p><ul><li><p>abstract定义的抽象类作为模板让子类继承，final定义的类不能被继承。</p></li><li><p>抽象方法定义通用功能让子类重写，final定义的方法子类不能重写</p></li></ul><h2 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h2><p><strong>使用场景：</strong>当系统中出现同一功能多处在开发，而该功能中大部分代码是一样的，只有其中部分可能不同的时候</p><p><strong>实现步骤：</strong></p><p>①定义一个抽象类</p><p>②定义2个方法，一个是模板方法：把相同代码放里面去，不同代码定义成抽象方法</p><p>③子类继承抽象类，重写抽象方法。</p><p><strong>使用final修饰会更专业的原因：</strong></p><p>模板方法是给子类直接使用的，不是让子类重写的，一旦子类重写了模板方法，则模板方法就失效了，因此，加上final后可以防止子类重写了模板方法，这样更安全、专业。</p><h2 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h2><p><strong>定义：</strong>指对象可以有多种形态</p><p><strong>形式：</strong><code>父类类型 对象名称 = new 子类构造器;</code></p><p><strong>多态中成员访问特点：</strong></p><ul><li><p>方法调用：编译看左边，运行看右边。</p></li><li><p>变量调用：编译看左边，运行也看<font color="Red">左边</font>。</p></li></ul><p><strong>多态的前提：</strong>有继承/实现关系；有父类引用指向子类对象；<font color="Red">有方法重写</font>。</p><p><strong>优势：</strong></p><ul><li>在多态形式下，右边对象可以实现解耦合，便于扩展和维护</li><li>定义方法的时候，使用父类型作为参数，该方法就可以接收这父类的一切子类对象，体现出多态的扩展性与便利</li></ul><p><strong>劣势：</strong>多态下不能使用子类的独有功能</p><p><strong>类型转换问题：</strong></p><p>自动类型转换：从子到父，如：<code>Animal c = new Cat();</code></p><p>强制类型转换：从父到子，必须使用强制类型转换：<code>子类 对象变量 = (子类)父类类型的变量;</code></p><ul><li><strong>作用：</strong>可以解决多态下的劣势，可以实现调用子类独有的功能</li><li><strong>注意：</strong>有继承/实现关系的类就可以在编译阶段进行强制类型转换；但是，如果转型后的类型和对象真实对象的类型不是同一种类型，那么在运行代码时，就会出现ClassCastException，如：</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Animal</span> c <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Cat</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Dog</span> d <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">Dog</span><span class="token punctuation">)</span>c<span class="token punctuation">;</span> <span class="token comment">// 出现异常 ClassCastException</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li><font color="Red">Java建议强转转换前使用<code>instanceof</code>判断当前对象的真实类型，再进行强制转换</font></li></ul><p>如：<code>变量名 instanceof 真实类型</code>，判断关键字左边的变量指向的对象的真实类型，是否是<font color="Red">右边的类型或者是其子类类型</font>，是则返回true，反之返回false。</p>]]></content>
      
      
      <categories>
          
          <category> JavaSE进阶 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>笔记一：static和继承</title>
      <link href="/2022/07/14/bi-ji-yi-static-he-ji-cheng/"/>
      <url>/2022/07/14/bi-ji-yi-static-he-ji-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="static静态关键字"><a href="#static静态关键字" class="headerlink" title="static静态关键字"></a>static静态关键字</h2><h3 id="static"><a href="#static" class="headerlink" title="static"></a>static</h3><ul><li>static是静态的意思，可以修饰成员变量和成员方法</li><li>static修饰成员变量之后称为静态成员变量（类变量），修饰方法之后称为静态方法（类方法）</li><li>static修饰后的成员变量，可以<font color="Red">被类的所有对象共享</font>（访问、修改)。</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">User</span> <span class="token punctuation">{</span><span class="token keyword">static</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>成员变量的分类：</strong></p><ul><li>静态成员变量（有static修饰，属于类，内存中加载一次）：常表示如在线人数信息等需要被共享的信息，可以被共享访问</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">User</span><span class="token punctuation">{</span><span class="token comment">// 静态成员变量</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> onlineNumber <span class="token operator">=</span> <span class="token number">161</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>访问方式：①类名.静态成员变量（<font color="Red">推荐</font>） ②对象．静态成员变量（不推荐）</p><ul><li>实例成员变量（无static修饰，存在于每个对象中）：常表示姓名、年龄等属于每个对象的信息</li></ul><p>访问方式：对象.实例成员变量</p><p><strong>成员方法的分类：</strong></p><ul><li>静态成员方法（有static修饰，归属于类），<font color="Red">建议</font>用类名访问，也可以用对象访问</li><li>实例成员方法（无static修饰，归属于对象），只能用对象触发访问</li></ul><p><strong>注意：</strong></p><ul><li>同一个类中，访问静态变量和静态方法，类名可以<font color="Red">省略</font>不写</li><li>静态方法只能访问静态成员，不能直接访问实例成员</li><li>实例方法可以访问静态成员，也可以访问实例成员</li><li>静态方法不可以出现<font color="Red">this</font>关键字，this只能代表当前对象</li></ul><p><strong>两种方法的使用场景：</strong></p><ul><li>表示对象自己的行为的，且方法中需要访问实例成员的，则该方法必须申明成实例方法</li><li>如果该方法是以执行一个共用功能为目的，则可以申明成静态方法</li></ul><h3 id="static工具类"><a href="#static工具类" class="headerlink" title="static工具类"></a>static工具类</h3><p><strong>定义：</strong>类中都是一些静态方法，每个方法都是以完成一个共用的功能为目的，这个类用来给系统开发人员共同使用的。</p><p><strong>优点：</strong>使用工具类使得调用方便，还提高了代码复用。</p><ul><li><font color="Red">工具类的方法不用实例方法做</font>，这是因为实例方法需要创建对象调用，而工具类只是为了调用方法，创建对象只会浪费内存</li></ul><p><strong>要求：</strong>由于工具里面都是静态方法，直接用类名即可访问，因此，工具类无需创建对象，建议<font color="Red">将工具类的构造器进行私有</font></p><h3 id="static代码块"><a href="#static代码块" class="headerlink" title="static代码块"></a>static代码块</h3><p><strong>定义：</strong>代码块是类的5大成分之一（成员变量、构造器，方法，代码块，内部类），定义在类中方法外。在Java类下，使用 { } 括起来的代码被称为代码块 。</p><p><strong>分类：</strong></p><p><strong>①静态代码块：</strong></p><ul><li>格式：<code>static{}</code></li><li>特点：需要通过static关键字修饰，随着<font color="Red">类</font>的加载而加载，并且自动触发、只执行一次</li><li>使用场景：在类加载的时候做一些静态数据初始化的操作，以便后续使用。</li></ul><p><strong>②构造代码块（少见）：</strong></p><ul><li>格式：<code>{}</code></li><li>特点：每次创建对象，调用<font color="Red">构造器</font>执行时，都会执行该代码块中的代码，并且在构造器执行前执行</li><li>使用场景：初始化实例资源</li></ul><h3 id="static单例设计模式"><a href="#static单例设计模式" class="headerlink" title="static单例设计模式"></a>static单例设计模式</h3><p><strong>什么是设计模式（Design pattern）</strong></p><ul><li>开发中经常遇到一些问题，一个问题通常有n种解法的，但其中肯定有一种解法是最优的，这个最优的解法被人总结出来了，称之为设计模式</li><li>设计模式有20多种，对应20多种软件开发中会遇到的问题</li><li>学设计模式主要是学2点：①这种模式用来解决什么问题；②遇到这种问题了，该模式是怎么写的，他是如何解决这个问题的</li></ul><p><strong>单例模式</strong>：可以保证系统中，应用该模式的这个类永远只有一个实例，即一个类永远只能创建一个对象。如任务管理器对象我们只需要一个就可以解决问题了，这样可以节省内存空间。</p><ul><li><strong>分类：</strong>单例模式分为饿汉单例设计模式和懒汉单例设计模式</li></ul><p><strong>饿汉单例设计模式：</strong>在用类获取对象的时候，对象已经提前为你创建好了</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">/** a、定义一个单例类 */public class SingleInstance {      /** c.定义一个静态变量存储一个对象即可 :属于类，与类一起加载一次 */    public static SingleInstance instance = new SingleInstance ();        /** b.单例必须私有构造器*/    private SingleInstance (){        System.out.println("创建了一个对象");    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>懒汉单例设计模式：</strong>在真正需要该对象的时候，才去创建一个对象</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">/** 定义一个单例类 */class SingleInstance{    /** 定义一个静态变量存储一个对象即可 :属于类，与类一起加载一次 */    public static SingleInstance instance ; // null        /** 单例必须私有构造器*/    private SingleInstance(){}        /** 必须提供一个方法返回一个单例对象  */    public static SingleInstance getInstance(){        if(instance == null){            instance = new SingleInstance();        }        return instance;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><h3 id="什么是继承"><a href="#什么是继承" class="headerlink" title="什么是继承"></a>什么是继承</h3><p><strong>定义：</strong>Java中提供了一个关键词<font color="Red">extends</font>，用这个关键字，我们可以让一个类和另一个类建立起父子关系，如：</p><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">public class Student extends People {}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>代码中Student称为子类（派生类），People称为父类（基类）。这样书写的话，子类就可以直接使用父类公共的属性和方法，提高了代码的复用性。</p><p><strong>继承设计规范：</strong>子类们相同特征（共性属性，共性方法）放在父类中定义，子类独有的的属性和行为应该定义在子类自己里面。</p><p><strong>继承的特点：</strong></p><ul><li>子类可以继承父类的属性和行为，但是子类不能继承父类的构造器</li><li>Java是单继承模式：一个类只能继承一个直接父类</li><li>Java不支持多继承、但是支持多层继承</li><li>Java中所有的类都是Object类的子类</li></ul><p>在子类方法中访问成员满足：<font color="Red">就近原则</font>，即先子类局部范围找，再在子类成员范围找，最后在父类成员范围找，如果父类范围还没有找到则报错。</p><p>可以通过<font color="Red">super</font>关键字，指定访问父类的成员，格式：<code>super.父类成员变量/父类成员方法</code></p><h3 id="继承后方法重写"><a href="#继承后方法重写" class="headerlink" title="继承后方法重写"></a>继承后方法重写</h3><p><strong>定义</strong>：在继承体系中，子类出现了和父类中一模一样的方法声明，我们就称子类这个方法是重写的方法</p><p><strong>应用场景：</strong></p><ul><li>当子类需要父类的功能，但父类的该功能不完全满足自己的需求时</li><li>子类可以重写父类中的方法<code>super.父类成员方法</code></li></ul><p><strong>Override重写注释</strong></p><ul><li>@Override是放在重写后的方法上，作为重写是否正确的校验注解</li><li>加上该注解后如果重写错误，编译阶段会出现错误提示</li><li>建议重写方法都加<font color="Red">@Override</font>注解，代码安全，优雅！</li></ul><p><strong>方法重写注意事项和要求</strong></p><ul><li>重写方法的名称、形参列表必须与被重写方法的名称和参数列表<font color="Red">一致</font></li><li><font color="Red">私有方法以及静态方法</font>不能被重写</li><li>子类重写父类方法时，访问权限必须大于或者等于父类 （暂时了解 ：缺省 &lt; protected &lt; public）</li></ul><h3 id="继承后子类构造器的特点"><a href="#继承后子类构造器的特点" class="headerlink" title="继承后子类构造器的特点"></a>继承后子类构造器的特点</h3><p>子类中所有的构造器默认都会先访问父类中无参的构造器，再执行自己。这是因为:</p><ul><li>子类在初始化的时候，有可能会使用到父类中的数据，如果父类没有完成初始化，子类将无法使用父类的数据</li><li>子类初始化之前，一定要调用父类构造器先完成父类数据空间的初始化</li><li>在代码中，子类构造器的第一行语句默认都是：<code>super()</code>，不写也存在</li></ul><p><strong><code>super</code>调用父类有参数构造器的作用</strong>：初始化继承自父类的数据</p><ul><li><p>如果父类中没有无参数构造器，只有有参构造器，会报错，这是因为子类默认的是调用父类无参构造器。</p></li><li><p>子类构造器中可以通过书写<code>super(...)</code>，自动调用父类的有参数构造器</p></li></ul><h3 id="this和super"><a href="#this和super" class="headerlink" title="this和super"></a>this和super</h3><ul><li>this代表本类对象的引用；super代表父类存储空间的标识</li></ul><table><thead><tr><th><strong>关键字</strong></th><th><strong>访问成员变量</strong></th><th><strong>访问成员方法</strong></th><th><strong>访问构造方法</strong></th></tr></thead><tbody><tr><td><strong>this</strong></td><td>this.成员变量  访问本类成员变量</td><td>this.成员方法(…)  访问本类成员方法</td><td>this(…) 访问本类构造器</td></tr><tr><td><strong>super</strong></td><td>super.成员变量  访问父类成员变量</td><td>super.成员方法(…)  访问父类成员方法</td><td>super(…)  访问父类构造器</td></tr></tbody></table><p><strong>使用注意点：</strong></p><ul><li>子类通过 this (…）去调用本类的其他构造器，本类其他构造器会通过 super 去手动调用父类的构造器，最终还是会调用父类构造器的</li><li>注意：this(…) super(…) 都只能放在构造器的<code>第一行</code>，所以二者不能共存在同一个构造器中</li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaSE进阶 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> static </tag>
            
            <tag> 继承 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN_GP</title>
      <link href="/2022/07/14/wgan-gp/"/>
      <url>/2022/07/14/wgan-gp/</url>
      
        <content type="html"><![CDATA[<img src="/2022/07/14/wgan-gp/image-20220714084905587-16577679352952.png" class=""><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>GAN是强大的生成模型，但是以难训练著称。前面一篇文章讲到的 WGAN 提升了 GAN 训练的稳定性，但有时候还是会产生不好的样本或收敛失败。在原始 WGAN 论文中，作者也提到了，这些问题主要是在判别器中使用 weight clipping 技术来实现 Lipschitz 限制导致的，特别是当超参数 c 没有设置合适。</p><p>$$w\leftarrow clip(w,-c,c)$$</p><p>WGAN 模型的性能对超参数 c 特别敏感。下图中，当判别器中没有使用批量标准化，c 从0.001增加到0.1，判别器从梯度消失转为梯度爆炸。</p><img src="/2022/07/14/wgan-gp/image-20220714091239852-16577679352953.png" class=""><p>同时作者还证明了 weight clipping 降低了模型的表现能力并且限制了模型模拟复杂函数的能力。在下面的实验中，第一行是由 WGAN 估计的判别器值等高线图，第二行是由 WGAN 的一个变体估计的，即本文提出的方法WGAN_GP。从图中可以看出，WGAN 不能创造一个复杂的边界来包围模型的模式（橙色点），只是对最优函数进行了非常简单的近似模拟，而改进的 WGAN_GP 可以。</p><img src="/2022/07/14/wgan-gp/image-20220714093217526-16577679352964.png" class=""><h2 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN_GP"></a>WGAN_GP</h2><p>WGAN_GP使用梯度惩罚（gradient penalty）而不是 weight clipping 来实现 Lipschitz 限制：</p><p>$$|f(x_1)-f(x_2)|\leq K|x_1-x_2|$$</p><p><strong>梯度惩罚</strong></p><p>可微函数 1-Lipschtiz 在任何地方都有范数最多为1的梯度</p><img src="/2022/07/14/wgan-gp/image-20220714094908951-16577679352966.png" class=""><p>作者在论文中的附录 A 证明了命题1，感兴趣的可以看一下。论文连接：<a href="http://arxiv.org/abs/1704.00028">WGAN_GP</a></p><p>这个命题指出在真实数据和生成数据之间的插值点会有一个函数$f^{*}$的梯度规范为1。因此 WGAN_GP 使用的不是weight clipping，而是当其梯度规范偏离其目标规范值时对模型进行惩罚。WGAN_GP 的目标函数为：</p><img src="/2022/07/14/wgan-gp/image-20220714095809861-16577679352965.png" class=""><p>式中$\overset{\wedge}{x}=t\overset{\sim}{x}+(1-t)x,0\leq t\leq 1$，t是随机采样出来的；论文中，$\lambda$设置为10。</p><p>批量标准化禁止在判别器中使用，因为批量标准化会在相同批量的样本中建立联系，使得判别器从单一输入到单一输出的映射变成了从整批输入到整批输出的映射，而 WGAN_GP 惩罚的是判别器相对于每个输入的梯度规范，而不是整个批次，使用批量标准化会影响梯度惩罚的效率。</p><p>不可否认，引入梯度惩罚会增加计算成本，这可能并不是最优的选择，但作者通过实验证明 WGAN_GP 确实产生了一些更高质量的图像。</p><p><strong>算法</strong></p><p>有了前面的基础，限制让我们细看 WGAN_GP 算法的细节和梯度惩罚是怎样计算的。</p><img src="/2022/07/14/wgan-gp/image-20220714103234274-16577679352967.png" class=""><p>与 WGAN 的算法进行对比，有两点不同：①使用了梯度惩罚，而不是 weight clipping；②使用了 Adam 优化算法，而不是 RMSProp 优化算法。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>WGAN_GP 增强了训练的稳定性，如下图所示，当模型设计不是最优时，WGAN_GP 仍然可以生成高质量的图片，而反观其他模型，生成的可能就是一堆噪音。</p><img src="/2022/07/14/wgan-gp/image-20220714103953609-16577679352968.png" class=""><p>下面是使用不同方法在 CIFAR-10 数据集上 Inception score 随生成器迭代次数的变化曲线。从图中可以看出，相对于 WGAN，WGAN_GP 收敛速度更快，且可以生成更高质量的图片，且使用 Adam 优化算法可以进一步提升模型的性能；相比于 DCGAN， WGAN_GP 收敛的慢些，但 Inception score 的收敛过程更加稳定。</p><img src="/2022/07/14/wgan-gp/image-20220714104944679-16577679352969.png" class=""><p>这是否就意味着 DCGAN 比 WGAN_GP 性能好？其实不然，WGAN_GP 的主要优势是它可以使训练更加稳定，使得模型更容易训练成功。为了验证 WGAN_GP 有助于模型收敛的更好，作者使用更加复杂的模型——深度残差网络作为生成器和判别器。下图就是不同模型在 LSUN 数据集上 Inception score 的结果，Inception score 越高，表示模型越好。</p><img src="/2022/07/14/wgan-gp/image-20220714105902203-16577679352951.png" class="">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> WGAN_GP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN</title>
      <link href="/2022/07/08/wgan/"/>
      <url>/2022/07/08/wgan/</url>
      
        <content type="html"><![CDATA[<img src="/2022/07/08/wgan/image-20220708100202682.png" class=""><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>GAN以难训练而著称，在训练的过程中，模型没有收敛或者模型崩了是很常见的事。GAN通过生成器和判别器之间的对抗作用，使得生成器不断生成和原始数据概率分布相似的数据，从而达到以假乱真的目的。那怎样去学一个概率分布？从数学的角度就是学习一个概率密度函数，这个函数可以使得以下数学式在真实数据中最大（这和最大似然估计很相似）。下式中，$x^{(i)}$是真实的数据，<em>P</em>是概率密度函数</p><p>$$\underset{\theta \in R^{d}}{max}\frac{1}{m}\sum_{i=1}^{m}logP_{\theta}(x^{(i)})$$</p><p>如果我们知道真实数据的分布$P_{r}$和生成数据的分布$P_{g}$，那么我们只需最小化 <em><strong>KL</strong></em> 散度$KL(P_{r}||P_{g})$就可以使这两个分布相似，原始的GAN在KL散度这个评价标准做一定的推导进而得出训练原始GAN的损失函数 <em><strong>JS</strong></em> 散度，有关推导看<a href="http://arxiv.org/abs/1406.2661">这篇论文</a>。但 <em><strong>JS</strong></em> 散度存在一个问题，真实数据$P_{r}$和生成数据$P_{g}$没有数据重叠的话，不管真实数据和生成数据之间的距离多远， <em><strong>JS</strong></em> 散度计算出来的值都是log2，这就造成了梯度消失的问题。以图像生成为例，图像是一个高维数据，真实数据的分布在这个高维空间中占据很小一部分，这就很难使两个分布有重叠部分，GAN也就很难训练。</p><p>因此，在这篇论文中，作者的着力点是怎样判断生成数据和真实数据两者的分布相似，换言之，怎样计算两个分布之间的距离，从而由这个距离得出新的损失函数来训练GAN。作者应用的是Wasserstein Distance，因此命名为Wasserstein GAN，即WGAN。初看 Wasserstein Distance 的公式，会觉得这根本就不是我能够学的。事实上，它们并不难，接下来我会用例子去解释它们。</p><h2 id="EM距离"><a href="#EM距离" class="headerlink" title="EM距离"></a>EM距离</h2><p>假设我们将分布P视为一堆土，而另一个分布Q视为它的目标。那么P和Q之间的EM距离（Earth Mover distance）是推土机将土堆P转换为土堆Q所消耗的最小成本。这样讲可能会很抽象，下面我将例举李宏毅老师课堂上的一个例子，来看EM距离是如何计算的。</p><img src="/2022/07/08/wgan/image-20220708161212421.png" class=""><p>以上P和Q为两个分布，为了方便理解，我们可以将其看成两个土堆，同时你开着一个推土机。我想你有很多办法将P变成Q，那么你怎样操作会使消耗的功最小呢？</p><img src="/2022/07/08/wgan/image-20220708163129472.png" class=""><p>现在我们将其定义为一个数学问题，你“移动的计划”可以看成是一个矩阵，矩阵中每个位置的值可以看成你从土堆P的对应位置移动到土堆Q对应位置的土堆的重量。则移动计划$\gamma$的平均距离可以定义为</p><p>$$B(\gamma)=\underset{x_{p},x_{q}}{\sum}\gamma(x_{p},x_{q})||x_{p}-x_{q}||$$</p><p>式中，$x_{p},x_{q}$可以近似看成上图中矩阵对应的位置；$\gamma(\cdot)$表示移动的高度，也就是上面说的移动土的重量；$||\cdot||$表示两个位置对应坐标下的距离。</p><p>因此P和Q之间的EM距离可以看成求解下述问题得到最优解对应的，式中$\Pi$是所有可能的“移动计划”。</p><p>$$W(P,Q)=\underset{\gamma \in \Pi}{min}B(r)$$</p><p>以上述P和Q为例，它们的最佳“移动计划”如下图所示：</p><img src="/2022/07/08/wgan/image-20220708165227081.png" class=""><p>这篇论文第二章节用一个例子证明EM距离如何使得它收敛于一个简单的分布，而KL散度和JS散度是如何发散或者不收敛，具体可以查看<a href="http://arxiv.org/abs/1701.07875">原论文</a></p><h2 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h2><p>WGAN提出了一个新的成本函数，即使用Wasserstein距离，在任何地方都拥有一个更平滑的梯度。下图是GAN和WGAN的D(x)值的图，红线是GAN的，它充满了梯度消失或爆炸的区域。而相对于蓝线的WGAN，梯度在任何地方都比较平滑，即使生成器没有产生好的图像，也能够学习。</p><img src="/2022/07/08/wgan/image-20220708181906988.png" class=""><p>然而，Wasserstein距离的方程式是非常难解的。利用Kantorovich-Rubinstein duality，我们将其简化为</p><img src="/2022/07/08/wgan/image-20220708182718650.png" class=""><p>其中sup是最小的上界，<em>f</em>是一个遵循下面约束的1-Lipschitz函数</p><p>$$|f(x_1)-f(x_2)|\leq|x_1-x_2|$$</p><p>所以要想计算Wasserstein距离，我们还需找到一个1-Lipschitz函数。像其他深度学习问题，我们可以构建一个深度网络去学习这个函数，这个网络可以用判别器D实现，只不过最后一层不通过sigmoid函数，输出的是一些数值而不是一个概率值，这个数值可以理解为输出的图片有多真实。</p><p>WGAN和GAN在网络结构上设计几乎是一样的，不同点就是WGAN的判别器最后一层没有经过sigmoid函数。它们主要的区别主要是体现在损失函数上：</p><img src="/2022/07/08/wgan/image-20220708185201931.png" class=""><p>这里损失函数中f是一个1-Lipschitz函数，为例实现这一约束，WGAN使用了一个非常简单的技术——weight clipping，即将判别器的权重由超参数c控制，有了这些知识我们就能看懂论文中WGAN的算法：</p><img src="/2022/07/08/wgan/image-20220708185137888.png" class=""><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>损失指标与图像质量之间的关系</strong></p><p>在GAN中，损失衡量的是它对判别器的欺骗程度，而不是对图像质量的衡量。如下图所示，前面两个图使用正常GAN的训练算法，后面一张图使用WGAN训练算法。从中可以看出即使图像质量提高了，GAN中的生成器损失值也不会下降。因此，我们无法通过损失值来看出训练的进展（我们通常是展示训练过程生成的图像，然后通过我们的视觉来评价模型训练进程）。相反，WGAN损失函数的值可以反映了图像质量，随着损失值下降，生成图片的质量也上升了，这是我们所期待的。</p><img src="/2022/07/08/wgan/image-20220708190704427.png" class="" title="DCGAN生成器JS散度变化曲线"><img src="/2022/07/08/wgan/image-20220708190512241.png" class="" title="DCGAN生成器损失值变化曲线"><img src="/2022/07/08/wgan/image-20220708191141579.png" class="" title="WGAN中W距离变化曲线"><p><strong>提高训练的稳定性</strong></p><p>WGAN做出的贡献有：</p><ul><li>解决了模型崩溃的问题</li><li>不需要精心设计模型的网络结构</li><li>当判别器学习的很好，生成器仍然能够学习</li></ul><p>下面我们展示论文中的实验结果，即使将DCGAN中的批量标准化去掉，WGAN仍然可以生成高质量的图片。</p><img src="/2022/07/08/wgan/image-20220708192139487.png" class=""><img src="/2022/07/08/wgan/image-20220708192153820.png" class=""><img src="/2022/07/08/wgan/image-20220708192208832.png" class=""><h2 id="WGAN的问题"><a href="#WGAN的问题" class="headerlink" title="WGAN的问题"></a>WGAN的问题</h2><p>论文中作者是使用weight clipping技术来实现Lipschitz限制，但其实这是执行Lipschitz约束的一种糟糕的方式。作者文中也反映了这一问题，如果clipping参数的值很大，那么任何权重都需要很长时间才能达到限制，从而判别器很难训练到最优。如果clipping参数的值很小，当模型较深或未使用批量标准化，就很容易导致梯度消失的问题。</p><p>WGAN的困难在于执行Lipscitz约束条件，clipping虽然简单，但它解决了很多问题。虽然超参数c没有设置好，模型仍然会产生低质量的图片并且模型不能收敛。后面有文章用梯度惩罚执行Lipschitz约束条件，但它也有这样的问题，并且两者都会降低生成图片的多样性。真正完全满足Lipschitz约束条件的是Spectral Normalization，这两篇文章的链接：<a href="http://arxiv.org/abs/1704.00028">WGAN_GP</a>、<a href="http://arxiv.org/abs/1802.05957">SNGAN</a>，后续有时间的话，我也会学习这两篇文章，并和大家分享。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> WGAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN的Pytorch实现</title>
      <link href="/2022/07/06/wgan-de-pytorch-shi-xian/"/>
      <url>/2022/07/06/wgan-de-pytorch-shi-xian/</url>
      
        <content type="html"><![CDATA[<p>GAN存在训练困难、训练得到的loss无法表示训练进程等问题。大多数的GAN都是从模型的结构上进行修改，如DCGAN，用卷积神经网络设计生成器和判别器，并进行了一些调整，但这些终究是治标不治本，没有从根本上解决问题。原始GAN是用JS散度来评判两个分布的相似程度，而JS散度存在一个问题，就是真实数据$P_{data}$和生成数据$P_{G}$没有数据重叠的话，不管真实数据和生成数据之间的距离多远，JS散度计算出来的值都是log2，这就导致了生成器梯度消失的问题。WGAN就是用来解决这个问题，其优点有以下几个方面：</p><ul><li>彻底解决GAN训练不稳定和mode collapse的问题，不再需要小心平衡生成器和判别器的训练程度</li><li>不需要精心设计网络结构，MLP网络就能实现很好的结果</li><li>WGAN定义的损失函数可以反映训练的进程，从而我们可以根据这个指标来判断模型训练的效果</li></ul><p>WGAN实现以上好处使用的技术有：</p><ul><li>损失函数不取log</li><li>每次更新判别器的参数都截断到-c到c之间</li><li>使用RMSProp参数优化算法，而不是Adam</li><li>判别器的最后一层去掉sigmoid</li></ul><h2 id="模型实现">模型实现</h2><p>具体为什么要这么做，请查看原论文，本文主要关注的是WGAN模型以及训练过程Pytorch代码实现。</p><p>首先来看模型部分，这里使用的是DCGAN的模型，只不过将判别器的最后一层的sigmoid去掉</p><img src="/2022/07/06/wgan-de-pytorch-shi-xian/image-20220706103409376.png" class="" title="DCGAN的模型结构"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment"># 模型参数初始化</span><span class="token keyword">def</span> <span class="token function">weights_init</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    classname <span class="token operator">=</span> m<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__    <span class="token keyword">if</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'Conv'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>  <span class="token comment"># 均值为0，标准差为0.02的正态分布</span>    <span class="token keyword">elif</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'BatchNorm'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>        m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>             <span class="token comment"># 均值为1，标准差为0.02的正态分布</span><span class="token comment"># 生成器</span><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    input (N, in_dim)    output (N, 3, 64, 64)    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">dconv_bn_relu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span>                                   padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span>l2_5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            dconv_bn_relu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment"># (N, 512, 8, 8)  </span>            dconv_bn_relu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token comment"># (N, 256, 16, 16)</span>            dconv_bn_relu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>         <span class="token comment"># (N, 128, 32, 32)</span>            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token comment"># (N, 3, 64, 64)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        <span class="token comment"># (N, 1024 * 4 * 4)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>   <span class="token comment"># (N, 1024, 4, 4)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>l2_5<span class="token punctuation">(</span>out<span class="token punctuation">)</span>                    <span class="token comment"># (N, 3, 64, 64)</span>        <span class="token keyword">return</span> out<span class="token comment"># 判别器</span><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""        input (N, 3, 64, 64)        output (N, )        """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">conv_bn_lrelu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ls <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># (N, 128, 32, 32)</span>            conv_bn_lrelu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token comment"># (N, 256, 16, 16)</span>            conv_bn_lrelu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token comment"># (N, 512, 8, 8)</span>            conv_bn_lrelu<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                       <span class="token comment"># (N, 1024, 4, 4)</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>dim <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                              <span class="token comment"># (N, 1)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>ls<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个部分与前面笔记<a href="https://faith-ye.github.io/2022/05/06/hw6-gan/">HW6-GAN</a>生成器和判别器的模型基本一样，有关数据处理可以看这个笔记，下面我们主要看WGAN的训练过程，可以看前面模型的训练过程并进行对比。</p><h2 id="模型训练">模型训练</h2><p>准备好model和optimizer</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 设置超参数</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>z_dim <span class="token operator">=</span> <span class="token number">100</span>lr <span class="token operator">=</span> <span class="token number">0.0001</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span>cliping <span class="token operator">=</span> <span class="token number">0.02</span>critic_iter <span class="token operator">=</span> <span class="token number">1</span><span class="token comment"># model</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span>z_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>D <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>D<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># optimizer，注意这里用的是RMSprop</span>opt_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>opt_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment"># 用于后向传播更新模型参数</span>one <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>mone <span class="token operator">=</span> one <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>开始训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        imgs <span class="token operator">=</span> data        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        bs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>     <span class="token comment"># 这里不用batch_size是为了防止最后一个并不是</span>        <span class="token triple-quoted-string string">"""Train D"""</span>        <span class="token comment"># Requires grad, Generator requires_grad = False</span>        <span class="token keyword">for</span> p <span class="token keyword">in</span> D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">for</span> d_iter <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>critic_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>            D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># Clamp parameters</span>            <span class="token keyword">for</span> p <span class="token keyword">in</span> D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token operator">-</span>cliping<span class="token punctuation">,</span> cliping<span class="token punctuation">)</span>            z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            r_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            f_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>            <span class="token comment"># Train with real images</span>            d_loss_real <span class="token operator">=</span> D<span class="token punctuation">(</span>r_imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            d_loss_real<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>mone<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># Train with fake images</span>            d_loss_fake <span class="token operator">=</span> D<span class="token punctuation">(</span>f_imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            d_loss_fake<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>one<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            d_loss <span class="token operator">=</span> d_loss_fake <span class="token operator">-</span> d_loss_real            Wasserstein_D <span class="token operator">=</span> d_loss_real <span class="token operator">-</span> d_loss_fake            opt_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token triple-quoted-string string">""" Train G"""</span>        <span class="token keyword">for</span> p <span class="token keyword">in</span> D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># to avoid computation</span>        G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        f_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        g_loss <span class="token operator">=</span> D<span class="token punctuation">(</span>f_imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>mone<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        g_cost <span class="token operator">=</span> <span class="token operator">-</span>g_loss        opt_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 打印当前模型训练的状态</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'\rEpoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> '</span></span>              <span class="token string-interpolation"><span class="token string">f'Loss_D: </span><span class="token interpolation"><span class="token punctuation">{</span>d_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss_G: </span><span class="token interpolation"><span class="token punctuation">{</span>g_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面展示一张我训练迭代十次后出来的照片，整体看起来还是不错的，这里我没有使用原始DCGAN的模型，而是用了它的简化版，即前面笔记<a href="https://faith-ye.github.io/2022/05/06/hw6-gan/">HW6-GAN</a>中的模型，只是将判别器最后一层的sigmoid去掉，这个视觉上比HW6-GAN第10次迭代的效果要好些，但其中还是有一些瑕疵，个人觉得是我迭代的次数太少，也可能是代码问题。</p><img src="/2022/07/06/wgan-de-pytorch-shi-xian/Epoch_010.jpg" class="">]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> WGAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zotero</title>
      <link href="/2022/06/15/zotero/"/>
      <url>/2022/06/15/zotero/</url>
      
        <content type="html"><![CDATA[<p>说到文献管理软件，大家可能会想到<a href="https://endnote.com/">EndNote</a>或<a href="http://www.inoteexpress.com/aegean/">NoteExpress</a>，这里给大家分享 <a href="https://www.zotero.org/">Zotero</a>，我选择它有以下几点原因：</p><ul><li>是个开源的文献管理软件，<strong>免费</strong></li><li>可以结合浏览器插件进行使用，本地的Zotero文献数据库还可以免费上传到Zotero的网络服务器上，且不受空间大小限制</li><li><strong>一个目录下可以分为多个子目录</strong>，这使得文献管理起来方便多了，EndNote只支持二级目录</li><li><strong>Zotero还支持文献的标签功能</strong></li></ul><p>下面主要介绍Zotero的基本用法，包括：安装、添加资源、文献引用、添加笔记和文档数据同步</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>从 <a href="https://www.zotero.org/">Zotero官网</a> 下载安装包进行软件安装，下载界面会识别你使用的浏览器并推荐相应的插件，点击并进行安装。</p><img src="/2022/06/15/zotero/image-20220615103732563.png" class=""><h2 id="添加资源"><a href="#添加资源" class="headerlink" title="添加资源"></a>添加资源</h2><p>首先我们学习一下Zotero的界面分布，其界面大概分为三个部分：左侧是用户自定义的文件夹，中间是文件夹下收录的资源，右侧是选中资源对应的信息。</p><img src="/2022/06/15/zotero/image-20220615105409007.png" class=""><p>我选这款软件很重要的一点是，你在线研究论文时就可以使用Zotero的浏览器插件添加。当你打开文献网页后，点击激活Zotero的快捷键Ctrl+Shift+S，选择文献要保存的文件夹，点击完成即可添加到Zotero数据库中。这里我比较喜欢点进去查看PDF然后使用这个快捷键进行添加，这样会顺带把原文PDF收录。</p><img src="/2022/06/15/zotero/image-20220615110709983.png" class=""><p>当然你也可以手动输入，点进文献文件夹，然后在中间界面上方点击绿色圆圈的加号，选择资源的类型，并在右侧手动输入相关信息完成录入。你也可以从文件或剪切板导入，但这些都比较麻烦，建议使用第一种方法。</p><h2 id="文献引用和数据同步"><a href="#文献引用和数据同步" class="headerlink" title="文献引用和数据同步"></a>文献引用和数据同步</h2><p>一般Zotero安装时会自动添加到Microsoft Word插件中，如果在Word界面顶部没有看到Zotero，可在Zotero的设置中依次找到 <code>编辑 → 首选项 → 引用 → 文字处理软件</code> 重新安装插件即可。</p><p>在Microsoft Word中成功安装了Zotero插件后，就可以直接将Zotero中的引文插入文档。在 Word 中点击 <code>Zotero → Add/Edit Citation</code>， 然后选择以下方式选择你想要的引用格式。以后需要修改引用格式时在在Zotero的设置中依次找到 <code>编辑 → 首选项 → 引用 → 样式</code> 重新设置。</p><img src="/2022/06/15/zotero/image-20220615113205108.png" class=""><p>一旦选择了引文格式，就可以通过输入作者的姓名从Zotero数据库中找到来源，但我一般选择经典试图打开Zotero数据库进行手动选择。</p><img src="/2022/06/15/zotero/image-20220615150522038.png" class=""><p>文章写完后，在Word点击 <code>Zotero → Add/Edit Bibliography</code> 即可自动生成参考文献列表。</p><h2 id="添加笔记"><a href="#添加笔记" class="headerlink" title="添加笔记"></a>添加笔记</h2><p>右键文献则可写文献笔记，也可以从上部添加笔记的按钮中添加笔记。由于Zotero自带的笔记功能不支持Markdown语法，因此我们需要使用 <a href="https://github.com/ffecon/tools/blob/master/markdown.xpi">MarkdownHere</a> 插件，下载这个插件，然后在Zotero的设置中依次找到 <code>工具 → 插件 → 点击右上方的设置 → Install Add-on From File</code> ，找到刚才xpi文件位置，然后点击Install Now后重启软件即可。</p><p>导入这个插件后，我们使用Markdown语法编写好笔记，然后点击 <code>文件 → Markdown转换</code> 即可进行渲染。</p><h2 id="文档数据同步"><a href="#文档数据同步" class="headerlink" title="文档数据同步"></a>文档数据同步</h2><p>由于Zotero官方同步空间较小，只能使用其他方法来弥补。而<a href="http://zotfile.com/">ZotFile</a>插件是用于将zotero中文献附件转移至网络同步盘中的一种插件，可以解决官方同步空间小的问题。这里以onedrive网盘为例，讲述Zotero和ZotFile插件的关联以及使用。</p><p>点击上面的链接进行下载，按照MarkdownHere插件安装的方法安装此插件。随后进行以下设置，将 Zotero 附件的默认位置改为 ZotFile 的目标文件夹。</p><ul><li>打开<code>编辑 → 首选项 → 引用 → 文字处理软件</code>和<code>工具 → ZotFile Preference</code></li><li>查看Zotero数据文件路径</li><li>根据Zotero数据文件路径设置ZotFile跟踪的数据文件路径</li><li>设置附件移动的目标文件夹，这里须在OneDrive下新建一个ZotFile文件夹</li><li>修改Zotero附件文件夹</li></ul><img src="/2022/06/15/zotero/image-20220615165153562.png" class=""><h2 id="其他插件安装"><a href="#其他插件安装" class="headerlink" title="其他插件安装"></a>其他插件安装</h2><p>对于原文获取不到的文献，我们只能采用一点非正常渠道：<a href="https://sci-hub.se/">SciHub</a>来获取。Zotero可以使用插件来完成原文的获取：首先使用 <a href="https://github.com/bwiernik/zotero-shortdoi">Zotero-ShortDOI</a> 插件获取文献 DOI，然后利用 <a href="https://github.com/ethanwillis/zotero-scihub">Zotero-SciHub</a> 插件获得原文，这两个插件的安装也和前面一样，注意下载的是xpi文件。</p>]]></content>
      
      
      <categories>
          
          <category> 生命在于折腾 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 好用的软件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力增强卷积网络</title>
      <link href="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/"/>
      <url>/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/</url>
      
        <content type="html"><![CDATA[<img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520090637034.png" class=""><p><strong>主要思想：</strong>作者将卷积得到的特征图与通过自注意力机制产生的一组特征图连接（concatenate）起来，通过这种自注意力机制来增强卷积算子，从而提升模型性能。</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>卷积神经网络（CNN）在许多计算机视觉应用中都取得了巨大的成功，特别是在图像分类中。然而，CNN有一个显著的弱点，由于卷积操作和池化操作，只对图像的局部领域进行操作，因此缺少全局信息，而这些信息对于图像识别是很有必要的。</p><p>而在捕获长距离交互关系（long range interaction），自注意力的表现不错。自主意力背后的关键思想是生成隐藏层计算的值的加权平均值。不同于卷积操作或者池化操作，这些权重是动态根据输入特征，通过隐藏单元之间的相似函数产生的。因此，输入信号之间的交互互动只依赖于信号本身，不像卷积，由它们的相对位置事先决定。</p><p>因此，本文将自主意力计算应用到卷积操作中，实现了长距离交互。同时本文考虑使用自主意力替代卷积做判别性视觉任务，提出了二维相关自主意力机制（two-dimensional relative self-attention mechanism），并在此基础上注入相对位置信息，使其更加适合用于图像处理。本文实验表明，上述机制在完全替代卷积方面具有很大的竞争力，但实验中发现将两者结合可以获得更好的结果。因此作者并没有完全抛弃卷积，而是利用自主意力来增强卷积，即将强调局部特征的卷积特征图和能够获取长距离依赖的自主意力特征图拼接起来得到最终结果。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在介绍本文方法之前，我们先来了解注意力增强的卷积网络的主要结构：</p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520102419566.png" class=""><ul><li>H，W，$F_{in}$：输入特征图的height，weight，通道数量</li><li>$N_{h}$，$d_{v}$，$d_{k}$：heads的数量，values的深度，queries和keys的深度（多头注意力中的一些参数）。这里$d_{v}、d_{k}$必须可以被$N_{h}$整除，并且$d_{v}^{h}、d_{k}^{h}$为每个head中values、queries和keys的深度</li></ul><h3 id="图像中自主意力的计算"><a href="#图像中自主意力的计算" class="headerlink" title="图像中自主意力的计算"></a>图像中自主意力的计算</h3><p>和注意力的计算一样，只不过需要对图像输入数据做一定的处理——输入tensor$(H,W,F_{in})$flatten成矩阵$X\in R^{HW\times F_{in}}$作为输入。</p><p><strong>单头的计算形式:</strong></p><p>$$O_{h}=Softmax(\frac{(XW_{q})(XW_{k})^{T}}{\sqrt{d_{k}^{h}}})(XW_{v})$$</p><p><strong>多头的计算形式：</strong></p><p>$$MHA(X)=Concat(O_{1},…,O_{Nh})W^{O}$$</p><p>相关公式推导可以看前面笔记<a href="https://faith-ye.github.io/2022/04/02/zi-zhu-yi-li-mo-xing/">自注意力模型</a></p><h3 id="二维位置编码"><a href="#二维位置编码" class="headerlink" title="二维位置编码"></a>二维位置编码</h3><p>由于自主意力没有利用位置信息，因此满足交换律：$MHA(\pi (X))=\pi(MHA(X))$。</p><p>这里的$\pi$表示像素位置的任意交换，所以自主意力对于模拟像图像这种高度结构化的数据不是很有效，这时位置编码的技术就很关键。</p><ul><li>the Image Transformer extends the sinusoidal waves first introduced in the original Transformer to 2 dimensional inputs</li><li>CoordConv concatenates positional channels to an activation map</li></ul><p>然而，这些位置编码技术并不适合图像分类和目标检测。作者将其归因于这些技术虽然可以打破置换等变性（permutation equivariant），但不能处理图像任务时需要的平移等变性（translation equivariance）。而相对位置编码在打破置换等变性的同时实现了平移等变性，本文在相对位置编码的理论基础上将其拓展到二维上，并且基于Music Transformer提出一个内存有效实施的方法。</p><p><strong>相对位置编码（Relative positional encodings）</strong></p><p>本文通过相对位置编码技术注入了图像的相对高度和宽度信息，从而弥补了图像自主意力计算的缺点。则像素$i=(i_{x},i_{y})$关于像素$j=(j_{x},j_{y})$的attention logit计算公式如下：</p><p>$$l_{i,j}=\frac{q_{i}^{T}}{\sqrt{d_{k}^{h}}}(k_{j}+r_{j_{x}-i_{x}}^{W}+r_{j_{y}-i_{y}}^{H})$$</p><ul><li>$q_{i}$是像素i对应的查询向量，即矩阵Q的第i行</li><li>$k_{j}$是像素j对应的键向量，即矩阵K的第j行</li><li>$r_{j_{x}-i_{x}}^{W}、r_{j_{y}-i_{y}}^{H}$表示对于相对宽度$j_{x}-i_{x}$和相对高度$j_{y}-i_{y}$学习到的嵌入表示</li></ul><p><strong>此时单头的计算变为：</strong></p><p>$$O_{h}=Softmax(\frac{QK^{T}+S_{H}^{rel}+S_{W}^{rel}}{\sqrt{d_{k}^{h}}})V$$</p><ul><li>$S_{H}^{rel},S_{W}^{rel}\in R^{HW\times HW}$，它们是沿高度和宽度维度上的相对位置对数矩阵</li><li>$S_{H}^{rel}[i,j]=q_{i}^{T}r_{j_{y}-i_{y}}^{H},S_{W}^{rel}[i,j]=q_{i}^{T}r_{j_{x}-i_{x}}^{W}$</li></ul><h3 id="注意力增强卷积"><a href="#注意力增强卷积" class="headerlink" title="注意力增强卷积"></a>注意力增强卷积</h3><p>本文的提出的注意力增强卷积有以下两个特点：</p><ul><li>使用一种注意力机制，可以同时关注整体空间和特征子空间（每个head对应一个特征子空间）</li><li>引入额外的特征图而不是细化它们</li></ul><p><strong>对应公式：</strong></p><p>$$AAConv(X)=Concat[Conv(X),MHA(X)]$$</p><h3 id="注意力增强卷积结构"><a href="#注意力增强卷积结构" class="headerlink" title="注意力增强卷积结构"></a>注意力增强卷积结构</h3><ul><li>每次增强卷积后都会通过一个batch normalization layer来缩放卷积特征图和注意力特征图的贡献</li><li>每个增强卷积都会使用残差块结构</li><li>由于注意力的计算具有较大的内存占用，所以本文从具有最小空间维度的最后一层慢慢加入注意力增强的卷积，直到遇到内存限制</li><li>采用较小的批量大小和使用步长为2的3 x 3平均池化来执行下采样，而通过双线性插值进行上采样等操作来减少网络的内存占用</li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>这部分只列举各个实验结果</p><p><strong>CIFAR-100</strong></p><p>用于低分辨率图像的标准数据集</p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520160905233.png" class=""><p><strong>ImageNet</strong></p><p>用于高分辨率图像的标准数据集，只列举其中一个</p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520161451806.png" class=""><p><strong>COCO dataset</strong>  </p><p>用于目标检测的标准数据集</p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520161826025.png" class=""><p><strong>位置编码</strong></p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520162025902.png" class=""><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520162058341.png" class=""><p><strong>不同比例的注意力通道数</strong></p><img src="/2022/05/20/zhu-yi-li-zeng-qiang-juan-ji-wang-luo/image-20220520162304748.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1904.09925">Bello, Irwan, et al. “Attention augmented convolutional networks.” <em>Proceedings of the IEEE/CVF international conference on computer vision</em>. 2019.</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conformer-用卷积增强的Transformer做语音识别</title>
      <link href="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/"/>
      <url>/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/</url>
      
        <content type="html"><![CDATA[<p>今天学习一篇ASR-语言识别领域的文章，来自google的：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513194651384.png" class=""><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>提到端到端自动语音识别（ASR）系统，你可能会想到循环神经网络（RNN），因为RNN可以有效地模拟音频序列中的时间依赖性；你可能也会想到基于self-attention的Transformer架构，因为它能够捕捉序列的整体特征并且训练效率高；你甚至会想到卷积神经网络（CNN），因为它可以通过逐层捕捉序列的局部特征而获得序列的特征。</p><p>然而，基于self-attention或者卷积的模型都有它们的缺点。Transformer在提取长序列依赖的时候很有效，但它不擅长提取序列的局部特征，而卷积神经网络恰好相反。因此有没有可能将这两种特性结合起来建立一个新的模型，这个模型能同时提取输入数据的局部特征和整体特征。</p><p>Conformer就是将这两者结合起来，用卷积增强的Transformer做语音识别，并取得杰出的效果。下面，我们来学习一下Conformer的机制。</p><h2 id="Conformer"><a href="#Conformer" class="headerlink" title="Conformer"></a>Conformer</h2><p>语音识别使用的也是一个seq2seq模型，Conformer只使用卷积来改变encoder部分。Conformer Encoder的总体架构如下，首先我们用convolution subsampling layer处理输入，然后通过多个conformer blocks。</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513202038061.png" class=""><p>其中conformer blocks是由Feedforward module，Multi-head self attention Module, Convolution Module这三个Module组成的，其中Feedforward module在前后都有使用。下面我们分别学习这三个Module，并学习这些Moudle是如何结合在一起的。</p><h3 id="Multi-Headed-Self-Attention-Module"><a href="#Multi-Headed-Self-Attention-Module" class="headerlink" title="Multi-Headed Self-Attention Module"></a>Multi-Headed Self-Attention Module</h3><p>该Moudle采用了多头自注意力机制（multi-headed self-attention, MHSA），同时结合了Transformer-XL的一个重要技术——相对正弦位置编码方案。相对正弦位置编码使得self-attention module在不同的输入长度上具有更好的泛化能力，并且加强了编码器的鲁棒能力。同时该Moudle还使用了带有dropout的prenorm残差单元，这有助于训练和规范更深层次的模型。其整体结构如下图所示：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513203613588.png" class=""><h3 id="Convolution-Module"><a href="#Convolution-Module" class="headerlink" title="Convolution Module"></a>Convolution Module</h3><p>对于Convolution Module，使用了prenorm残差，pointwise卷积和线性门单元(Gated Linear Unit, GLU)，随后又经过了一系列结构，如下图所示：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513204736253.png" class=""><h3 id="Feed-Forward-Module"><a href="#Feed-Forward-Module" class="headerlink" title="Feed Forward Module"></a>Feed Forward Module</h3><p>对于Feed Forward Module，使用lprenorm残差，紧接着通过一个线性层和Swish激活函数，然后通过另一个线性层，该线性层前后都经过dropout处理，如下图所示：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513205632544.png" class=""><p>从Convolution Module和Feed Forward Module来看，它们都使用了Swish激活函数，它的计算公式如下</p><p>$$f(x)=x*\sigma(x)$$</p><p>式中，$\sigma(x)=(1+exp(-x))^{-1}$，它是一个sigmoid函数，有关它的图像如下图所示：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513211427887.png" class=""><h3 id="Conformer-Block"><a href="#Conformer-Block" class="headerlink" title="Conformer Block"></a>Conformer Block</h3><p>再回顾Conformer Block，我们可以得到它的计算公式：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513211645893.png" class=""><p>其中FFN是Feed Forward Module，MHSA是Multi-Headed Self-Attention Module，Conv是Convolution Module。其中特别注意这里使用的是1/2FFN，作者文中说明了半个要比一个的效果好。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>这部分就简单介绍一下，数据采用的是librispeech数据，其中包括970小时的labeled speech和额外的800M单词标记的文本语料库，用于构建语言模型。为了比较不同配置的Encoder好坏，统一使用单层的LSTM作为Decoder</p><p>实验中三种不同规模的Conformer的参数配置如下：</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513213021632.png" class=""><p>表格2展示的是和其他模型的对比情况，Conformer都达到了较好的效果</p><img src="/2022/05/13/conformer-yong-juan-ji-zeng-qiang-de-transformer-zuo-yu-yin-shi-bie/image-20220513213159848.png" class=""><p>同时作者还探讨了各个模块以及每个模块参数以及模块中结构的顺序对模型的影响，在这就不多加叙述，想了解的可以看原文。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/2005.08100">Gulati, Anmol, et al. “Conformer: Convolution-augmented transformer for speech recognition.” <em>arXiv preprint arXiv:2005.08100</em> (2020).</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Conformer </tag>
            
            <tag> ASR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW4-Self-Attention</title>
      <link href="/2022/05/12/hw4-self-attention/"/>
      <url>/2022/05/12/hw4-self-attention/</url>
      
        <content type="html"><![CDATA[<h2 id="作业描述"><a href="#作业描述" class="headerlink" title="作业描述"></a>作业描述</h2><p>本作业的目标是利用transformer中self-attention部分做一个多元分类，即从给定的语音中预测说话者的类别。利用的数据是从<a href="https://drive.google.com/file/d/1gaFy8RaQVUEXo2n0peCBR5gYKCB-mNHc/view">Voxceleb1</a>中挑选的一部分，数据如下：</p><ul><li>训练数据：69438条处理过的带标签音频特征</li><li>测试数据：6000条处理过的无标签音频特征</li><li>标签：总共600个标签，每个标签代表一个speaker</li></ul><p><strong>格式</strong></p><p>数据路径</p><ul><li>metadata.json</li><li>testdata.json</li><li>mapping.json</li><li>uttr-{random string}.pt</li></ul><p>metadata中的信息</p><ul><li>“n_mels”: mel-spectrogram的维数</li><li>“speakers”： 一个字典 <ul><li>Key: speaker的id </li><li>value：“feature_path”和“mel_len”</li></ul></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入相关的包</span><span class="token keyword">import</span> os<span class="token keyword">import</span> json<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token punctuation">,</span> random_split<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path<span class="token keyword">import</span> random<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn <span class="token keyword">import</span> pad_sequence<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">myDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">,</span> segment_len<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data_dir <span class="token operator">=</span> data_dir        self<span class="token punctuation">.</span>segment_len <span class="token operator">=</span> segment_len                <span class="token comment"># 加载一个字典，该字典对应speaker的标签(0, 1, 2, ... ,599)</span>        mapping_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"mapping.json"</span>        mapping <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>mapping_path<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>speaker2id <span class="token operator">=</span> mapping<span class="token punctuation">[</span><span class="token string">"speaker2id"</span><span class="token punctuation">]</span>                <span class="token comment"># 从metada中加载训练数据</span>        metadata_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"metadata.json"</span>        metadata <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span>metadata_path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"speakers"</span><span class="token punctuation">]</span>                <span class="token comment"># speaker的总个数</span>        self<span class="token punctuation">.</span>speaker_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>metadata<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> speaker <span class="token keyword">in</span> metadata<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> utterances <span class="token keyword">in</span> metadata<span class="token punctuation">[</span>speaker<span class="token punctuation">]</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>utterances<span class="token punctuation">[</span><span class="token string">"feature_path"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>speaker2id<span class="token punctuation">[</span>speaker<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        feat_path<span class="token punctuation">,</span> speaker <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        <span class="token comment"># 加载预处理的mel-spectrogram</span>        mel <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir<span class="token punctuation">,</span> feat_path<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mel<span class="token punctuation">)</span> <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>segment_len<span class="token punctuation">:</span>            start <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mel<span class="token punctuation">)</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>segment_len<span class="token punctuation">)</span>            mel <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>mel<span class="token punctuation">[</span>start<span class="token punctuation">:</span> start <span class="token operator">+</span> self<span class="token punctuation">.</span>segment_len<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            mel <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>mel<span class="token punctuation">)</span>        speaker <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>speaker<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> mel<span class="token punctuation">,</span> speaker    <span class="token keyword">def</span> <span class="token function">get_speaker_number</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>speaker_num<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><ul><li>把训练数据划分为训练集(90%)和验证集(10%)</li><li>创建dataloader来迭代数据</li></ul><p>由于我们是按batch训练模型，所以需要对同一batch的数据进行填充，使它们长度相同，这部分通过定义collate_batch()函数实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">collate_batch</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>    mel<span class="token punctuation">,</span> speaker <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>    mel <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>mel<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">)</span>    <span class="token comment"># mel: (batch size, length, 40)</span>    <span class="token keyword">return</span> mel<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>speaker<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    dataset <span class="token operator">=</span> myDataset<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>    speaker_num <span class="token operator">=</span> dataset<span class="token punctuation">.</span>get_speaker_number<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 划分数据集</span>    trainlen <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.9</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>    lengths <span class="token operator">=</span> <span class="token punctuation">[</span>trainlen<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">-</span> trainlen<span class="token punctuation">]</span>    trainset<span class="token punctuation">,</span> validset <span class="token operator">=</span> random_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> lengths<span class="token punctuation">)</span>    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        trainset<span class="token punctuation">,</span>        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>        shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">,</span>    <span class="token punctuation">)</span>    valid_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        validset<span class="token punctuation">,</span>        batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>        collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span> train_loader<span class="token punctuation">,</span> valid_loader<span class="token punctuation">,</span> speaker_num<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>在这里，我们使用的模型是基于Transformer的EncoderLayer，相关使用可以看官方API <a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer">TransformerEncoderLayer</a>。当然，你也可以使用Transformer完整的Encoder部分，它只不过多叠了几个EncoderLayer，有关它的使用也请看官方API <a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder">TransformerEncoder</a></p><p>如果你对Transformer不太了解，可以去看前面写的笔记-<a href="https://faith-ye.github.io/2022/04/11/transformer/">Transformer</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">,</span> n_spks<span class="token operator">=</span><span class="token number">600</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 将输入的特征维度投影到d_model</span>        self<span class="token punctuation">.</span>prenet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>        <span class="token comment"># TODO: 可以尝试实现</span>        <span class="token comment">#   Change Transformer to Conformer.</span>        <span class="token comment">#   https://arxiv.org/abs/2005.08100</span>        self<span class="token punctuation">.</span>encoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoderLayer<span class="token punctuation">(</span>          d_model<span class="token operator">=</span>d_model<span class="token punctuation">,</span> dim_feedforward<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> nhead<span class="token operator">=</span><span class="token number">2</span>        <span class="token punctuation">)</span>        <span class="token comment"># self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)</span>        <span class="token comment"># 将 d_model 中的特征维度投影到speaker的人数中，便于分类</span>        self<span class="token punctuation">.</span>pred_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>          <span class="token comment"># nn.Linear(d_model, d_model),</span>          <span class="token comment"># nn.ReLU(),</span>          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> n_spks<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mels<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>prenet<span class="token punctuation">(</span>mels<span class="token punctuation">)</span>          <span class="token comment"># out: (batch size, length, d_model)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>       <span class="token comment"># out: (length, batch size, d_model)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># out: (batch size, length, d_model)</span>        stats <span class="token operator">=</span> out<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>         <span class="token comment"># mean pooling</span>                out <span class="token operator">=</span> self<span class="token punctuation">.</span>pred_layer<span class="token punctuation">(</span>stats<span class="token punctuation">)</span>    <span class="token comment"># out: (batch, n_spks)</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="学习率调度器"><a href="#学习率调度器" class="headerlink" title="学习率调度器"></a>学习率调度器</h2><ul><li>对于transformer结构，学习率时间表的设计是和CNN不一样的</li><li>先前的知识表明采用warmup形式的学习率对于训练像transformer结构的模型十分有效</li></ul><p>本文采用的是cosine学习率，它的计算公式如下</p><img src="/2022/05/12/hw4-self-attention/image-20220512192405370.png" class=""><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> math<span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> Optimizer<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> LambdaLR<span class="token keyword">def</span> <span class="token function">get_cosine_schedule_with_warmup</span><span class="token punctuation">(</span>    optimizer<span class="token punctuation">:</span> Optimizer<span class="token punctuation">,</span>    num_warmup_steps<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>    num_training_steps<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>    num_cycles<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.5</span><span class="token punctuation">,</span>    last_epoch<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">lr_lambda</span><span class="token punctuation">(</span>current_step<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># warmup</span>        <span class="token keyword">if</span> current_step <span class="token operator">&lt;</span> num_warmup_steps<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>current_step<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_warmup_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># decadence</span>        progress <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>current_step <span class="token operator">-</span> num_warmup_steps<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>            <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_training_steps <span class="token operator">-</span> num_warmup_steps<span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token builtin">max</span><span class="token punctuation">(</span>            <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>math<span class="token punctuation">.</span>pi <span class="token operator">*</span> <span class="token builtin">float</span><span class="token punctuation">(</span>num_cycles<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2.0</span> <span class="token operator">*</span> progress<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">return</span> LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token punctuation">,</span> last_epoch<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>这部分用于调节以提升模型性能</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"data_dir"</span><span class="token punctuation">:</span> <span class="token string">"./Dataset"</span><span class="token punctuation">,</span>    <span class="token string">"save_path"</span><span class="token punctuation">:</span> <span class="token string">"models/model.pth"</span><span class="token punctuation">,</span>    <span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token number">32</span><span class="token punctuation">,</span>    <span class="token string">"lr"</span><span class="token punctuation">:</span> <span class="token number">1e-3</span><span class="token punctuation">,</span>    <span class="token string">"valid_steps"</span><span class="token punctuation">:</span> <span class="token number">2000</span><span class="token punctuation">,</span>    <span class="token string">"warmup_steps"</span><span class="token punctuation">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>    <span class="token string">"n_epochs"</span><span class="token punctuation">:</span> <span class="token number">70000</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="加载数据和模型"><a href="#加载数据和模型" class="headerlink" title="加载数据和模型"></a>加载数据和模型</h2><p>准备好dataloader，model，loss criterion，optimizer</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_loader<span class="token punctuation">,</span> valid_loader<span class="token punctuation">,</span> speaker_num <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'data_dir'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span>n_spks<span class="token operator">=</span>speaker_num<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>scheduler <span class="token operator">=</span> get_cosine_schedule_with_warmup<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'warmup_steps'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> timen_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>         <span class="token comment"># 总迭代次数</span>best_acc <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.0</span>                     <span class="token comment"># 用于保存在测试集准确率最高的模型</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>        <span class="token comment"># 每次迭代后，在验证集中验证模型</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'valid_steps'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        val_loss<span class="token punctuation">,</span> val_acc <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>valid_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>                loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>                val_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                val_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        val_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        val_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_loader<span class="token punctuation">)</span>        <span class="token comment"># 当模型性能提升时保存模型</span>        <span class="token keyword">if</span> val_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>            best_acc <span class="token operator">=</span> val_acc            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">, acc = </span><span class="token interpolation"><span class="token punctuation">{</span>best_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">), loss = </span><span class="token interpolation"><span class="token punctuation">{</span>val_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># 将结果打印出来</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%02d/%02d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f'</span> <span class="token operator">%</span> \          <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n_epochs<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> train_loss<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h2><p>首先我们得为测试数据创建dataset和dataloader，并加载我们保存的最好的模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">InferenceDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>        testdata_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"testdata.json"</span>        metadata <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>testdata_path<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>data_dir <span class="token operator">=</span> data_dir        self<span class="token punctuation">.</span>data <span class="token operator">=</span> metadata<span class="token punctuation">[</span><span class="token string">"utterances"</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        utterance <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        feat_path <span class="token operator">=</span> utterance<span class="token punctuation">[</span><span class="token string">"feature_path"</span><span class="token punctuation">]</span>        mel <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_dir<span class="token punctuation">,</span> feat_path<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> feat_path<span class="token punctuation">,</span> mel<span class="token keyword">def</span> <span class="token function">inference_collate_batch</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>    feat_paths<span class="token punctuation">,</span> mels <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>    <span class="token keyword">return</span> feat_paths<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>mels<span class="token punctuation">)</span>dataset <span class="token operator">=</span> InferenceDataset<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'data_dir'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>    dataset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    collate_fn<span class="token operator">=</span>inference_collate_batch<span class="token punctuation">,</span><span class="token punctuation">)</span>model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span>n_spks<span class="token operator">=</span>speaker_num<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">Classifier(  (prenet): Linear(in_features=40, out_features=80, bias=True)  (encoder_layer): TransformerEncoderLayer(    (self_attn): MultiheadAttention(      (out_proj): _LinearWithBias(in_features=80, out_features=80, bias=True)    )    (linear1): Linear(in_features=80, out_features=256, bias=True)    (dropout): Dropout(p=0.1, inplace=False)    (linear2): Linear(in_features=256, out_features=80, bias=True)    (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)    (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)    (dropout1): Dropout(p=0.1, inplace=False)    (dropout2): Dropout(p=0.1, inplace=False)  )  (pred_layer): Sequential(    (0): Linear(in_features=80, out_features=600, bias=True)  ))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将预测结果保存到csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> csvmapping_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'data_dir'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"mapping.json"</span>mapping <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>mapping_path<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">"Id"</span><span class="token punctuation">,</span> <span class="token string">"Category"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">for</span> feat_paths<span class="token punctuation">,</span> mels <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        mels <span class="token operator">=</span> mels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        outs <span class="token operator">=</span> model<span class="token punctuation">(</span>mels<span class="token punctuation">)</span>        preds <span class="token operator">=</span> outs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> feat_path<span class="token punctuation">,</span> pred <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>feat_paths<span class="token punctuation">,</span> preds<span class="token punctuation">)</span><span class="token punctuation">:</span>            results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>feat_path<span class="token punctuation">,</span> mapping<span class="token punctuation">[</span><span class="token string">"id2speaker"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'predict.csv'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> newline<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span> <span class="token keyword">as</span> csvfile<span class="token punctuation">:</span>    writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>csvfile<span class="token punctuation">)</span>    writer<span class="token punctuation">.</span>writerows<span class="token punctuation">(</span>results<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java两个常用API</title>
      <link href="/2022/05/12/java-liang-ge-chang-yong-api/"/>
      <url>/2022/05/12/java-liang-ge-chang-yong-api/</url>
      
        <content type="html"><![CDATA[<h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p>API的全称是Application Programming Interface，应用程序编程接口</p><ul><li>Java写好的功能代码，可以直接调用</li><li>Oracle也为Java提供的这些功能代码提供了相应的API文档（技术使用说明书）</li></ul><p>本节主要学习String和ArrayList这两个常用API</p><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String类定义的变量可以用于存储字符串，同时String类提供了很多操作字符串的功能，我们可以直接使用</p><p><strong>概述</strong></p><ul><li>java.lang.String类代表字符串，String类定义的变量可以用于指向字符串对象，然后操作该字符串</li><li>Java程序中的所有字符文字都为此类的对象</li></ul><p><strong>String是不可变字符串的原因？</strong></p><p>String变量每次的修改其实都是产生并指向了新的字符串对象，原来的字符串对象都是没有改变的，所以称不可变字符串</p><p><strong>特点</strong></p><ul><li>双引号创建的字符串对象，在字符串常量池中存储同一个</li><li>通过new构造器创建的字符串对象，在堆内存中分开存储</li></ul><p><strong>字符串内容比较</strong></p><p>推荐使用String类提供的”equals“比较：只关心内容一样即可。不推荐用”==“比较，因为比较的是地址</p><table><thead><tr><th align="center">方法名</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">public boolean equals(Object anObject)</td><td align="center">将此字符串与指定对象进行比较。只关心字符内容是否一致！</td></tr><tr><td align="center">public boolean equalsIgnoreCase (String anotherString)</td><td align="center">将此字符串与指定对象进行比较，忽略大小写比较字符串。只关心字符内容是否一致！</td></tr></tbody></table><p>以equals为例，使用如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">okName<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>   <span class="token comment">// 判断okName字符串和name字符串是否相同，返回值为true或false</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>String常用方法</strong></p><table><thead><tr><th>方法名</th><th>说明</th></tr></thead><tbody><tr><td>public int length()</td><td>返回此字符串的长度</td></tr><tr><td>public char charAt(int index)</td><td>获取某个索引位置处的字符</td></tr><tr><td>public char[] toCharArray()：</td><td>将当前字符串转换成字符数组返回</td></tr><tr><td>public String substring(int beginIndex, int endIndex)</td><td>根据开始和结束索引进行截取，得到新的字符串（包前不包后）</td></tr><tr><td>public String substring(int beginIndex)</td><td>从传入的索引处截取，截取到末尾，得到新的字符串</td></tr><tr><td>public String replace(CharSequence target, CharSequence replacement)</td><td>使用新值，将字符串中的旧值替换，得到新的字符串</td></tr><tr><td>public String[] split(String regex)</td><td>根据传入的规则切割字符串，得到字符串数组返回</td></tr></tbody></table><h2 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h2><p>ArrayList代表的是集合类，集合是一种容器，与数组类似，不同的是集合的大小是不固定的。通过创建ArrayList的对象表示得到一个集合容器，同时ArrayList提供了比数组更好用，更丰富的API给程序员使用</p><p><strong>ArrayList对象创建</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">ArrayList</span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>ArrayList集合的添加元素的方法</strong></p><table><thead><tr><th align="left">方法名</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">public boolean add(E e)</td><td align="left">将指定的元素追加到此集合的末尾</td></tr><tr><td align="left">public void add(int index,E element)</td><td align="left">在此集合中的指定位置插入指定的元素</td></tr></tbody></table><p><strong>泛型概述</strong></p><ul><li>ArrayList&lt;E&gt;：其实就是一个泛型类，可以在编译阶段约束集合对象只能操作某种数据类型。</li></ul><p><strong>举例：</strong></p><ul><li><p>ArrayList&lt;String&gt; ：此集合只能操作字符串类型的元素。</p></li><li><p>ArrayList&lt;Integer&gt;：此集合只能操作整数类型的元素。</p></li></ul><p><strong>注意：</strong>集合中只能存储引用类型，不支持基本数据类型，因此不能填int，需用Integer</p><p><strong>ArrayList集合常用方法</strong></p><table><thead><tr><th align="left">方法名称</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">public E get(int  index)</td><td align="left">返回指定索引处的元素</td></tr><tr><td align="left">public int  size()</td><td align="left">返回集合中的元素的个数</td></tr><tr><td align="left">public E remove(int  index)</td><td align="left">删除指定索引处的元素，返回被删除的元素</td></tr><tr><td align="left">public boolean remove(Object o)</td><td align="left">删除指定的元素，返回删除是否成功</td></tr><tr><td align="left">public E set(int index,E element)</td><td align="left">修改指定索引处的元素，返回被修改的元素</td></tr></tbody></table><p>利用上述方法，我们可以实现集合的遍历：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java面向对象</title>
      <link href="/2022/05/11/java-mian-xiang-dui-xiang/"/>
      <url>/2022/05/11/java-mian-xiang-dui-xiang/</url>
      
        <content type="html"><![CDATA[<h2 id="设计对象并使用"><a href="#设计对象并使用" class="headerlink" title="设计对象并使用"></a>设计对象并使用</h2><ul><li><strong>类（设计图）：</strong>是对象共同特征的描述</li><li><strong>对象：</strong>是真实存在的具体实例</li></ul><p>在Java中，必须先设计类，才能创建对象并使用</p><img src="/2022/05/11/java-mian-xiang-dui-xiang/image-20220509105228063.png" class=""><p><strong>注意事项：</strong></p><ul><li>类名首字母建议大写，满足“驼峰模式”，不能用关键字，必须是合法标识符</li><li>一个Java文件中可以定义多个class类，但只能一个类是public修饰，而且public修饰的类名必须成为代码文件名</li><li>成员变量的完整定义格式是： 修饰符 数据类型 变量名称 = 初始化值; 一般无需指定初始化值，存在默认值</li></ul><h2 id="构造器"><a href="#构造器" class="headerlink" title="构造器"></a>构造器</h2><p><strong>作用</strong></p><ul><li>定义在类中的，可以用于初始化一个类的对象，并返回对象的地址</li></ul><p><strong>格式</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java">修饰符 类名<span class="token punctuation">(</span>形参列表<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>调用构造器得到对象的格式</strong></p><p>类 变量名称 = new 构造器;</p><p><strong>分类和作用</strong></p><ul><li>无参数构造器：初始化对象时（默认存在的），成员变量的数据均采用默认值</li><li>有参数构造器：在初始化对象的时候，同时可以接收参数为对象进行赋值</li></ul><p><strong>注意事项</strong></p><ul><li>任何类定义出来，默认自带了无参数构造器，写不写都有</li><li>一旦定义了有参数构造器，那么无参数构造器就没有了，如果还想用无参数构造器，此时就需要自己手写一个无参数构造器</li></ul><h2 id="this关键字"><a href="#this关键字" class="headerlink" title="this关键字"></a>this关键字</h2><ul><li>可以出现在构造器、方法中，<strong>代表当前对象的地址</strong></li></ul><p><strong>作用</strong></p><ul><li>可以用于指定访问当前对象的成员变量、成员方法</li></ul><p>以this出现在有参数构造器中的用法为例，此时的this是当前对象的地址，就完美的将构造器中的name赋值给当前对象的成员变量name</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Car</span> <span class="token punctuation">{</span>    <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">double</span> price<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">Car</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">,</span> <span class="token keyword">double</span> price<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>price <span class="token operator">=</span> price<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><ul><li>面向对象的三大特征：封装、继承、多态</li><li>作用：告诉我们，如何正确设计对象的属性和方法</li><li>原则：对象代表什么，就得封装对应的数据，并提供数据对应的行为</li></ul><p><strong>如何封装</strong></p><ul><li>一般会把成员变量使用private隐藏起来，对外就不能直接访问了</li><li>提供public修饰的getter和setter方法暴露其取值和赋值</li></ul><h2 id="JavaBean"><a href="#JavaBean" class="headerlink" title="JavaBean"></a>JavaBean</h2><ul><li>也可以称为实体类，其对象可以用于在程序中封装数据</li></ul><p><strong>标准JavaBean须满足如下书写要求：</strong></p><ul><li>成员变量使用private修饰</li><li>提供成员变量对应的setXxx() / getXxx()方法</li><li>必须提供一个无参数构造器；有参数构造器是可写可不写的</li></ul><p><strong>成员变量和局部变量的区别</strong></p><table><thead><tr><th align="center">区别</th><th align="center">成员变量</th><th align="center">局部变量</th></tr></thead><tbody><tr><td align="center">类中位置不同</td><td align="center">类中，方法外</td><td align="center">常见于方法中</td></tr><tr><td align="center">初始化值不同</td><td align="center">有默认值，无需初始化</td><td align="center">没有默认值，使用前需要完成赋值</td></tr><tr><td align="center">内存位置不同</td><td align="center">堆内存</td><td align="center">栈内存</td></tr><tr><td align="center">生命周期不同</td><td align="center">随着对象的创建而存在，随着对象的消失而消失</td><td align="center">随着方法的调用而存在，随着方法的运行结束而消失</td></tr><tr><td align="center">作用域</td><td align="center"></td><td align="center">在所归属的大括号中</td></tr></tbody></table><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><ul><li>目标：完成电影信息的展示案例，理解面向对象变成的代码</li></ul><p>首先我们设计一个Movie的类</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">demo2</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Movie</span> <span class="token punctuation">{</span>    <span class="token comment">// 1、成员变量</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">double</span> score<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token class-name">String</span> actor<span class="token punctuation">;</span>    <span class="token comment">// 3、构造器</span>    <span class="token keyword">public</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">,</span> <span class="token keyword">double</span> score<span class="token punctuation">,</span> <span class="token class-name">String</span> actor<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>score <span class="token operator">=</span> score<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>actor <span class="token operator">=</span> actor<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment">// 2、getter + setter</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setName</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getScore</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> score<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setScore</span><span class="token punctuation">(</span><span class="token keyword">double</span> score<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>score <span class="token operator">=</span> score<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getActor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> actor<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setActor</span><span class="token punctuation">(</span><span class="token class-name">String</span> actor<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>actor <span class="token operator">=</span> actor<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建对象，并访问对象</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">demo2</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Test</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment">// 1、设计电影类</span>        <span class="token comment">// 2、创建3个电影对象，封装电影的信息</span>        <span class="token comment">// 3、定义一个电影类型的数组，存储3部电影对象</span>        <span class="token class-name">Movie</span><span class="token punctuation">[</span><span class="token punctuation">]</span> movies <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        movies<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token string">"《长津湖》"</span><span class="token punctuation">,</span> <span class="token number">9.7</span><span class="token punctuation">,</span> <span class="token string">"吴京"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        movies<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token string">"《我和我的父亲》"</span><span class="token punctuation">,</span> <span class="token number">9.6</span><span class="token punctuation">,</span> <span class="token string">"吴京"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        movies<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Movie</span><span class="token punctuation">(</span><span class="token string">"《朴水少年》"</span><span class="token punctuation">,</span> <span class="token number">9.5</span><span class="token punctuation">,</span> <span class="token string">"王川"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment">// 4、遍历数组中每个电影对象，然后获取它的信息展示出来</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> movies<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token class-name">Movie</span> m <span class="token operator">=</span> movies<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"电影名："</span> <span class="token operator">+</span> m<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"得分："</span> <span class="token operator">+</span> m<span class="token punctuation">.</span><span class="token function">getScore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"主演："</span> <span class="token operator">+</span> m<span class="token punctuation">.</span><span class="token function">getActor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"------------------------------"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>HW6-GAN</title>
      <link href="/2022/05/06/hw6-gan/"/>
      <url>/2022/05/06/hw6-gan/</url>
      
        <content type="html"><![CDATA[<h2 id="作业描述"><a href="#作业描述" class="headerlink" title="作业描述"></a>作业描述</h2><p>这部分我将用GAN实现一个动画人脸的生成，利用的模型是DCGAN，它在原始GAN模型的基础上，将生成器和判别器的网络结构换成了当时已经十分成熟的卷积神经网络结构，并对卷积神经网络结构进行一定的调整，克服了原始GAN训练不稳定和梯度消失的问题。具体改变有：</p><ul><li>取消所有的pooling层。生成器中使用fractionally strided convolution代替pooling层，判别器中使用strided convolution代替pooling层。</li><li>在生成器和判别器中都使用批量标准化</li><li>去除了全连接层</li><li>生成器中使用ReLU作为激活函数，最后一层使用tanh激活函数</li><li>判别器中使用LeakyReLU作为激活函数</li></ul><p>DCGAN的网络结构如下图所示：</p><img src="/2022/05/06/hw6-gan/image-20220506195849410.png" class=""><p>现在让我们来实现这一部分，首先现在我们需要导入本作业需要的一些包，并设置随机种子的个数（这部分直接复制粘贴就好)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> os<span class="token keyword">import</span> glob<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable    <span class="token comment"># 产生随机分布</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> random<span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>需要使用transforms将图片转成以下格式：</p><ul><li>修改图片尺寸为(64, 64)</li><li>将数值从[0, 1]映射到[-1, 1]</li><li>转成tensor格式读入</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Dataset</span><span class="token keyword">class</span> <span class="token class-name">CrypkoDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fnames<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>fnames <span class="token operator">=</span> fnames        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fnames<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> self<span class="token punctuation">.</span>fnames<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>fname<span class="token punctuation">)</span>   <span class="token comment"># 读取图片</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>                <span class="token comment"># 对图片进行一定的修改</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>制定transform规则并获取dataset</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'./faces'</span><span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 1. 修改图片尺寸为(64, 64)</span><span class="token comment"># 2. 将数值从 [0, 1] 线性映射到 [-1, 1]</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dataset <span class="token operator">=</span> CrypkoDataset<span class="token punctuation">(</span>fnames<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>展示一组照片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images <span class="token operator">=</span> <span class="token punctuation">[</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/05/06/hw6-gan/output_7_2.png" class="">    <p>由于我们使用了transform将数据的范围变成了[-1, 1]，因此我们需要将其转换为[0, 1]，才能展示出正确的图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/05/06/hw6-gan/output_9_1.png" class=""><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>现在实现模型的部分，这一部分也可以自行修改</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型参数初始化</span><span class="token keyword">def</span> <span class="token function">weights_init</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    classname <span class="token operator">=</span> m<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__    <span class="token keyword">if</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'Conv'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>  <span class="token comment"># 均值为0，标准差为0.02的正态分布</span>    <span class="token keyword">elif</span> classname<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'BatchNorm'</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>        m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>             <span class="token comment"># 均值为1，标准差为0.02的正态分布</span>        <span class="token comment"># 生成器</span><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">dconv_bn_relu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2_5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dconv_bn_relu<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l2_5<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token keyword">return</span> y<span class="token comment"># 判别器</span><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">conv_bn_lrelu</span><span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> out_dim<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ls <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            conv_bn_lrelu<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>weights_init<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>ls<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> y <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>这部分可以进行调节</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">batch_size <span class="token operator">=</span> <span class="token number">64</span>z_dim <span class="token operator">=</span> <span class="token number">100</span>z_sample <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># 随机生成100个样本，用于检测模型的训练结果</span>lr <span class="token operator">=</span> <span class="token number">1e-4</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><p><strong>准备好dataloader，model，loss criterion，optimizer</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 生成一个文件目录，用于保存模型结果</span>save_dir <span class="token operator">=</span> <span class="token string">'./logs'</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># dataloader</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># model</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span>z_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>D <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span>in_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>D<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># loss criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># optimizer</span>opt_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>opt_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Training</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        imgs <span class="token operator">=</span> data<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                bs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>                <span class="token triple-quoted-string string">"""训练D"""</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        g_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>                      <span class="token comment"># 生成的概率分布</span>        r_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 真实数据的概率分布</span>                <span class="token comment"># 对两种数据打标签，真实为1，生成的为0</span>        g_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        r_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 两种数据经过判别器</span>        g_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>g_imgs<span class="token punctuation">)</span>        r_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>r_imgs<span class="token punctuation">)</span>                <span class="token comment"># 计算D的loss</span>        g_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>g_logits<span class="token punctuation">,</span> g_label<span class="token punctuation">)</span>        r_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>r_logits<span class="token punctuation">,</span> r_label<span class="token punctuation">)</span>        loss_D <span class="token operator">=</span> <span class="token punctuation">(</span>g_loss <span class="token operator">+</span> r_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>                <span class="token comment"># 后向传播更新D的模型参数</span>        D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_D<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opt_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token triple-quoted-string string">"""训练G"""</span>        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        g_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>                <span class="token comment"># 生成数据经过判别器</span>        g_logits <span class="token operator">=</span> D<span class="token punctuation">(</span>g_imgs<span class="token punctuation">)</span>                <span class="token comment"># 计算loss</span>        loss_G <span class="token operator">=</span> criterion<span class="token punctuation">(</span>g_logits<span class="token punctuation">,</span> r_label<span class="token punctuation">)</span>     <span class="token comment"># 生成器的目的是生成和真实数据一样的分布，因此用的是r_label</span>                <span class="token comment"># 后向传播更新G的模型参数</span>        G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_G<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opt_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 打印当前模型训练的状态</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'\rEpoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> Loss_D: </span><span class="token interpolation"><span class="token punctuation">{</span>loss_D<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss_G: </span><span class="token interpolation"><span class="token punctuation">{</span>loss_G<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>    <span class="token comment"># 每进行一次epoch，生成一组图片，用于评估模型训练的情况</span>    G<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    g_imgs_sample <span class="token operator">=</span> <span class="token punctuation">(</span>G<span class="token punctuation">(</span>z_sample<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>    filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'Epoch_</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">03d</span><span class="token punctuation">}</span></span><span class="token string">.jpg'</span></span><span class="token punctuation">)</span>    torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>save_image<span class="token punctuation">(</span>g_imgs_sample<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f' | save samples to </span><span class="token interpolation"><span class="token punctuation">{</span>filename<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>        <span class="token comment"># 展示生成的图片</span>    grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>g_imgs_sample<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 将G转换成训练模型</span>    G<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 模型保存</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>G<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'dcgan_g.pth'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>D<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'dcgan_d.pth'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Epoch [1/10] 1115/1115 Loss_D: 0.5579 Loss_G: 2.0209 | save samples to ./logs\Epoch_001.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_1.png" class="">    <pre><code>Epoch [2/10] 1115/1115 Loss_D: 0.2129 Loss_G: 6.2952 | save samples to ./logs\Epoch_002.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_3.png" class=""><pre><code>Epoch [3/10] 1115/1115 Loss_D: 0.2469 Loss_G: 2.8889 | save samples to ./logs\Epoch_003.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_5.png" class=""><pre><code>Epoch [4/10] 1115/1115 Loss_D: 0.3291 Loss_G: 3.8916 | save samples to ./logs\Epoch_004.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_7.png" class=""><pre><code>Epoch [5/10] 1115/1115 Loss_D: 0.2093 Loss_G: 3.2604 | save samples to ./logs\Epoch_005.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_9.png" class=""><pre><code>Epoch [6/10] 1115/1115 Loss_D: 0.1691 Loss_G: 3.0890 | save samples to ./logs\Epoch_006.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_11.png" class=""><pre><code>Epoch [7/10] 1115/1115 Loss_D: 0.1185 Loss_G: 3.0753 | save samples to ./logs\Epoch_007.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_13.png" class=""><pre><code>Epoch [8/10] 1115/1115 Loss_D: 0.1162 Loss_G: 3.1938 | save samples to ./logs\Epoch_008.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_15.png" class=""><pre><code>Epoch [9/10] 1115/1115 Loss_D: 0.1183 Loss_G: 4.2176 | save samples to ./logs\Epoch_009.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_17.png" class=""><pre><code>Epoch [10/10] 1115/1115 Loss_D: 0.1022 Loss_G: 2.4000 | save samples to ./logs\Epoch_010.jpg</code></pre><img src="/2022/05/06/hw6-gan/output_17_19.png" class=""><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>现在我们就可以利用我们训练好的Generator来随机生成图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型加载</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span>z_dim<span class="token punctuation">)</span>G<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span><span class="token string">'dcgan_g.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>G<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> n_output <span class="token operator">=</span> <span class="token number">20</span>z_sample <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_output<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>imgs_sample <span class="token operator">=</span> <span class="token punctuation">(</span>G<span class="token punctuation">(</span>z_sample<span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span>filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'result.jpg'</span></span><span class="token punctuation">)</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>save_image<span class="token punctuation">(</span>imgs_sample<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token comment"># show image</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>imgs_sample<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/05/06/hw6-gan/output_19_1.png" class=""><p>虽然图中的动画人物看起来很怪，但也有几分和动画人物相似，并且有的已经非常像了。这里我只把n_epoch设置为10，如果将n_epoch设置大点，我想结果会好点。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1511.06434">Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised representation learning with deep convolutional generative adversarial networks.”arXiv preprint arXiv:1511.06434(2015).</a></p>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW2-Classifier</title>
      <link href="/2022/05/05/hw2-classifier/"/>
      <url>/2022/05/05/hw2-classifier/</url>
      
        <content type="html"><![CDATA[<h2 id="作业描述"><a href="#作业描述" class="headerlink" title="作业描述"></a>作业描述</h2><p>本作业处理的是一个phoneme分类，是一个多元分类问题。phoneme是语言的一种语音的一种语音单位，可以用来区分一个词和另一个词，如下面黑体部分。</p><ul><li><strong>b</strong>at / <strong>p</strong>at , b<strong>a</strong>d / b<strong>e</strong>d</li></ul><p>作业使用的数据集是<a href="https://catalog.ldc.upenn.edu/LDC93S1">TIMIT Acoustic-Phonetic Continuous Speech Corpus</a>，采用的数据格式如下：</p><p><strong>timit_11/</strong></p><ul><li>train_11.npy –&gt; 训练数据</li><li>train_label_11.npy –&gt; 逐帧phoneme标签（0-38）</li><li>test_11.npy –&gt; 测试数据</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入需要的包</span><span class="token keyword">import</span> os<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset<span class="token keyword">import</span> time<span class="token keyword">import</span> random<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义一些函数"><a href="#定义一些函数" class="headerlink" title="定义一些函数"></a>定义一些函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your model (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_accuracy</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot accuracy of your model (train &amp; dev acc) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training epochs'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><p>从.npy文件中加载训练和测试数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading data ..."</span><span class="token punctuation">)</span>data_root <span class="token operator">=</span> <span class="token string">'./timit_11/'</span>train <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>data_root <span class="token operator">+</span> <span class="token string">'train_11.npy'</span><span class="token punctuation">)</span>train_label <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>data_root <span class="token operator">+</span> <span class="token string">'train_label_11.npy'</span><span class="token punctuation">)</span>test <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>data_root <span class="token operator">+</span> <span class="token string">'test_11.npy'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Size of training data: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Size of testing data: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Loading data ...Size of training data: (1229932, 429)Size of testing data: (451552, 429)</code></pre><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TIMITDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            y <span class="token operator">=</span> y<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>label <span class="token operator">=</span> <span class="token boolean">None</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>label <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将训练数据划分为训练集和验证集，你可以通过改变变量 VAL_RATIO 来修改验证集的比例</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">VAL_RATIO <span class="token operator">=</span> <span class="token number">0.2</span>percent <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> VAL_RATIO<span class="token punctuation">)</span><span class="token punctuation">)</span>train_x<span class="token punctuation">,</span> val_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> val_y <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token punctuation">:</span> percent<span class="token punctuation">]</span><span class="token punctuation">,</span> train<span class="token punctuation">[</span>percent<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_label<span class="token punctuation">[</span><span class="token punctuation">:</span> percent<span class="token punctuation">]</span><span class="token punctuation">,</span> train_label<span class="token punctuation">[</span>percent<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Size of training set: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Size of validation set: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>val_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Size of training set: (983945, 429)Size of validation set: (245987, 429)</code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>根据Dataset制作DataLoader，你可以修改下面的变量 BATCH_SIZE</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">BATCH_SIZE<span class="token operator">=</span> <span class="token number">64</span>train_set <span class="token operator">=</span> TIMITDataset<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>val_set <span class="token operator">=</span> TIMITDataset<span class="token punctuation">(</span>val_x<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型实现相关函数"><a href="#模型实现相关函数" class="headerlink" title="模型实现相关函数"></a>模型实现相关函数</h2><h3 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h3><p>这部分可以自行修改，注意输入数据的维度为429，数据类别有39种</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">429</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 训练模型 '''</span>    n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>   <span class="token comment"># 最大迭代次数</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer使用Adam</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 损失函数使用CrossEntropyLoss</span>        best_acc <span class="token operator">=</span> <span class="token number">0.0</span>             <span class="token comment"># 用于记录验证时最好的准确率，并将此时的模型</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录训练损失</span>    acc_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录预测准确度</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 将模型参数的 gradient 至0</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 利用后向传播算出每个参数的gradient</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 更新模型参数</span>                        train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                train_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>                <span class="token comment"># 每次迭代后，在验证集中验证你的模型</span>        dev_acc<span class="token punctuation">,</span> dev_loss <span class="token operator">=</span> dev<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_acc<span class="token punctuation">)</span>        loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_loss<span class="token punctuation">)</span>                <span class="token comment"># 将结果打印出来</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%02d/%02d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f'</span> <span class="token operator">%</span> \              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n_epochs<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> dev_acc<span class="token punctuation">,</span> dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># 当模型性能提升时保存模型</span>        <span class="token keyword">if</span> dev_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>            best_acc <span class="token operator">=</span> dev_acc            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">, accuracy = </span><span class="token interpolation"><span class="token punctuation">{</span>best_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 保存模型到指定路径</span>                <span class="token keyword">return</span> best_acc<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    dev_loss<span class="token punctuation">,</span> dev_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            dev_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            dev_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    dev_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    dev_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">)</span>        <span class="token keyword">return</span> dev_acc<span class="token punctuation">,</span> dev_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>config中包含模型训练的超参数（可以进行调节）和保存模型的路径</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 可以进行调节来提升模型性能</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span>                <span class="token comment"># 最大迭代次数</span>    <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.0001</span><span class="token punctuation">,</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment"># 模型保存路径</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型加载和训练"><a href="#模型加载和训练" class="headerlink" title="模型加载和训练"></a>模型加载和训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>best_acc<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record <span class="token operator">=</span> train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>[01/20] 61.04 sec(s) Train Acc: 0.575976 Loss: 1.418989 | Val Acc: 0.679743 loss: 1.018808Saving model (epoch = 01, accuracy = 0.6797)[02/20] 59.27 sec(s) Train Acc: 0.636308 Loss: 1.162909 | Val Acc: 0.697712 loss: 0.942522Saving model (epoch = 02, accuracy = 0.6977)[03/20] 57.94 sec(s) Train Acc: 0.655783 Loss: 1.090724 | Val Acc: 0.708123 loss: 0.903914Saving model (epoch = 03, accuracy = 0.7081)[04/20] 57.50 sec(s) Train Acc: 0.667945 Loss: 1.045382 | Val Acc: 0.716786 loss: 0.870373Saving model (epoch = 04, accuracy = 0.7168)[05/20] 57.50 sec(s) Train Acc: 0.676864 Loss: 1.011510 | Val Acc: 0.720506 loss: 0.856811Saving model (epoch = 05, accuracy = 0.7205)[06/20] 57.69 sec(s) Train Acc: 0.684058 Loss: 0.983198 | Val Acc: 0.724416 loss: 0.837952Saving model (epoch = 06, accuracy = 0.7244)[07/20] 57.36 sec(s) Train Acc: 0.690473 Loss: 0.961224 | Val Acc: 0.726238 loss: 0.831526Saving model (epoch = 07, accuracy = 0.7262)[08/20] 56.88 sec(s) Train Acc: 0.695339 Loss: 0.943797 | Val Acc: 0.728803 loss: 0.821308Saving model (epoch = 08, accuracy = 0.7288)[09/20] 56.70 sec(s) Train Acc: 0.699613 Loss: 0.928245 | Val Acc: 0.729120 loss: 0.819629Saving model (epoch = 09, accuracy = 0.7291)[10/20] 57.16 sec(s) Train Acc: 0.703794 Loss: 0.913152 | Val Acc: 0.733738 loss: 0.803043Saving model (epoch = 10, accuracy = 0.7337)[11/20] 56.80 sec(s) Train Acc: 0.706580 Loss: 0.901354 | Val Acc: 0.735575 loss: 0.798162Saving model (epoch = 11, accuracy = 0.7356)[12/20] 56.79 sec(s) Train Acc: 0.709608 Loss: 0.888328 | Val Acc: 0.735815 loss: 0.793815Saving model (epoch = 12, accuracy = 0.7358)[13/20] 57.12 sec(s) Train Acc: 0.712408 Loss: 0.879705 | Val Acc: 0.736096 loss: 0.796301Saving model (epoch = 13, accuracy = 0.7361)[14/20] 57.16 sec(s) Train Acc: 0.715146 Loss: 0.869005 | Val Acc: 0.738202 loss: 0.787290Saving model (epoch = 14, accuracy = 0.7382)[15/20] 57.15 sec(s) Train Acc: 0.717777 Loss: 0.860623 | Val Acc: 0.737059 loss: 0.793017[16/20] 57.05 sec(s) Train Acc: 0.719551 Loss: 0.853531 | Val Acc: 0.737689 loss: 0.788586[17/20] 57.11 sec(s) Train Acc: 0.721698 Loss: 0.845117 | Val Acc: 0.739344 loss: 0.784496Saving model (epoch = 17, accuracy = 0.7393)[18/20] 57.78 sec(s) Train Acc: 0.723899 Loss: 0.838226 | Val Acc: 0.740059 loss: 0.784261Saving model (epoch = 18, accuracy = 0.7401)[19/20] 58.68 sec(s) Train Acc: 0.725527 Loss: 0.832501 | Val Acc: 0.739783 loss: 0.782018[20/20] 58.36 sec(s) Train Acc: 0.726496 Loss: 0.827860 | Val Acc: 0.742173 loss: 0.777942Saving model (epoch = 20, accuracy = 0.7422)</code></pre><p><strong>可视化显示</strong></p><p>可视化显示可以看出训练过程中是否存在过拟合、模型不合适等问题</p><p>展示训练集和验证集中loss的变化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_learning_curve<span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'deep model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    </p><img src="/2022/05/05/hw2-classifier/output_23_0-16517416642191.png" class=""><p>​    </p><p>展示训练集和验证集中acc随迭代次数的变化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_accuracy<span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'deep model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/05/05/hw2-classifier/output_25_0-16517416642192.png" class=""><p>​    </p><h2 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h2><p>创建测试dataloader，从模型保存路径中加载模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建dataloader</span>test_set <span class="token operator">=</span> TIMITDataset<span class="token punctuation">(</span>test<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 加载模型</span><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>预测</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> x <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>                                x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>     <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                          pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> y <span class="token keyword">in</span> pred<span class="token punctuation">:</span>            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将测试集上的预测结果保存到.csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"predict.csv"</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Id,Category\n'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> y <span class="token keyword">in</span>  <span class="token builtin">enumerate</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{}\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Classifier </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java方法</title>
      <link href="/2022/05/04/java-fang-fa/"/>
      <url>/2022/05/04/java-fang-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="方法定义和调用"><a href="#方法定义和调用" class="headerlink" title="方法定义和调用"></a>方法定义和调用</h2><p>方法是一种语法结构，它可以把一段代码封装成一个功能，以方便重复调用，这样就提高了代码的重复性，使程序逻辑更加清晰。</p><p>以两个整数求和为例子，方法定义如下，函数声明中第一个int是<strong>返回值类型</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">int</span> a<span class="token punctuation">,</span> <span class="token keyword">int</span> b<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> c <span class="token operator">=</span> a <span class="token operator">+</span> b<span class="token punctuation">;</span>    <span class="token keyword">return</span> c<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可以在函数中调用，调用格式如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> rs <span class="token operator">=</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注意事项</strong></p><ul><li><p>方法的编写顺序无所谓，方法与方法之间是平级关系，不能嵌套定义</p></li><li><p>方法的返回值类型为void（无返回值），方法内则不能使用return返回数据，如果方法的返回值类型写了具体类型，方法内部则必须使用return返回对应类型的数据</p></li><li><p>return语句下面，不能编写代码，因为执行不到，属于无效的代码</p></li><li><p>方法不调用不执行，调用时必须严格匹配方法的参数情况</p></li><li><p>有返回值的方法调用时可以选择定义变量接受结果，或者直接输出调用，甚至直接调用；无返回值方法的调用只能直接调用一下</p></li></ul><h2 id="方法的参数传递机制"><a href="#方法的参数传递机制" class="headerlink" title="方法的参数传递机制"></a>方法的参数传递机制</h2><p><strong>Java的参数传递机制：值传递</strong></p><ul><li>在传输实参给方法的形参的时候，并不是传输实参变量本身，而是传输实参变量中存储的值</li></ul><p><strong>基本类型的传递机制</strong></p><ul><li><strong>形参</strong>：以方法为例，就是方法定义时的变量</li><li><strong>实参</strong>：在方法内部定义的变量</li><li>传输的是实参存储的值</li></ul><p><strong>引用类型的参数传递</strong></p><p>也是<strong>值传递</strong>，与基本类型的参数在传递时的不同：基本类型的参数传输存储的数据值，而引用类型的参数传输存储的<strong>地址值</strong>。</p><h2 id="方法重载"><a href="#方法重载" class="headerlink" title="方法重载"></a>方法重载</h2><ul><li>同一个类中，出现多个方法名称相同，但是形参列表是不同的，那么这些方法就是重载方法</li></ul><p><strong>作用</strong></p><ul><li>可读性好，方法名称相同提示是同一类型的功能，通过形参不同实现功能差异化的选择，这是一种专业的代码设计，还可以提高开发效率</li></ul><p><strong>识别技巧</strong></p><ul><li>只要是同一个类中，方法名称相同、形参列表不同，那么它们就是重载的方法，其他不关心</li><li>形参列表不同指的是：形参的<strong>个数、类型、顺序</strong>不同，不关心形参的名称</li></ul><p><strong>return关键字单独使用</strong></p><ul><li>return; —&gt; 可以立即<strong>跳出并结束当前方法的执行</strong>；return关键字单独使用可以放在任何方法中</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>数组</title>
      <link href="/2022/05/04/shu-zu/"/>
      <url>/2022/05/04/shu-zu/</url>
      
        <content type="html"><![CDATA[<h2 id="数组的定义"><a href="#数组的定义" class="headerlink" title="数组的定义"></a>数组的定义</h2><ul><li>数组就是用来存储一批同种类型数据的内存区域（可以理解为容器）</li></ul><h3 id="静态初始化数组"><a href="#静态初始化数组" class="headerlink" title="静态初始化数组"></a>静态初始化数组</h3><p>定义数组的时候直接给数组赋值</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 完整格式</span>数据类型<span class="token punctuation">[</span><span class="token punctuation">]</span> 数组名 <span class="token operator">=</span> <span class="token keyword">new</span> 数组类型<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">{</span>元素<span class="token number">1</span><span class="token punctuation">,</span> 元素<span class="token number">2</span><span class="token punctuation">,</span> 元素<span class="token number">3.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token comment">// 简化格式</span>数据类型<span class="token punctuation">[</span><span class="token punctuation">]</span> 数组名 <span class="token operator">=</span> <span class="token punctuation">{</span>元素<span class="token number">1</span><span class="token punctuation">,</span> 元素<span class="token number">2</span><span class="token punctuation">,</span> 元素<span class="token number">3.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> ages <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>数组变量名中存储的是数组在内存中的地址，数组是引用类型</li></ul><p><strong>数组的访问</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 数组名称[索引]</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>           <span class="token comment">// 取值</span>arr<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">;</span>                         <span class="token comment">// 赋值</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>arr<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token comment">// 获取长度</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意事项</strong></p><ul><li><p>也可以写成”<strong>数组类型 数组名[]</strong>“，但习惯于前面的定义格式</p></li><li><p>什么类型的数组存放什么类型的数据，否则报错</p></li><li><p>数组一旦定义出来，程序执行过程中，长度和类型就固定了</p></li></ul><h3 id="动态初始化数组"><a href="#动态初始化数组" class="headerlink" title="动态初始化数组"></a>动态初始化数组</h3><ul><li>定义数组的时候只确定元素的类型和数组的长度，之后再存入具体数据</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 格式</span>数据类型<span class="token punctuation">[</span><span class="token punctuation">]</span> 数组名 <span class="token operator">=</span> <span class="token keyword">new</span> 数据类型<span class="token punctuation">[</span>长度<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">int</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>动态初始化元素默认值</strong></p><img src="/2022/05/04/shu-zu/image-20220425153733090.png" class=""><h2 id="数组的遍历"><a href="#数组的遍历" class="headerlink" title="数组的遍历"></a>数组的遍历</h2><ul><li>一个一个的把数据访问一遍</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> ages <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token comment">// 快捷方式：ages.fori + enter</span><span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> ages<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>ages<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Java内存分配介绍"><a href="#Java内存分配介绍" class="headerlink" title="Java内存分配介绍"></a>Java内存分配介绍</h2><ul><li>方法区：字节码文件加载时进入的内存</li><li>栈：方法运行时所进入的内存，变量也是在这里</li><li>堆：new 出来的东西会在这块内存中开辟空间并产生地址</li></ul><img src="/2022/05/04/shu-zu/image-20220504093328882.png" class=""><p>把一个数组赋值给另一个数组（地址），则这两个数组变量指向同一个数组对象，改变其中一个数组里面的值，另一个数组也会随着改变。</p>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java数组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序流程控制</title>
      <link href="/2022/05/04/cheng-xu-liu-cheng-kong-zhi/"/>
      <url>/2022/05/04/cheng-xu-liu-cheng-kong-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="分支结构"><a href="#分支结构" class="headerlink" title="分支结构"></a>分支结构</h2><h3 id="If分支"><a href="#If分支" class="headerlink" title="If分支"></a>If分支</h3><ul><li>根据判定的结果决定执行某个分支的代码</li></ul><p><strong>if分支的三种格式</strong></p><ul><li>格式1</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">if</span><span class="token punctuation">(</span>条件表达式<span class="token punctuation">)</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>；<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>格式2</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">if</span><span class="token punctuation">(</span>条件表达式<span class="token punctuation">)</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">else</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>格式3</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">if</span><span class="token punctuation">(</span>条件表达式<span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>条件表达式<span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">else</span><span class="token punctuation">{</span> 代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="switch分支"><a href="#switch分支" class="headerlink" title="switch分支"></a>switch分支</h3><ul><li>也是匹配条件去执行分支，适合做值匹配的分支选择。</li></ul><p><strong>格式</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">switch</span><span class="token punctuation">(</span>表达式<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">case</span> 值<span class="token number">1</span><span class="token operator">:</span>执行代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span><span class="token keyword">case</span> 值<span class="token number">2</span><span class="token operator">:</span>执行代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">case</span> 值n<span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span>执行代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token keyword">break</span><span class="token punctuation">;</span><span class="token keyword">default</span><span class="token operator">:</span>执行代码<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>switch分支注意事项</strong></p><ul><li>表达式类型只能是byte、short、int、char、String，不支持double、float、long</li><li>case给出的值不允许重复，且只能是字面量，不能是变量</li><li>不要忘记写break，否则会出现穿透现象</li></ul><h2 id="循环结构"><a href="#循环结构" class="headerlink" title="循环结构"></a>循环结构</h2><ul><li>控制一段代码反复执行很多次</li></ul><h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><p><strong>格式</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">for</span><span class="token punctuation">(</span>初始化语句<span class="token punctuation">;</span>循环条件<span class="token punctuation">;</span>迭代语句<span class="token punctuation">)</span><span class="token punctuation">{</span>    循环体语句（重复执行的代码）<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h3><p><strong>格式</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java">初始化语句<span class="token punctuation">;</span><span class="token keyword">while</span><span class="token punctuation">(</span>循环条件<span class="token punctuation">)</span><span class="token punctuation">{</span>循环体语句<span class="token punctuation">;</span>迭代语句<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="do-while循环"><a href="#do-while循环" class="headerlink" title="do-while循环"></a>do-while循环</h3><p><strong>格式</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java">初始化语句<span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token punctuation">{</span>    循环体语句<span class="token punctuation">;</span>    迭代语句<span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">while</span><span class="token punctuation">(</span>循环条件<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>特点：一定会运行一次循环体语句</li></ul><p>基于这三个循环结构，可以实现死循环和嵌套循环</p><h2 id="跳转关键词"><a href="#跳转关键词" class="headerlink" title="跳转关键词"></a>跳转关键词</h2><ul><li>break ： 跳出并结束当前所在循环的执行</li><li>continue ： 跳出当前循环的当次执行，进入循环的下一次</li></ul><p><strong>注意事项</strong></p><p>break只能用于结束所在循环，或者结束所在switch分支的执行；continue只能在循环中进行使用</p><h2 id="随机数Random"><a href="#随机数Random" class="headerlink" title="随机数Random"></a>随机数Random</h2><ul><li>用于在程序中获取随机数的技术</li></ul><p><strong>Random的使用</strong></p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">random</span><span class="token punctuation">;</span><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Random</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">RandomDemo1</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">Random</span> random <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Random</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> number <span class="token operator">=</span> random<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>number<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>步骤</strong>：导包$\Rightarrow$创建对象$\Rightarrow$调用相关函数</p><p>上述代码中 nextInt(n) 功能只能生成：0至n-1之间的随机数，不包含n。因此要生成区间随机数可以用减加法</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 3 - 17 ==&gt; (0 - 14) + 3</span><span class="token keyword">int</span> number <span class="token operator">=</span> random<span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">3</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java基础语法</title>
      <link href="/2022/05/04/java-ji-chu-yu-fa/"/>
      <url>/2022/05/04/java-ji-chu-yu-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p><strong>手动注释</strong></p><ul><li>单行注释： //</li><li>多行注释： /* */</li><li>文档注释： /** */ 注意：文档注释的内容将来可以提取到程序说明书中去</li></ul><p><strong>快捷注释</strong></p><ul><li>单行注释： Ctrl + /</li><li>多行注释： Ctrl + Shift + /</li></ul><h2 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h2><p>计算机是用来处理数据的，字面量就是告诉程序员：数据在程序中的书写格式。</p><p><strong>常用数据</strong></p><img src="/2022/05/04/java-ji-chu-yu-fa/image-20220328171031761.png" class=""><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p><strong>变量的作用</strong></p><ul><li>存储一个数据，存储的数据可以变化</li></ul><p><strong>变量定义的格式</strong></p><ul><li>数据类型 变量名称 = 初始值;</li><li>= 赋值：从右边往左执行</li></ul><p><strong>变量使用的注意事项</strong></p><ul><li>变量要先声明再使用</li><li>变量声明后，不能存储其他类型的数据</li><li>变量的有效范围是从定义开始到”}”截止，且在同一范围内部不能定义2个同名变量</li><li>变量定义的时候可以没有初始值，但是在使用的时候必须给初始值</li></ul><p><strong>注：</strong>Java程序中支持书写二进制、八进制、十六进制的数据，分别需要以0B或0b、0、0X或0x开头</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p><strong>作用</strong></p><ul><li>约束变量存储数据的格式</li></ul><p><strong>分类</strong></p><ul><li>引用数据类型（如String等）</li><li>基本数据类型：4大类8种</li></ul><img src="/2022/05/04/java-ji-chu-yu-fa/image-20220328192903776.png" class=""><h2 id="关键字、标识符"><a href="#关键字、标识符" class="headerlink" title="关键字、标识符"></a>关键字、标识符</h2><p><strong>关键字</strong></p><ul><li>Java自己保留的一些单词，作为特殊功能的</li><li>不能用来作为类名或者变量的名称</li></ul><img src="/2022/05/04/java-ji-chu-yu-fa/image-20220328193625441.png" class=""><p><strong>标识符</strong></p><ul><li>标识符就是由一些字符、符号组合起来的名称，用于给类，方法，变量等起名字的规则</li></ul><p><strong>标识符的要求</strong></p><ul><li>基本要求：由数字、字母、下划线(_)和美元符($)等组成</li><li>强制要求：不能以数字开头、不能是关键字、区分大小写</li></ul><p><strong>命名指导规范</strong></p><ul><li>变量名称：满足标识符规则，建议全英文、有意义、首字母小写，满足“驼峰模式”，例如：int studentNumber = 59</li><li>类名称：满足标识符规则，建议全英文、有意义、首字母大写，满足“驼峰模式”，例如：HelloWorld.java</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java快速入门和IDEA的使用</title>
      <link href="/2022/05/04/java-kuai-su-ru-men-he-idea-de-shi-yong/"/>
      <url>/2022/05/04/java-kuai-su-ru-men-he-idea-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h2 id="入门程序-HelloWorld"><a href="#入门程序-HelloWorld" class="headerlink" title="入门程序-HelloWorld"></a>入门程序-HelloWorld</h2><p>1、开发一个Java程序要经历的步骤</p><ul><li><strong>编写、编译(javac)、运行(java)</strong></li></ul><p>2、Java代码编写的基本要求</p><ul><li>文件名称的后缀必须是java结尾</li><li>文件名称必须与代码的类名称一致</li><li>必须使用英文模式下的符号</li></ul><p>3、JDK(Java Development Kit，Java开发工具包)的组成</p><ul><li><strong>JVM</strong>(Java Virtual Machine)：Java 虚拟机，正真运行Java程序的地方</li><li><strong>核心类库</strong>：Java自己写好的程序，给程序员自己的程序调用的</li><li><strong>JRE</strong>(Java Runtime Enviroment)：Java的运行环境，包括上面两个</li><li><strong>开发工具</strong>：javac、java…</li></ul><p>以HelloWorld程序为例，先用javac编译HelloWorld.java文件生成HelloWorld.class文件，然后通过java HelloWorld指令送到JRE中，JRE通过调用核心类库，然后送到JVM中运行。</p><h2 id="IDEA入门程序"><a href="#IDEA入门程序" class="headerlink" title="IDEA入门程序"></a>IDEA入门程序</h2><p>1、IDEA的结构</p><ul><li><strong>project - module - package - class</strong></li><li>project中可以创建多个module</li><li>module中可以创建多个package</li><li>package中可以创建多个class</li></ul><p>2、新建</p><ul><li><strong>new project / module / package / class</strong></li></ul><p>3、常用快捷键</p><ul><li>main/psvm、sout、….           快速输入相关代码</li><li>Ctrl + D                                      复制当前行数据到下一行</li><li>Ctrl + Y                                       删除所在行，建议用Ctrl + X</li><li>Ctrl + Alt + L                             格式化代码</li><li>Ctrl + /， Ctrl + Shift + /          对代码进行注释</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习的可解释性</title>
      <link href="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/"/>
      <url>/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们都知道神经网络是一个黑箱模型，虽然它在测试集的准确率可以达到很高，但很难解释清楚其中缘由。而有些模型像线性模型、决策树等虽然很容易解释，但模型往往不够强大，在测试集上有很差的表现。然而，在测试集上表现好并不意味着模型很智能，在一些领域中，我们不但需要模型的性能好，还需要知道为什么，我们才会放心的使用这个模型。如当我们用ML挑选简历时，我们需要知道机器学习模型是依据应聘人的那些特征做出推荐的决定，而不单单是该模型在测试集中表现好。</p><p>可解释性人工智能（Explainable AI）这个技术可以用于填补这个鸿沟，但可解释性并不意味着我们要完全明白ML模型是如何运作的，就像我们不完全知道人类的大脑运行的原理，但是我们相信人类做出的决定。我们需要的只是ML模型给我一个它做出决定的理由，而这个理由可以被我们和我们的顾客以及老板满意。</p><h2 id="种类"><a href="#种类" class="headerlink" title="种类"></a>种类</h2><p>机器学习的可解释性包括两个方面，一个是local explanation，另一个是global explanation。以图像分类器为例，local explanation需要回答的是为什么你觉得这张图片属于这个类别？而global explanation需要回答的是这些类别具有什么样的特征？</p><h3 id="Local-explanation"><a href="#Local-explanation" class="headerlink" title="Local explanation"></a>Local explanation</h3><p>仍然以图像分类器为例，Local explanation的目标是每个component对于最终结果的重要性程度，这可以通过移动或修改其中一个component来看模型输出的变化来实现，模型输出改变越大，意味着这个component越重要。</p><p><strong>基于梯度的方法</strong></p><p>假设输入为一张图像$x$，它有很多component ${x_{1},x_{2},…,x_{N}}$ 组成。如果输入是image，则component一般是pixel，segment等。如果输入是text，则component一般是word。现在我们依次给每个component加上一个$\Delta x$，对应就会得到一个loss $\Delta e$（模型输出和真实值之间）。我们想要知道每个component对于模型判断的重要性，只需计算对应的$|\frac{\Delta e}{\Delta x}|=|\frac{\partial e}{\partial x_{n}}|$得到。利用这些数值，我们可以绘制saliency map，如下图，亮度越高（即前面计算的数值越大）的区域代表这个component对于预测结果的影响越大</p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503203524561.png" class=""><p>基于梯度来判断component重要性的方法也存在局限性：Noisy Gradient和Gradient Saturation</p><p>Noisy Gradient是有些梯度会非常大（如下图），我们可以通过在计算梯度时添加多个扰动，然后计算加入扰动后的平均梯度避免，这种方法被称作SmoothGrad，相关见论文<a href="https://arxiv.org/abs/1706.03825">Randomly add noises to the input image, get saliency maps of the noisy images, and average them</a></p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503204447762.png" class=""><p>Gradient Saturation是指某个因素对图片的预测起到了推动作用，但是这个作用是有限的，超过一定程度后就不再增加预测的几率。以预测大象这个类别为例，很明显鼻子的长度是一个很重要的影响因素。随着鼻子长度的增加，预测的几率的几率会增加，但超过一定数值后，预测概率不会增加，即出现变化率为0的情况，但这个鼻子长度的动物已经不能算是大象了。</p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503205121997.png" class=""><h3 id="Global-explanation"><a href="#Global-explanation" class="headerlink" title="Global explanation"></a>Global explanation</h3><p>假设我们已经训练好一个CNN网络结构，将一张图片X输入CNN，在每一个filter后提取一个feature map，每个feature map都有对应的特征值$a_{ij}$，我们可以通过使这些特征值之和最大为目标找到对应的输入X，通过观察这个输入的特征我们就可以判断这个filter可以侦察到图片的某些特征。或者我们可以以输出为目标，找到输出为某种类别概率最高对应的输入X即可得到该类别图片对应有哪些特征？</p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503210224555.png" class=""><p>但事实上，我们更多时候我们找到的X是一堆杂讯，我们根本不能从中学习到什么？其中一个解决方法是在优化目标上加上一个限制R(X)，R(X)应符合图案本身的设计，同时你还需调影响结果的超参数。下面展示<a href="https://arxiv.org/abs/1506.06579">Understanding Neural Networks Through Deep Visualization</a>侦察到各种类别对应的图片特征。</p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503211706831.png" class=""><p>另外还有一种更有效的方式，利用Generator。利用GAN训练一个Image Generator，可以通过低维度的向量通过Generator得到一个图片。与前面通过对应某个类别概率最大找到模型对应输入X不同的是，这里我们找到对应的输入z，然后将这个z输入Generator中得到Image X。借助这个图片，我们就可以找出该类别具有的一些特征。</p><img src="/2022/05/03/ji-qi-xue-xi-de-ke-jie-shi-xing/image-20220503212409392.png" class=""><p>推荐论文：<a href="https://arxiv.org/abs/1612.00005">Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://www.youtube.com/watch?v=WQY85vaQfTI">李宏毅2021机器学习课程</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Explainable AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对抗攻击与防御</title>
      <link href="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/"/>
      <url>/2022/04/30/dui-kang-gong-ji-yu-fang-yu/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>对抗攻击英文为adversarial attack，即对输入样本添加一些人无法察觉的细微改动，导致模型以高置信度输出一个错误的答案。在现实生活中，我们建立的系统很多时候会遇到干扰，甚至是人为的蓄意攻击，如垃圾邮件、恶意软件和网络入侵等。因此机器训练出来的模型不光性能要好，还要能够对抗人类的恶意，这就是对抗攻击与防御产生的动机。</p><h2 id="对抗攻击"><a href="#对抗攻击" class="headerlink" title="对抗攻击"></a>对抗攻击</h2><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>以图片攻击为例，图片可以看成一个很长的向量，如果在一些重要的像素部分加上一个很小的杂讯，再把它输入到神经网络。虽然我们人眼识别不出来这个改动，但通过深度学习训练出来的分类可能就会误判。下图只是为了直观，但在实际应用中这种攻击人眼是识别不出来的。</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220429154701030.png" class=""><p>通常没有被攻击的图片称为Benign Image，被攻击的图片称为Attacked Image。按照攻击得到的类别，对抗攻击可以分为：</p><ul><li>定向攻击（targeted attack）：误分类成一个指定的类别</li><li>非定向攻击（non-targeted attack）：误分类成其他类别（只要不是正确的类别即可）</li></ul><h3 id="数学理论"><a href="#数学理论" class="headerlink" title="数学理论"></a>数学理论</h3><p>假设benign image是$x^{0}$，输入到一个图像分类器中，输出为$y^{0}=f(x^{0})$，该图片对应的真实分类为cat，$\overset{-}{y}$</p><p>被攻击后的输入是x，输出$y=f(x)$，想要攻击成功的话，就得让y和$\overset{-}{y}$相差越大越好。如果是定向攻击的话，还要保证y和$y^{target}$越接近越好。</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220429160059119.png" class=""><p>因此这个模型的损失函数（Loss Function）可以定义为：</p><ul><li>Non-targeted attack: $L(x)=-e(y,\overset{-}{y})$</li><li>targeted attack: $L(x)=-e(y,\overset{-}{y})+e(y,y^{target})$</li></ul><p>式中函数e()表示输入之间的差异，目标是使L(x)越小越好</p><p>另外正如我们前面所说，这些攻击是不容易被人类观察到的，即$x$和$x^{0}$之间的差距越小越好，所有整个模型需要优化的表达式为：</p><p>$$x^{*}=arg \underset{d(x,x^{0})\leq\epsilon}{min}L(x)$$</p><p>怎么计算$d(x,x^{0})$呢，通常采用的是向量p-范数</p><ul><li><p>2-范数L2-norm ：$d(x,x^{0})=\parallel \Delta x \parallel_{2} = \sqrt{\overset{n}{\underset{i=1}{\sum}}|\Delta x_{i}|^{2}}$</p></li><li><p>无穷范数L-infinity ：$d(x,x^{0})=\parallel \Delta x \parallel_{\infty} = \underset{i}{max}|\Delta x_{i}|$</p></li></ul><p>确定后模型的损失函数后，我们就可以用其来确定输入，这与往常的神经网络更新网络结构的参数是不一样的，因为被攻击的模型已经确认。</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220429165210157.png" class=""><p>同样，我们可以采用梯度下降法确定输入x，因为模型对输入加了限制，因此我们需对优化算法进行一些修改。以L-infinity确认$d(x,x^{0})$，则为了满足$d(x,x^{0})\leq\epsilon$的限制，只需将每个像素的的更新都在以$\epsilon$为边长的正方形内。</p><p>从整个数学理论上看，如果我们想对攻击进行改进，就需要使用更有效的限制或者更好的优化方法。</p><p>李宏毅老师课堂上了讲解了两种优化方法，下面提供了论文的链接，感兴趣的可以去了解一下</p><ul><li><a href="https://arxiv.org/abs/1412.6572"><strong>Fast Gradient Sign Method (FGSM)</strong></a></li><li><a href="https://arxiv.org/abs/1607.02533"><strong>Iterative FGSM</strong></a></li></ul><p>FGSM中作者的想法很大胆，只使用一次迭代就可以达到攻击的目的。作者只是对上面的方法做了一个简单的修改，在对损失函数求导得到的梯度上加一个符号函数sign（大于0输出1，小于0输出-1），这样就能满足输入限制的要求</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220429175930538.png" class=""><h2 id="白盒攻击-amp-黑盒攻击"><a href="#白盒攻击-amp-黑盒攻击" class="headerlink" title="白盒攻击&amp;黑盒攻击"></a>白盒攻击&amp;黑盒攻击</h2><p>前面我们列举的例子就是白盒攻击（white box attack），即在攻击之前我们就已经知道模型的参数。但在通常情况下，我们是不知道模型的参数，这种情况下的攻击被称作黑盒攻击（black box attack）。</p><h3 id="黑盒攻击"><a href="#黑盒攻击" class="headerlink" title="黑盒攻击"></a>黑盒攻击</h3><ul><li>不知道目标模型的参数，但有目标模型的训练资料</li></ul><p>在这种情况之下，我们可以训练一个替代模型，然后使用代理模型产生被攻击的对象</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220430153827720.png" class=""><p>那么上面所说的黑箱攻击容易成功吗？</p><p>从论文<a href="https://arxiv.org/pdf/1611.02770.pdf">Delving into Transferable Adversarial Examples and Black-box Attacks</a>的实验结果来看，是容易成功的</p><p>下图中有两个表格，第一个表格中列代表被攻击的模型，行代表的是代理模型。每个单元格中的数值表示在行中模型生成攻击成功的图像在列中模型上评估的正确性。因此准确率越低，代表产生的攻击越有效。对角线上代理模型和攻击模型是同一模型，可以看成是白盒攻击。不同行不同列即为黑盒攻击，从实验结果中可以看出得出的准确率都在50%以下，因此黑箱攻击还是挺有效。</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220430184814214.png" class=""><p>第二个表格中“-”好代表没有用这个模型训练生成攻击成功的图像，因此在第二个表格中，对角线代表的是黑盒攻击，因为代理模型中并未采用待攻击的模型。这些黑盒攻击中，准确率最高为6%，比第一个表格中只使用一个代理模型产生的黑盒攻击的模型准确率降了很多，说明采用多个代理模型产生的黑盒攻击更有效。</p><p>你可能还是会怀疑黑盒攻击为什么会产生效果，这篇论文作者给出的j解释是每个模型产生攻击的方向很相似，想更深入了解这个问题可以看论文<a href="https://arxiv.org/pdf/1905.02175.pdf">Adversarial Examples Are Not Bugs, They Are Features</a></p><p>另外还有很多黑盒攻击：</p><ul><li><a href="https://arxiv.org/pdf/1710.08864.pdf">One Pixel Attack for Fooling Deep Neural Networks</a>，只需要改变一个像素就可以达到攻击的目的</li><li><a href="https://arxiv.org/pdf/1610.08401.pdf">Universal adversarial perturbations</a>，使用一个通用的非常小的扰动就可以让攻击成功</li></ul><p>上面讲述的对抗攻击都是应用在图像上，其实对抗攻击还可以应用于语言处理、自然语言处理以及我们的日常生活中，因此我们需要想办法做好防御，来抵御这些来自人类的恶意。</p><h2 id="防御"><a href="#防御" class="headerlink" title="防御"></a>防御</h2><p>防御有以下两种：被动防御和主动防御</p><h3 id="被动防御"><a href="#被动防御" class="headerlink" title="被动防御"></a>被动防御</h3><p>以图像攻击为例，被动防御中最经典的做法就是在图像进入模型之前在一个filter（滤波器），这样会使那些使得攻击成功的扰动信号失真，从而使攻击失效。</p><img src="/2022/04/30/dui-kang-gong-ji-yu-fang-yu/image-20220430192108405.png" class=""><p>常用的方法有：</p><ul><li>将输入图像轻微模糊化，但并不影响分类</li><li>图像压缩（先压缩再解压从而消除攻击）</li><li>使用Generator技术生成和输入图像几乎一摸一样的image</li><li>随机防御（Randomization），有几种防御手段，随机选择其中一个，目的是预防防御预先被人知道</li></ul><h3 id="主动防御"><a href="#主动防御" class="headerlink" title="主动防御"></a>主动防御</h3><p>主动防御为每一张图像生成一个对抗图像，然后将生成的对抗图像和原始图像都丢入模型中进行训练（<strong>对抗训练</strong>），从而增强了模型的鲁棒性。这种方法也可以看作一种<strong>数据增强</strong>（Data Augmentation）的手段，缺点就是成倍的增加计算量。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://www.youtube.com/watch?v=xGQKhbjrFRk">李宏毅2021机器学习课程</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Adversarial Attack </tag>
            
            <tag> Defense </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动微分</title>
      <link href="/2022/04/27/zi-dong-wei-fen/"/>
      <url>/2022/04/27/zi-dong-wei-fen/</url>
      
        <content type="html"><![CDATA[<p>在学习这节之前，我们需先了解一些基本的微积分知识，如导数、微分、偏导数及链式法则等。如果你对这些知识不太了解，请自行在网上找相关资料学习，这是因为求导是几乎所有深度学习优化算法的关键步骤。</p><p>有过算法实现经验的小伙伴可能有过这种体验，如果一个模型需要通过算法率定的参数够多，自己通过梯度下降法实现模型参数的更新是一件很痛苦的事，而且还容易算错。深度学习pytorch框架通过自动计算导数（自动微分）来帮我们实现这个痛苦的过程。</p><p>那么pytorch是如何实现自动微分？在实际应用中，系统会根据我们设计的模型构建出一个计算图，来跟踪计算是那些数据通过哪些操作组合产生输出。自动微分在计算图的基础上可以实现反向传播梯度（反向传播）来算出每个参数的偏导数，进而我们可以利用这些偏导数的数值来更新模型参数。</p><h2 id="简单例子"><a href="#简单例子" class="headerlink" title="简单例子"></a>简单例子</h2><p>我们用函数$y = 2x^{T}x$这个简单的例子来展示pytorch是如何实现自动微分的。首先，我们创建变量x并为其分配一个初始值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4.0</span><span class="token punctuation">)</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor([0., 1., 2., 3.])</code></pre><p>在计算y关于x的梯度之前，我们需要一个地方来存储梯度。实际操作中，我们会经常成千上万次地更新相同的参数，所以就不可能在每次对一个参数求导时都分配新的内存，因为每次都分配新的内存可能很快就会将内存耗尽。注意，一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># 等价于x = torch.arange(4.0,requires_grad=True)</span>x<span class="token punctuation">.</span>grad        <span class="token comment"># 默认值为None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>现在让我们计算y</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">y <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor(28., grad_fn=&lt;MulBackward0&gt;)</code></pre><p>x是一个长度为4的向量，计算x和x的点积，得到一个标量赋值给y输出。接下来，我们通过调用反向传播函数来自动计算y关于x每个分量的梯度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([ 0.,  4.,  8., 12.])</code></pre><p>根据导数运算，函数$y=2x^{T}x$关于x的梯度是4x，通过这可以验证上述梯度计算是否正确</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad <span class="token operator">==</span> <span class="token number">4</span> <span class="token operator">*</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([True, True, True, True])</code></pre><p>上述就是pytorch通过反向传播计算梯度，如果你想计算x的另一个函数的梯度，需要通过x.grad.zero_()消除之前的梯度值。这是因为在默认情况下，pytorch会自动累积梯度。</p><h2 id="非标量变量的反向传播"><a href="#非标量变量的反向传播" class="headerlink" title="非标量变量的反向传播"></a>非标量变量的反向传播</h2><p>当y不是标量时，向量y关于向量x的导数是一个矩阵，对于高阶和高维的y和x，求导的结果是一个高阶张量。当我们调用向量的反向计算时，我们通常会计算一批训练样本对应损失函数的导数。但在这，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。由于我们只想求偏导数的和，因此可以传递一个都是1的梯度的函数，然后通过链式法则便可实现。这个函数可以通过$y.sum()=y_{1}+y_{2}+…+y_{n}$实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 消除之前的梯度</span>y <span class="token operator">=</span> x <span class="token operator">*</span> xy<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>tensor([0., 2., 4., 6.])</code></pre><h2 id="分离计算"><a href="#分离计算" class="headerlink" title="分离计算"></a>分离计算</h2><p>有时，我们希望将某些计算移动到记录的计算图之外。例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。想象⼀下，我们想计算z关于x的梯度，但由于某种原因，我们希望将y视为⼀个常数，并且只考虑到x在y被计算后发挥的作⽤。</p><p>在这⾥，我们可以分离y来返回⼀个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息。换句话说，梯度不会向后流经u到x。因此，下⾯的反向传播函数计算z=u*x关于x的偏导数，并将u作为常数处理，而不是z=x*x*x关于x的偏导数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y <span class="token operator">=</span> x <span class="token operator">*</span> xu <span class="token operator">=</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>z <span class="token operator">=</span> u <span class="token operator">*</span> xz<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad <span class="token operator">==</span> u<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([0., 1., 4., 9.]), tensor([True, True, True, True]))</code></pre><p>由于刚刚记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x*x关于x的导数，即2*x</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">*</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([0., 2., 4., 6.]), tensor([True, True, True, True]))</code></pre><p>前面我们通过一些例子学习了pytorch是如何自动计算导数，用一句话总结就是：首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，最后访问得到的梯度。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基本线性代数运算</title>
      <link href="/2022/04/26/ji-ben-xian-xing-dai-shu-yun-suan/"/>
      <url>/2022/04/26/ji-ben-xian-xing-dai-shu-yun-suan/</url>
      
        <content type="html"><![CDATA[<p>在实现深度学习模型时，我们难免会对数据进行操作，因此我们需要部分线性代数相关的内容。这节我们将学习线性代数中的基本数学对象和运算，并通过相关代码来表现它们。</p><h2 id="标量"><a href="#标量" class="headerlink" title="标量"></a>标量</h2><p>我们称仅包含一个数值的为标量，它可以由只有一个元素的张量表示。下面我们简单实例化两个标量，并执行一些熟悉的算术运算。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span>x <span class="token operator">+</span> y<span class="token punctuation">,</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> x <span class="token operator">/</span> y<span class="token punctuation">,</span> x <span class="token operator">**</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))</code></pre><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><p>你可以将向量视为标量值组成的列表，下面我们生成一个向量，并通过索引来访问元素。并像python数组一样，用相关函数来看向量的长度和形状。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([0, 1, 2, 3])</code></pre><p>通过索引获取向量中元素，注意索引是从0开始</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(3)</code></pre><p>通过调用python内置len()函数来访问张量的长度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>4</code></pre><p>我们可以用.shape属性访问向量的形状，该属性列出了张量沿 每个轴的长度。由于向量只有一个轴，形状只有一个元素，即向量的长度。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>torch.Size([4])</code></pre><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>矩阵将向量从一维推广到二维，在数学表示中，我们使用$A\in R^{mxn}$来表示矩阵A，A由m行和n列的实值标量组成。其中元素$a_{ij}$属于矩阵A第i行第j列，A的形状是(m,n)或m x n。当矩阵具有相同数量的行和列时，我们将A称为方阵。</p><p>我们可以通过reshape(m, n)或view(m, n)将一个长度为mn的向量变成形状为m x n的矩阵。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>       <span class="token comment"># 也可以用torch.arange(20).reshape(5, 4)</span>A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11],        [12, 13, 14, 15],        [16, 17, 18, 19]])</code></pre><p>我们也可以通过一些函数来生成一些特殊向量</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 构造一个未初始化的5x4矩阵</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment"># 构造一个随机初始化的5x4矩阵</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>       <span class="token comment"># 值在0到1</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>      <span class="token comment"># 标准正态分布，值在-1到1</span><span class="token comment"># 构造一个全零矩阵</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment"># 构造一个全一矩阵</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment"># 直接从数据中构造</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过.T属性访问矩阵的转置，转置就是交换矩阵中的行和列</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>T<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[ 0,  4,  8, 12, 16],        [ 1,  5,  9, 13, 17],        [ 2,  6, 10, 14, 18],        [ 3,  7, 11, 15, 19]])</code></pre><p><strong>索引和变形</strong></p><p>Pytorch的索引与Numpy一样，切片也是左闭右开</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>         <span class="token comment"># 取所有行，取第一列到最后一列</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[ 1,  2,  3],        [ 5,  6,  7],        [ 9, 10, 11],        [13, 14, 15],        [17, 18, 19]])</code></pre><p>变形在Pytorch中用view实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>B <span class="token operator">=</span> A<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># 指定某个维度为-1时，该维度会被自动计算</span>C <span class="token operator">=</span> A<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">torch.Size([5, 4])torch.Size([20])torch.Size([2, 10])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>我们可以通过item()函数将tensor中的value取出作为Python的数值，前提是该tensor内部只有一个数值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>10</code></pre><h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><p>前面我们介绍了标量、向量和矩阵，其实它们都是张量的一个表示形式。张量为我们提供了描述具有任意数量轴的n维数组的通用方法，它们的索引机制与矩阵类似。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],        [[12, 13, 14, 15],         [16, 17, 18, 19],         [20, 21, 22, 23]]])</code></pre><p><strong>张量算法的基本性质</strong></p><p>标量、向量、矩阵和任意数量轴的张量有⼀些实⽤的属性，如任意按元素的一元运算都不会改变张量的形状。同样，给定具有<br>相同形状的任意两个张量，任何按元素⼆元运算的结果都将是相同形状的张量。如二元运算Hadamard积（两个矩阵按元素乘法）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>B <span class="token operator">=</span> A<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 通过分配新内存，将A的⼀个副本分配给B</span>A<span class="token punctuation">,</span> A <span class="token operator">*</span> B<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[ 0.,  1.,  2.,  3.],         [ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.],         [12., 13., 14., 15.],         [16., 17., 18., 19.]]), tensor([[  0.,   1.,   4.,   9.],         [ 16.,  25.,  36.,  49.],         [ 64.,  81., 100., 121.],         [144., 169., 196., 225.],         [256., 289., 324., 361.]]))</code></pre><p>将张量乘以或加上⼀个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token number">2</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>a <span class="token operator">+</span> X<span class="token punctuation">,</span> <span class="token punctuation">(</span>a <span class="token operator">*</span> X<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[[ 2,  3,  4,  5],          [ 6,  7,  8,  9],          [10, 11, 12, 13]],          [[14, 15, 16, 17],          [18, 19, 20, 21],          [22, 23, 24, 25]]]), torch.Size([2, 3, 4]))</code></pre><h2 id="降维和交换维度"><a href="#降维和交换维度" class="headerlink" title="降维和交换维度"></a>降维和交换维度</h2><p><strong>降维</strong></p><p>我们可以对任意张量进行的一个有用的操作是计算其元素的和，这可以通过调用函数实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(torch.Size([5, 4]), tensor(190.))</code></pre><p>默认情况下，求和函数会沿所有的轴降低张量的维度，使它变为一个标量。我们还可以指定张量沿哪一个轴来通过求和降低维度，指定axis=0将通过汇总所有行的元素降维，axis=1将通过汇总所有列的元素降维，下面以axis=1为例</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A_sum_axis1 <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>A_sum_axis1<span class="token punctuation">,</span> A_sum_axis1<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))</code></pre><p>沿着⾏和列对矩阵求和，等价于对矩阵的所有元素进⾏求和。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token comment"># 等同于A.sum()</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(190.)</code></pre><p>⼀个与求和相关的量是平均值（mean或average）。我们通过将总和除以元素总数来计算平均值。在代码中，<br>我们可以调⽤函数来计算任意形状张量的平均值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> A<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor(9.5000), tensor(9.5000))</code></pre><p>同样，计算平均值的函数也可以沿指定轴降低张量的维度。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))</code></pre><p><strong>非降维求和</strong></p><p>我们可以通过keepdims=True来保持轴数不变，这种求和有时很有用。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sum_A <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>sum_A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 6.],        [22.],        [38.],        [54.],        [70.]])</code></pre><p>例如，由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过⼴播将A除以sum_A。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">/</span> sum_A<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[0.0000, 0.1667, 0.3333, 0.5000],        [0.1818, 0.2273, 0.2727, 0.3182],        [0.2105, 0.2368, 0.2632, 0.2895],        [0.2222, 0.2407, 0.2593, 0.2778],        [0.2286, 0.2429, 0.2571, 0.2714]])</code></pre><p><strong>交换维度</strong></p><p>tensor.transpose(dim0,dim1)交换维度dim0和维度dim1，所以，对于一个张量X（3维及以上的张量），X.transpose(0,2)等价于X.transpose(2,0)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> X<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(torch.Size([2, 3, 4]), torch.Size([4, 3, 2]))</code></pre><h2 id="其他运算"><a href="#其他运算" class="headerlink" title="其他运算"></a>其他运算</h2><h3 id="点积"><a href="#点积" class="headerlink" title="点积"></a>点积</h3><p>我们已经学习了按元素操作、求和及平均值。另⼀个最基本的操作之⼀是点积。给定两个向量$x, y\in R^{d}$，它们的点积$x^{T}y$ （或⟨x, y⟩）是相同位置的按元素乘积的和</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))</code></pre><p>注意，我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x <span class="token operator">*</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(6.)</code></pre><h3 id="矩阵-向量积"><a href="#矩阵-向量积" class="headerlink" title="矩阵-向量积"></a>矩阵-向量积</h3><p>有了点积的基础，我们就可以理解矩阵-向量积，假设矩阵$A\in R^{mxn}$和向量$x\in R^{n}$，则矩阵向量积Ax是一个长度为m的列向量，矩阵向量积是将矩阵的每一行当成一个向量与x做点积得到。</p><p>在代码中，我们通过调用torch.mv(A, x)实现，这里请注意A的列维数必须与x的维数（其⻓度）相同</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>A<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))</code></pre><h3 id="矩阵-矩阵乘法"><a href="#矩阵-矩阵乘法" class="headerlink" title="矩阵-矩阵乘法"></a>矩阵-矩阵乘法</h3><p>如果你已经掌握了点积和矩阵-向量积的知识，那么矩阵-矩阵乘法就会很简单，关于矩阵之间的乘法如果不知，可自行百度。</p><p>假设我们有两个矩阵$A\in R^{nxk}$和$B\in R^{kxm}$，则矩阵-矩阵乘法AB可以看作是简单地执⾏m次矩阵-向量积，并将结果拼接在⼀起，形成⼀个n x m矩阵。在下⾯的代码中，我们在A和B上执⾏矩阵乘法。这⾥的A是⼀个5⾏4列的矩阵， B是⼀个4⾏3列的矩阵。两者相乘后，我们得到了⼀个5⾏3列的矩阵</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">B <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 6.,  6.,  6.],        [22., 22., 22.],        [38., 38., 38.],        [54., 54., 54.],        [70., 70., 70.]])</code></pre><h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p><strong>概念</strong></p><p>以向量范数为例，设V是数域F上的线性空间，且对于V的任一个向量x，对应一个非负实数$\parallel x \parallel$，满足以下条件：</p><p>①正定性：$\parallel x \parallel &gt;= 0$，$\parallel x \parallel = 0$当且仅当$x=0$</p><p>②齐次性：$\parallel ax \parallel = |a|\parallel x \parallel$</p><p>③三角不等式：对任意$x,y\in V$，都有$\parallel x+y \parallel &lt;= \parallel x \parallel + \parallel y \parallel$</p><p>则称$\parallel x+y \parallel$为向量x的范数</p><p>下面我们介绍p-范数:<br>$$\parallel x \parallel_{p} = (\overset{n}{\underset{i=1}{\sum}}|x_{i}|^{p})^{1/p}$$<br>则2-范数就是向量元素平方和的平方根，其实就是欧几里得距离：<br>$$\parallel x \parallel_{2} = \sqrt{\overset{n}{\underset{i=1}{\sum}}|x_{i}|^{2}}$$<br>在代码中，我们可以按如下方式计算向量的2-范数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">u <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>u<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor(5.)</code></pre><p>有时你还会碰到1-范数，它表示为向量元素的绝对值之和：<br>$$\parallel x \parallel_{1} = \overset{n}{\underset{i=1}{\sum}}|x_{i}|$$<br>我们通过将绝对值函数和按元素求和函数结合起来实现1-范数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>u<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(7.)</code></pre><p>类似于向量的2-范数，矩阵$X\in R^{mxn}$的F范数也是矩阵元素平方和的平方根：<br>$$\parallel X \parallel_{F} = \sqrt{\overset{m}{\underset{i=1}{\sum}}\overset{n}{\underset{j=1}{\sum}}x_{ij}^{2}}$$<br>F范数满足向量范数的所有性质，它就像是矩阵型向量的2-范数。我们可以调用相同的函数norm()计算矩阵的F范数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(6.)</code></pre><p>最后我将列举三种常见的矩阵p-范数</p><p>①$\parallel A \parallel_{1} = \underset{j}{max}(\overset{n}{\underset{i=1}{\sum}}|a_{ij}|)$，称为列和范数；</p><p>②$\parallel A \parallel_{2} = \sqrt{\lambda_{1}}$，$\lambda_{1}$为$A^{H}A$的最大特征值，称为谱范数</p><p>③$\parallel A \parallel_{\infty} = \underset{i}{max}(\overset{n}{\underset{j=1}{\sum}}|a_{ij}|)$，称为行和范数</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理</title>
      <link href="/2022/04/25/shu-ju-yu-chu-li/"/>
      <url>/2022/04/25/shu-ju-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<p>这节我们将简要介绍使用pandas预处理原始数据，并将原始数据转换为张量格式的步骤。</p><h2 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h2><p>首先，我们简单创建一个人工数据集，并存储在csv文件./data/house_tiny.csv中。下面我们将数据集按行写入csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'./data'</span><span class="token punctuation">,</span> <span class="token string">'house_tiny.csv'</span><span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NumRooms,Alley,Price\n'</span><span class="token punctuation">)</span> <span class="token comment"># 列名</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,Pave,127500\n'</span><span class="token punctuation">)</span> <span class="token comment"># 每⾏表⽰⼀个数据样本</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'2,NA,106000\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'4,NA,178100\n'</span><span class="token punctuation">)</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,NA,140000\n'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>有数据集后，我们可以导入pandas包并调用read_csv函数加载原始数据集。该数据集有四行三列，其中每⾏描述了房间数量（“NumRooms”）、巷⼦类型（“Alley”）和房屋价格（“Price”）。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price0       NaN  Pave  1275001       2.0   NaN  1060002       4.0   NaN  1781003       NaN   NaN  140000</code></pre><h2 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h2><p>有输出结果可以看出，表格中存在缺失的数据。为了避免这些数据对之后的模型搭建存在影响，需对其进行处理，常见的方法有插值法和删除法，插值法是用一个替代值替换缺失值，而删除法则是直接忽略缺失值。</p><p><strong>插值法</strong></p><p>我们一般用同一列的均值替换“NaN”项，可以用fillna()函数实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data1 <span class="token operator">=</span> data<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>data<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price0       3.0  Pave  1275001       2.0   NaN  1060002       4.0   NaN  1781003       3.0   NaN  140000</code></pre><p><strong>删除法</strong></p><p>一般是删除缺失值所对应的行，用dropna()函数实现</p><ul><li>axis默认值为0，当设置为1时，是删除缺失值所对应的列</li><li>subset是参考某几列（或几行）作为删除一句</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">data2 <span class="token operator">=</span> data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'NumRooms'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley   Price1       2.0   NaN  1060002       4.0   NaN  178100</code></pre><p>除此之外，有时还需要删除重复的数据，可以用drop_duplicates()函数实现。由于一般我们都是用插值法处理缺失值，所以这里我们考虑该方法。</p><p>通过位置索引iloc，我们将data分为inputs和outputs</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>   NumRooms Alley0       3.0  Pave1       2.0   NaN2       4.0   NaN3       3.0   NaN</code></pre><p>对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。由于“Alley”列只接受两种类型的类别值“Pave”和“NaN”，pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。类型为“Pave”的⾏会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。类型为“NaN”的⾏会将“Alley_Pave”的值设置为0，“Alley_nan”的值设置为1。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>   NumRooms  Alley_Pave  Alley_nan0       3.0           1          01       2.0           0          12       4.0           0          13       3.0           0          1</code></pre><h2 id="转换为张量格式"><a href="#转换为张量格式" class="headerlink" title="转换为张量格式"></a>转换为张量格式</h2><p>现在inputs和outputs中所有数据都是数值类型，我们可以把它们转换为张量格式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchX<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span>X<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[3., 1., 0.],         [2., 0., 1.],         [4., 0., 1.],         [3., 0., 1.]], dtype=torch.float64), tensor([127500, 106000, 178100, 140000]))</code></pre><p>这节我们主要学习了csv文件数据的预处理，其实以其他格式存储的数据也是通过类似的方式进行处理，最终都得转变成tensor格式。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW3-CNN</title>
      <link href="/2022/04/20/hw3-cnn/"/>
      <url>/2022/04/20/hw3-cnn/</url>
      
        <content type="html"><![CDATA[<h2 id="作业介绍"><a href="#作业介绍" class="headerlink" title="作业介绍"></a>作业介绍</h2><p>作业的目标是使用卷积神经网络（我用的是VGG）解决图像分类问题，并用数据扩充的技术提高模型的性能。</p><p>使用的数据集是一个关于食物分类的dataset:food-11。如名字所示，食物的种类有11种，分别为面包、乳制品、甜点、鸡蛋、 油炸食品、肉类、面条、米饭、海鲜、汤和水果蔬菜。其中数据分为训练集（9866张）、验证集（3430张）和测试集（3347张），训练集和验证集中照片的格式为”类别_编号.jpg“，如3_100.jpg为类别3（鸡蛋）的照片，测试集中照片的格式为”编号.jpg“，不包含类别，测试集食物的类别需要用模型预测并保存到.csv文件中。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入需要的包</span><span class="token keyword">import</span> os<span class="token keyword">import</span> glob<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> random<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">import</span> time<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltseed <span class="token operator">=</span> <span class="token number">2022</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义一些函数"><a href="#定义一些函数" class="headerlink" title="定义一些函数"></a>定义一些函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your model (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_accuracy</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot accuracy of your model (train &amp; dev acc) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training epochs'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> root<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 只画前16张图片的预测结果</span>    text <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">'面包'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token string">'乳制品'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token string">'甜点'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token string">'鸡蛋'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token string">'油炸食品'</span><span class="token punctuation">,</span>            <span class="token number">5</span><span class="token punctuation">:</span><span class="token string">'肉类'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span><span class="token string">'面条'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span><span class="token string">'米饭'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span><span class="token string">'海鲜'</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span><span class="token string">'汤'</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token string">'水果蔬菜'</span><span class="token punctuation">}</span>        fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 设置子图数量和画布大小   </span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>num<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 设置显示中文字体（黑体）</span>    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.family'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 4行4列的第i+1个子图 </span>        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>        img <span class="token operator">=</span> plt<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>fnames<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        label <span class="token operator">=</span> preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment"># 在图片(70,120)的位置标出食物类别（是否戴眼镜），字体大小为 24，字体颜色为红色</span>        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token number">70</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> s<span class="token operator">=</span>text<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'fontsize'</span><span class="token punctuation">:</span><span class="token number">48</span> <span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FoodDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 制作Dataset '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fnames<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>fnames <span class="token operator">=</span> fnames        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Finished reading the </span><span class="token interpolation"><span class="token punctuation">{</span>mode<span class="token punctuation">}</span></span><span class="token string"> set(</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>fnames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> samples found)'</span></span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fnames<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> self<span class="token punctuation">.</span>fnames<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        fname <span class="token operator">=</span> fname<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\\'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">)</span>        <span class="token comment"># 加载图片</span>        img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_image<span class="token punctuation">(</span>fname<span class="token punctuation">)</span>        <span class="token comment"># transform</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> img        <span class="token keyword">else</span><span class="token punctuation">:</span>            label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>fname<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>label<span class="token punctuation">)</span>            label <span class="token operator">=</span> label<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> img<span class="token punctuation">,</span> label<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pre_dataloader</span><span class="token punctuation">(</span>root<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 制作DataLoader '''</span>    fnames <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>           <span class="token comment"># 获取当前路径下的所有文件对应的路径</span>    dataset <span class="token operator">=</span> FoodDataset<span class="token punctuation">(</span>fnames<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> transform<span class="token punctuation">)</span>       <span class="token comment"># 生成一个数据集，并输入到指定的dataloader</span>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span>         shuffle <span class="token operator">=</span> <span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>这部分主要自己实现一个VGG网络结构，在这之前我们简单的讲解一下VGG的结构。</p><p>VGG网络主要由两个部分组成：第一部分主要是卷积层和池化层组成，第二部分由全连接层组成。它的特点如下：</p><ul><li>每个卷积层中使用3x3filters，并将它们组合成卷积序列</li><li>多个3x3卷积序列可以模拟更大的接受场的效果</li><li>每次的图像像素缩小一倍，卷积核的数量增加一倍</li></ul><p>VGG有很多个版本，也算是比较稳定和经典的model。它的特点也是连续conv多计算量巨大，这里我们以VGG16为例<br><img src="https://handbook.pytorch.wiki/chapter2/vgg16.png"><br>其中，VGG清一色用小卷积核的优势有：</p><ul><li>3层conv3x3后等同于1层conv7x7的结果； 2层conv3x3后等同于2层conv5x5的结果</li><li>卷积层的参数减少。相比5x5、7x7和11x11的大卷积核，3x3明显地减少了参数量</li><li>通过卷积和池化层后，图像的分辨率降低为原来的一半，但是图像的特征增加一倍，这是一个十分规整的操作，为后面的网络提供了一个标准</li></ul><p>下面我们根据VGG16的特点来实现这个模型：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnVGG16 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">25088</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于我电脑跑不动这个模型，所以在它的基础上进行稍微的修改，本文用的模型如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span>        <span class="token comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span>        <span class="token comment"># input 维度 [3, 128, 128]</span>        self<span class="token punctuation">.</span>cnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [64, 128, 128]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [64, 64, 64]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [128, 64, 64]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [128, 32, 32]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [256, 32, 32]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [256, 16, 16]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 16, 16]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># [512, 4, 4]</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>cnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 训练模型 '''</span>    n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>   <span class="token comment"># 最大迭代次数</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer使用Adam</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 损失函数使用CrossEntropyLoss</span>        min_loss <span class="token operator">=</span> <span class="token number">1000</span>             <span class="token comment"># 用于记录验证时最小的loss</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录训练损失</span>    acc_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录预测准确度</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 调整为train模型（开放Dropout等等）</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">)</span><span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 将模型参数的 gradient 至0</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 利用后向传播算出每个参数的gradient</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 更新模型参数</span>                        train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>                        loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                train_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>                <span class="token comment"># 每次迭代后，在验证集中验证你的模型</span>        dev_acc<span class="token punctuation">,</span> dev_loss <span class="token operator">=</span> dev<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>        acc_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_acc<span class="token punctuation">)</span>        loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_loss<span class="token punctuation">)</span>                <span class="token comment"># 将结果打印出来</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%02d/%02d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f'</span> <span class="token operator">%</span> \              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n_epochs<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> dev_acc<span class="token punctuation">,</span> dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># 当模型性能提升时保存模型</span>        <span class="token keyword">if</span> dev_loss <span class="token operator">&lt;</span> min_loss<span class="token punctuation">:</span>            min_loss <span class="token operator">=</span> dev_loss            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">, loss = </span><span class="token interpolation"><span class="token punctuation">{</span>min_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 保存模型到指定路径</span>                <span class="token keyword">return</span> min_loss<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    dev_loss<span class="token punctuation">,</span> dev_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 前向传播</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 计算loss</span>            dev_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            dev_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>    dev_acc <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    dev_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>        <span class="token keyword">return</span> dev_acc<span class="token punctuation">,</span> dev_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>                                    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>         <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                              pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> y <span class="token keyword">in</span> pred<span class="token punctuation">:</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">return</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>config中包含模型训练的超参数（可以进行调节）和保存模型的路径</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>data_dir <span class="token operator">=</span> <span class="token string">'./food-11'</span><span class="token comment"># 可以进行调节来提升模型性能</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span>                <span class="token comment"># 最大迭代次数</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">,</span>               <span class="token comment"># dataloader的最小批量</span>    <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment"># 模型保存路径</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="加载数据和模型"><a href="#加载数据和模型" class="headerlink" title="加载数据和模型"></a>加载数据和模型</h2><p>这部分需要注意的是我们需要为不同的数据制定不同的transform，因为我们只能对训练数据做数据扩充</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 训练时做数据扩充</span>train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># 随机将图片水平翻转</span>    transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token comment"># 随机旋转图片</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 验证测试时不用做数据扩充</span>test_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tr_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'training'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> train_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dv_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'validation'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> test_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tt_set <span class="token operator">=</span> pre_dataloader<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'testing'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> test_transform<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Finished reading the train set(9866 samples found)Finished reading the dev set(3430 samples found)Finished reading the test set(3347 samples found)</code></pre><p>展示16张训练集的图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">images<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">]</span>grid_img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>grid_img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_21_0.png" class=""><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">min_loss<span class="token punctuation">,</span> loss_record<span class="token punctuation">,</span> acc_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[01/30] 86.74 sec(s) Train Acc: 0.218123 Loss: 0.036563 | Val Acc: 0.262974 loss: 0.032123Saving model (epoch = 01, loss = 0.0321)[02/30] 83.66 sec(s) Train Acc: 0.311372 Loss: 0.030771 | Val Acc: 0.322449 loss: 0.030530Saving model (epoch = 02, loss = 0.0305)[03/30] 83.76 sec(s) Train Acc: 0.369349 Loss: 0.028417 | Val Acc: 0.406122 loss: 0.026898Saving model (epoch = 03, loss = 0.0269)[04/30] 86.88 sec(s) Train Acc: 0.414454 Loss: 0.026027 | Val Acc: 0.411079 loss: 0.025972Saving model (epoch = 04, loss = 0.0260)[05/30] 85.10 sec(s) Train Acc: 0.467971 Loss: 0.023721 | Val Acc: 0.383382 loss: 0.030133[06/30] 84.83 sec(s) Train Acc: 0.507399 Loss: 0.022244 | Val Acc: 0.367055 loss: 0.033233[07/30] 87.24 sec(s) Train Acc: 0.532840 Loss: 0.020973 | Val Acc: 0.514286 loss: 0.023898Saving model (epoch = 07, loss = 0.0239)[08/30] 86.20 sec(s) Train Acc: 0.577944 Loss: 0.019479 | Val Acc: 0.502332 loss: 0.023984[09/30] 88.35 sec(s) Train Acc: 0.591222 Loss: 0.018706 | Val Acc: 0.563848 loss: 0.020785Saving model (epoch = 09, loss = 0.0208)[10/30] 85.91 sec(s) Train Acc: 0.621528 Loss: 0.017443 | Val Acc: 0.557143 loss: 0.021090[11/30] 86.38 sec(s) Train Acc: 0.616562 Loss: 0.017344 | Val Acc: 0.560641 loss: 0.020721Saving model (epoch = 11, loss = 0.0207)[12/30] 87.27 sec(s) Train Acc: 0.648490 Loss: 0.016085 | Val Acc: 0.565015 loss: 0.020585Saving model (epoch = 12, loss = 0.0206)[13/30] 86.36 sec(s) Train Acc: 0.662376 Loss: 0.015385 | Val Acc: 0.609621 loss: 0.018134Saving model (epoch = 13, loss = 0.0181)[14/30] 87.04 sec(s) Train Acc: 0.672816 Loss: 0.014737 | Val Acc: 0.576676 loss: 0.020833[15/30] 86.98 sec(s) Train Acc: 0.691871 Loss: 0.013995 | Val Acc: 0.547230 loss: 0.023204[16/30] 86.17 sec(s) Train Acc: 0.701297 Loss: 0.013776 | Val Acc: 0.516618 loss: 0.024357[17/30] 87.39 sec(s) Train Acc: 0.713866 Loss: 0.012795 | Val Acc: 0.627697 loss: 0.017918Saving model (epoch = 17, loss = 0.0179)[18/30] 87.07 sec(s) Train Acc: 0.733732 Loss: 0.012115 | Val Acc: 0.628280 loss: 0.018558[19/30] 87.39 sec(s) Train Acc: 0.735962 Loss: 0.011708 | Val Acc: 0.623907 loss: 0.019147[20/30] 86.86 sec(s) Train Acc: 0.761200 Loss: 0.010815 | Val Acc: 0.639650 loss: 0.019255[21/30] 87.09 sec(s) Train Acc: 0.779749 Loss: 0.009971 | Val Acc: 0.608455 loss: 0.021485[22/30] 87.64 sec(s) Train Acc: 0.772045 Loss: 0.010318 | Val Acc: 0.633528 loss: 0.019861[23/30] 86.32 sec(s) Train Acc: 0.777215 Loss: 0.009820 | Val Acc: 0.661808 loss: 0.018393[24/30] 87.13 sec(s) Train Acc: 0.810562 Loss: 0.008549 | Val Acc: 0.647230 loss: 0.019221[25/30] 86.26 sec(s) Train Acc: 0.799818 Loss: 0.009009 | Val Acc: 0.655394 loss: 0.019204[26/30] 84.89 sec(s) Train Acc: 0.839955 Loss: 0.007461 | Val Acc: 0.650437 loss: 0.018734[27/30] 88.26 sec(s) Train Acc: 0.839955 Loss: 0.007236 | Val Acc: 0.641399 loss: 0.020359[28/30] 90.81 sec(s) Train Acc: 0.846544 Loss: 0.007010 | Val Acc: 0.643149 loss: 0.020707[29/30] 85.49 sec(s) Train Acc: 0.851105 Loss: 0.006651 | Val Acc: 0.650146 loss: 0.022475[30/30] 86.92 sec(s) Train Acc: 0.871883 Loss: 0.005801 | Val Acc: 0.667055 loss: 0.021603</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_accuracy<span class="token punctuation">(</span>acc_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'cnn model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_25_0.png" class=""><h2 id="模型测试-1"><a href="#模型测试-1" class="headerlink" title="模型测试"></a>模型测试</h2><p>加载最优模型预测测试集上的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 加载你最好的模型</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>preds <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>展示部分预测结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_pred<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span><span class="token string">'testing'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/20/hw3-cnn/output_29_0.png" class=""> <p>在测试集上的结果将会保存到pred.csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"predict.csv"</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Id,Category\n'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> y <span class="token keyword">in</span>  <span class="token builtin">enumerate</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{}\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Classifier </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HW1-Regression</title>
      <link href="/2022/04/19/hw1-regression/"/>
      <url>/2022/04/19/hw1-regression/</url>
      
        <content type="html"><![CDATA[<ul><li>目标：用深度神经网络（DNN）解决一个回归问题，了解训练基础DNN的技巧</li><li>任务描述： 给定美国特定州过去三天有关COVID-19的调查，然后预测第3天新检测阳性病例的百分比</li></ul><h2 id="导入一些包"><a href="#导入一些包" class="headerlink" title="导入一些包"></a>导入一些包</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># PyTorch</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token comment"># For data preprocess</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> csv<span class="token keyword">import</span> os<span class="token comment"># For plotting</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltmyseed <span class="token operator">=</span> <span class="token number">42069</span>  <span class="token comment"># set a random seed for reproducibility</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义一些函数"><a href="#定义一些函数" class="headerlink" title="定义一些函数"></a>定义一些函数</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your DNN (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token builtin">len</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> lim<span class="token operator">=</span><span class="token number">35.</span><span class="token punctuation">,</span> preds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot prediction of your DNN '''</span>    <span class="token keyword">if</span> preds <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        preds<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                targets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'ground truth value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'predicted value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Ground Truth v.s. Prediction'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>有三种数据集：训练集、验证集和测试集</p><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>这部分需要实现的功能如下：</p><ul><li>读取.csv文件，将covid.train.csv划分为训练集和验证集</li><li>提取数据特征，并进行归一化处理</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">COVID19Dataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 用于加载并对COVID19数据集进行预处理'''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode                <span class="token comment"># 读取数据为numpy arrays格式</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>            data <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>fp<span class="token punctuation">)</span><span class="token punctuation">)</span>            data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span>   <span class="token comment"># 不读取行列的注释</span>                <span class="token keyword">if</span> <span class="token keyword">not</span> target_only<span class="token punctuation">:</span>                                      feats <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">93</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                 <span class="token comment"># 考虑所有影响因素</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>                                      <span class="token comment"># 作业实现部分</span>            <span class="token comment"># TODO: Using 40 states &amp; 2 tested_positive features (indices = 57 &amp; 75)</span>            feats <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            feats<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">57</span><span class="token punctuation">)</span>            feats<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">75</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>            <span class="token comment"># 测试数据</span>            <span class="token comment"># data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 训练数据，用于划分训练集和验证集</span>            <span class="token comment"># data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))</span>            target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>                        <span class="token comment"># 将训练数据划分为训练集和测试集(9 : 1)</span>            <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'dev'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>                        <span class="token comment"># 将数据转成tensors格式</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>target<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token comment"># 归一化处理（你可以尝试将这部分去除，看结果会变成什么样子）</span>        self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> \            <span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span> \            <span class="token operator">/</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>std<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'</span>              <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>mode<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 返回数据的长度</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 每次返回一个样本</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># 训练</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>target<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 测试（没有目标值）</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>以小批量的格式从定义好的Dataset中加载数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">prep_dataloader</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> target_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 生成一个数据集，将其输入到指定的dataloader中 '''</span>    dataset <span class="token operator">=</span> COVID19Dataset<span class="token punctuation">(</span>path<span class="token punctuation">,</span> mode<span class="token operator">=</span>mode<span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>      dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>        dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span>        shuffle<span class="token operator">=</span><span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                <span class="token keyword">return</span> dataloader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h2><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><p>模型简单由具有ReLU激活函数的全连接层组成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SimpleNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 实现一个简单由几个全连接层组成的深度神经网络 '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment"># 你可以对这部分的网络结构进行修改</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 二维变成一维，数字对应去除的维度序号（从0开始）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 训练模型 '''</span>        n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>     <span class="token comment"># 最大迭代次数</span>            optimizer <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>        model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'optim_hparas'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 优化算法optimizer    </span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>            <span class="token comment"># 损失函数criterion</span>        min_mse <span class="token operator">=</span> <span class="token number">1000</span>             <span class="token comment"># 用于记录验证时最小的loss</span>    loss_record <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span>   <span class="token comment"># 记录训练损失</span>    early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>                       <span class="token comment"># 如果迭代过程中，超过设定迭代次数，模型的最小loss还没更新就停止迭代</span>        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>                      <span class="token comment"># 将模型设置为训练模式</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> tr_set<span class="token punctuation">:</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token comment"># 将梯度初始为0</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>               <span class="token comment"># 前向传播（计算模型输出）</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>     <span class="token comment"># 计算loss</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment"># 后向传播（计算梯度）</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token comment"># 更新模型参数</span>            loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># 每次迭代后，在验证集中验证你的模型</span>        dev_mse <span class="token operator">=</span> dev<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        <span class="token keyword">if</span> dev_mse <span class="token operator">&lt;</span> min_mse<span class="token punctuation">:</span>            <span class="token comment"># 当模型性能提升时保存模型</span>            min_mse <span class="token operator">=</span> dev_mse            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving model (epoch = </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">, loss = </span><span class="token interpolation"><span class="token punctuation">{</span>min_mse<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)'</span></span><span class="token punctuation">)</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 保存模型到指定的路径</span>            early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>               <span class="token comment"># 每次模型性能改进，将该值变为0</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>            early_stop_cnt <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment"># 每次迭代后，模型性能未提升则加1</span>                loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_mse<span class="token punctuation">)</span>        <span class="token keyword">if</span> early_stop_cnt <span class="token operator">&gt;</span> config<span class="token punctuation">[</span><span class="token string">'early_stop'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment"># 如果你的模型在指定迭代次数后，模型性能仍为改进，则停止训练</span>            <span class="token keyword">break</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Finished training after </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string"> epochs'</span></span><span class="token punctuation">)</span>    <span class="token keyword">return</span> min_mse<span class="token punctuation">,</span> loss_record<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token comment"># 将模型设置为评估模式</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>   <span class="token comment"># 损失函数criterion</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                   <span class="token comment"># 不允许梯度计算</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment"># 前向传播</span>            mse_loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 计算loss</span>        total_loss <span class="token operator">+=</span> mse_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># 总loss</span>    total_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>              <span class="token comment"># 平均loss</span>    <span class="token keyword">return</span> total_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>                                    x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>         <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                              pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                                 preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 连接所有预测并转换为numpy数组</span>    <span class="token keyword">return</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><p>config中包含模型训练的超参数（可以进行调节）和保存模型的路径</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>                 os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#</span>target_only <span class="token operator">=</span> <span class="token boolean">False</span>                   <span class="token comment"># 可以进行调节来提升模型性能</span>config <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">3000</span><span class="token punctuation">,</span>                <span class="token comment"># 最大迭代次数</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">270</span><span class="token punctuation">,</span>               <span class="token comment"># dataloader的最小批量</span>    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token string">'SGD'</span><span class="token punctuation">,</span>              <span class="token comment"># 参数优化算法</span>    <span class="token string">'optim_hparas'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                <span class="token comment"># optimizer的超参数</span>        <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>                 <span class="token comment"># SGD的学习率</span>        <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0.9</span>              <span class="token comment"># SGD的momentum</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token string">'early_stop'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>               <span class="token comment"># 自模型上次改进以后的最多迭代次数</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment"># 模型保存路径</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="加载数据和模型"><a href="#加载数据和模型" class="headerlink" title="加载数据和模型"></a>加载数据和模型</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">tr_path <span class="token operator">=</span> <span class="token string">'./data/covid.train.csv'</span>  <span class="token comment"># 训练数据路径</span>tt_path <span class="token operator">=</span> <span class="token string">'./data/covid.test.csv'</span>   <span class="token comment"># 测试数据路径</span>tr_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>dv_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>tt_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tt_path<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 93)Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 93)Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 93)</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>          <span class="token comment"># 构建模型</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">model_loss<span class="token punctuation">,</span> model_loss_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>Saving model (epoch =    1, loss = 196.5020)Saving model (epoch =    2, loss = 64.4406)Saving model (epoch =    3, loss = 16.0075)Saving model (epoch =    4, loss = 7.1638)Saving model (epoch =    5, loss = 6.9936)Saving model (epoch =    6, loss = 4.3199)Saving model (epoch =    7, loss = 2.8746)Saving model (epoch =    8, loss = 2.3495)Saving model (epoch =    9, loss = 2.0699)Saving model (epoch =   10, loss = 1.8842)Saving model (epoch =   11, loss = 1.7374)Saving model (epoch =   12, loss = 1.6552)Saving model (epoch =   13, loss = 1.5494)Saving model (epoch =   14, loss = 1.4657)Saving model (epoch =   16, loss = 1.3691)Saving model (epoch =   18, loss = 1.2820)Saving model (epoch =   19, loss = 1.2714)Saving model (epoch =   20, loss = 1.2370)Saving model (epoch =   21, loss = 1.2115)Saving model (epoch =   22, loss = 1.1969)Saving model (epoch =   24, loss = 1.1566)Saving model (epoch =   25, loss = 1.1130)Saving model (epoch =   26, loss = 1.0947)Saving model (epoch =   28, loss = 1.0822)Saving model (epoch =   31, loss = 1.0681)Saving model (epoch =   32, loss = 1.0414)Saving model (epoch =   33, loss = 1.0325)Saving model (epoch =   34, loss = 1.0219)Saving model (epoch =   36, loss = 1.0006)Saving model (epoch =   42, loss = 0.9903)Saving model (epoch =   43, loss = 0.9615)Saving model (epoch =   46, loss = 0.9473)Saving model (epoch =   48, loss = 0.9305)Saving model (epoch =   52, loss = 0.9179)Saving model (epoch =   58, loss = 0.9060)Saving model (epoch =   61, loss = 0.9049)Saving model (epoch =   62, loss = 0.8991)Saving model (epoch =   63, loss = 0.8967)Saving model (epoch =   67, loss = 0.8928)Saving model (epoch =   68, loss = 0.8797)Saving model (epoch =   70, loss = 0.8776)Saving model (epoch =   73, loss = 0.8588)Saving model (epoch =   81, loss = 0.8583)Saving model (epoch =   84, loss = 0.8497)Saving model (epoch =   86, loss = 0.8392)Saving model (epoch =   96, loss = 0.8273)Saving model (epoch =   99, loss = 0.8218)Saving model (epoch =  105, loss = 0.8191)Saving model (epoch =  119, loss = 0.8141)Saving model (epoch =  138, loss = 0.8100)Saving model (epoch =  139, loss = 0.7944)Saving model (epoch =  160, loss = 0.7902)Saving model (epoch =  190, loss = 0.7779)Saving model (epoch =  218, loss = 0.7770)Saving model (epoch =  233, loss = 0.7751)Saving model (epoch =  241, loss = 0.7748)Saving model (epoch =  270, loss = 0.7630)Saving model (epoch =  326, loss = 0.7592)Saving model (epoch =  409, loss = 0.7497)Saving model (epoch =  541, loss = 0.7488)Saving model (epoch =  546, loss = 0.7450)Saving model (epoch =  642, loss = 0.7401)Saving model (epoch =  670, loss = 0.7389)Saving model (epoch =  800, loss = 0.7318)Finished training after 1000 epochs</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_learning_curve<span class="token punctuation">(</span>model_loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'deep model'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><img src="/2022/04/19/hw1-regression/output_23_0.png" class=""><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>       <span class="token comment"># 加载你最好的模型</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>plot_pred<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>                  <span class="token comment"># 展示在验证集上的预测结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/19/hw1-regression/output_24_0.png" class=""><h2 id="模型测试-1"><a href="#模型测试-1" class="headerlink" title="模型测试"></a>模型测试</h2><p>在测试集上的结果将会保存到pred.csv文件中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' 保存预测的结果到指定的文件中 '''</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saving results to </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">file</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>fp<span class="token punctuation">)</span>        writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'tested_positive'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> p <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>            writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> p<span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>  <span class="token comment"># 预测</span>save_pred<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token string">'pred.csv'</span><span class="token punctuation">)</span>         <span class="token comment"># 保存预测结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Saving results to pred.csv</code></pre>]]></content>
      
      
      <categories>
          
          <category> 李宏毅ML2021作业部分 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DNN </tag>
            
            <tag> Regression </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERT</title>
      <link href="/2022/04/17/bert/"/>
      <url>/2022/04/17/bert/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>BERT的全称是Bidirectional Encoder Representations from Transformers（来自Transformers的双向编码器表示），BERT基于Transformer，Transformer在初始论文中是用于Seq2Seq任务中，其Encoder部分后续被迁移到各种场景，逐渐演化成一种通用的特征提取器。BERT 通过使用预训练的 Transformer编码器，能够基于其双向上下文表示任何词元。在下游任务的监督学习过程中，BERT将输入表示到一个添加的输出层中，根据任务的性质对模型架构进行最小的更改，例如预测每个词元与预测整个序列。同时，BERT对预训练Transformer编码器的所有参数进行微调，而额外的输出层将从头开始训练。</p><p>在BERT的原始论文BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding 中，BERT的描述分为三个部分：输入表示、预训练任务和下游任务。</p><h2 id="BERT的输入表示"><a href="#BERT的输入表示" class="headerlink" title="BERT的输入表示"></a>BERT的输入表示</h2><p>在自然语言处理中，有些任务（如情感分析）以单个文本为输入，而有些任务（如自然语言推断）以一对文本序列作为输入。当输入为单个文本时，BERT输入序列是特殊类别词元“&lt;cls&gt;”、⽂本序列的标记、以及特殊分隔词元“&lt;sep&gt;”的连结。当输入为文本对是，BERT输入序列是“&lt;cls&gt;”、第⼀个⽂本序列的标记、“&lt;sep&gt;”、第⼆个⽂本序列标记、以及“&lt;sep&gt;”的连结。</p><p>BERT选择Transformer编码器作为其双向架构。在Transformer编码器中，位置嵌入被加到输入序列的每个位置。然而，与原始Transformer编码器不同，BERT使用可学习的位置嵌入，其输入为词元嵌入（Token Embeddings）、片段嵌入（Segment Embeddings）和位置嵌入（Position Embeddings）的和。</p><img src="/2022/04/17/bert/image-20220417165237930.png" class=""><h2 id="预训练任务"><a href="#预训练任务" class="headerlink" title="预训练任务"></a>预训练任务</h2><p>前面我们给出了输入文本的每个词元和插入的特殊标记“&lt;cls&gt;”及“&lt;seq&gt;” 的BERT表示。接下来，我们将使⽤这些表⽰来计算预训练BERT的损失函数。预训练包括以下两个任务：掩蔽语言模型和下一句预测。</p><h3 id="掩蔽语言模型（Masked-Language-Modeling-Masked-LM）"><a href="#掩蔽语言模型（Masked-Language-Modeling-Masked-LM）" class="headerlink" title="掩蔽语言模型（Masked Language Modeling, Masked LM）"></a>掩蔽语言模型（Masked Language Modeling, Masked LM）</h3><p>根据直觉，我们有理由相信deep bidirectional model比left-to-right model（如单向LSTM）或者浅级连接的left-to-right model和right-to-left model（如双向LSTM）更加强大。为了双向编码上下文以表示每个词元，BERT随机掩蔽词元并使用来自上下文的词元以自监督（self-supervised）的方式预测掩蔽词元。此任务称为掩蔽语言模型。这个模型可以用下图表示，假设输入是机器学习。</p><img src="/2022/04/17/bert/image-20220417181929265.png" class=""><p>在这个预训练任务中，将随机选择15%的词元作为预测的掩蔽词元。要预测⼀个掩蔽词元而不使⽤标签作弊，<br>⼀个简单的⽅法是总是⽤⼀个特殊的“&lt;mask&gt;”替换输⼊序列中的词元。然而，⼈造特殊词元“&lt;mask&gt;”不<br>会出现在微调中。为了避免预训练和微调之间的这种不匹配，如果为预测而屏蔽词元（例如，在“my dog is hairy ”中选择掩蔽和预测“hairy”），则在输⼊中将其替换为：  </p><ul><li>80%概率为特殊的“&lt;mask&gt;“词元（例如，“my dog is hairy ”变为“my dog is &lt;mask&gt;”）</li><li>10%概率为随机词元（例如，“my dog is hairy ”变为“my dog is apple”）</li><li>10%概率为不变的标签词元（例如，“my dog is hairy ”变为“my dog is hairy”）</li></ul><p>注意在15%的词元中，有10%的概率替换为随机词元。这种偶然的噪声鼓励BERT在其双向上下文编码中不那么偏向于掩蔽词元，而这种影响在标签保持不变时更加深刻。</p><p>总的来说Masked LM的目标是预测出被掩蔽的单词，相当于做一个完形填空，做完形填空的任务有利于BERT学会理解文本的上下文信息。</p><h3 id="下⼀句预测（Next-Sentence-Prediction-NSP）"><a href="#下⼀句预测（Next-Sentence-Prediction-NSP）" class="headerlink" title="下⼀句预测（Next Sentence Prediction, NSP）"></a>下⼀句预测（Next Sentence Prediction, NSP）</h3><p>虽然掩蔽语言模型能够双向上下文来表示单词，但它不能显式地表示文本对之间的逻辑关系，在这一些自然语言处理任务中尤为重要（如QA问答系统和自然语言推断）。为了帮助理解两个文本序列之间的关系，BERT在预训练中考虑了一个二元分类任务——下一句预测。在为预训练生成句子对时，有⼀半的时间它们确实是标签为“Yes”的连续句⼦。但在另⼀半的时间⾥，第⼆个句⼦是从语料库中随机抽取的，标记为“No”。</p><img src="/2022/04/17/bert/image-20220417182324087.png" class=""><p>  这个模型可以用上图表示，输入是两个句子，也就是文本对的输入格式。BERT输出是将特殊词元“&lt;cls&gt;”  编码后的向量，由于Transformer编码器中的自主意力，特殊词元“&lt;cls&gt;”的BERT表⽰已经对输⼊的两个句⼦进⾏了编码。再将编码后的向量输入一个多层感知机来预测第二个句子是否是BERT输入序列中第一个句子的下一句。  </p><h3 id="用于预训练BERT的数据集"><a href="#用于预训练BERT的数据集" class="headerlink" title="用于预训练BERT的数据集"></a>用于预训练BERT的数据集</h3><p>为了预训练BERT模型，我们需要以理想的格式生成数据集，以便于上述两个预训练任务。在论文中，预训练的语料库有两个：BooksCorpus（8亿个单词）、English Wikipedia（25亿个单词）。对于English Wikipedia，只提取文本段落而忽略列表、表格和标题。</p><h2 id="BERT下游任务"><a href="#BERT下游任务" class="headerlink" title="BERT下游任务"></a>BERT下游任务</h2><p>基于预训练后的BERT模型，可以将其融合到各种NLP任务中。BERT中每个词没有固定的词向量，是根据词的上下文来动态产生当前词的词向量。</p><p>在论文中，列出了四大BERT的下游任务：</p><img src="/2022/04/17/bert/image-20220417185625315.png" class=""><p>第一个任务是句子对的分类任务，第二个是单一句子的分类任务，第三个是问答系统，第四个是单一句子的标注任务。它们均可在预训练BERT的输出上接入相应的结构实现，最后基于任务的训练数据进行微调实现。其中任务一和任务二是将特殊词元“&lt;cls&gt;”  编码后的向量输入一个分类器实现，任务四是将单个句子里每个词元经过BERT编码后的向量分别输入一个分类器中实现。</p><img src="/2022/04/17/bert/image-20220417191544227.png" class=""><p>对于任务三，输入是一个问题加一个文件，输出是输入文件对应答案的开始和结束位置。由此可以看出该模型实现的要求是询问的答案可以在文件中找到，那么这个任务怎么实现呢？如上图，我们初始化两个和编码词元后的向量相同长度的vector，图中橙色的向量用于确认答案在文件中开始词元的序号（位置），蓝色的向量用于确认结束词元的序号。将这两个向量分别乘于文件中的词元经过BERT编码的向量，然后通过一个softmax层找到最大值对应的序号即可得到答案。如图中s=2，e=3，如果文件的内容是how to use BERT，则答案为use BERT。因此在这个任务中，我们需要训练的参数是图中的两个向量。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p><p>[2] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[3] <a href="https://arxiv.org/abs/1810.04805">Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” <em>arXiv preprint arXiv:1810.04805</em> (2018).</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BERT </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer</title>
      <link href="/2022/04/11/transformer/"/>
      <url>/2022/04/11/transformer/</url>
      
        <content type="html"><![CDATA[<p>在前面我们学习过<a href="https://faith-ye.github.io/2022/04/02/zi-zhu-yi-li-mo-xing/">自注意力模型</a>，自注意力模型拥有CNN并行运算和RNN挖掘序列中的关系两大优势。因此，使用自注意力模型来设计深度架构是很有吸引力的。对比之前仍然依赖RNN来实现输入表示的类似注意力模型，Transformer模型完全基于自注意力机制，不但实现了快速并行计算，还可以像DNN一样将模型增加到非常深的深度。Transformer由论文<a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>提出，最初是应用于文本数据上的序列到序列学习，但现在已经推⼴到各种现代的深度学习中，例如语⾔、视觉、语⾳和强化学习领域。</p><p>Transformer的整体架构如下图所示，是一个Encoder-Decoder架构。Transformer是由Encoder和Decoder组成，这两个部分是基于自注意力的模块叠加而成的，源序列和目标序列先词向量化(embedding)，然后加上位置编码(positional encoding)，再分别输入到Encoder和Decoder中。</p><img src="/2022/04/11/transformer/image-20220411170353238.png" class=""><h2 id="Encoder和Decoder"><a href="#Encoder和Decoder" class="headerlink" title="Encoder和Decoder"></a>Encoder和Decoder</h2><p>从宏观角度来看，transformer的Encoder是由多个相同的层叠加而成的，每个层都有两个子层(sublayer)。第一个子层是多头自注意力(multi-head self-attention)层；第二个子层是基于位置的前馈网络(position-wise feed-forward network)层。同时受残差网络的启发，每个子层都采用了残差连接(residual connection)，并在残差连接的加法计算之后，使用层规范化(layer normalization)。在计算编码器的自注意力时，查询、键和值都来自前一个layer的输出。由于使用了残差连接，Transformer的每一个layer都将输出一个d维表示向量。</p><p>Transformer的Decoder也是由多个相同的层叠加而成的。除了Encoder中描述的两个子层之外，Decoder还在两个子层之间插入了第三个子层，称为编码器 - 解码器注意力(encoder-decoder attention)层。Decoder的子层同Encoder一样，使用了残差连接和层规范化。在编码器－解码器注意⼒中，查询来⾃前Decoder前一个layer的输出，而键和值来⾃Encoder的输出。在Decoder自主意力中，查询、键和值都来自于Decoder上一个layer的输出。但是和Encoder自主意力不同的是，Decoder的每个位置只能考虑位置之前的所有位置。这种掩蔽(masked)注意力保留了自回归(auto-regressive)属性，确保预测仅依赖于已生成的输出词元。  </p><h2 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h2><p>有关这方面的详细推导请看<a href="https://faith-ye.github.io/2022/04/02/zi-zhu-yi-li-mo-xing/">这篇文章</a>，在这节我们主要讲解编码器 - 解码器注意力层是怎么运作的。</p><img src="/2022/04/11/transformer/image-20220411200918339.png" class=""><p>以语言识别为例，如上图假定Transformer的Encoder将一段声音讯号编码成$a^{1}、a^{2}、a^{3}$三个向量，而Transformer的Decoder获取第一个表示开始的向量，将其输入到掩蔽多头自主意力层，得到一个向量，将该向量的查询q和Encoder得到的三个向量的键、值做self-attention处理得到向量v，再把向量v作为Decoder的基于位置的前馈网络层中，最后得到目标词汇。</p><img src="/2022/04/11/transformer/image-20220411200951752.png" class=""><p>将得到目标词汇对应的向量连同start对应的向量作为Decoder的输出，经过掩蔽多头自主意力层得到另一个向量，将该向量的查询$q^{‘}$和Encoder得到的三个向量的键、值做self-attention处理得到向量$v^{‘}$，反复进行这样的操作直到Decoder输出结束的标志。</p><h2 id="基于位置的前馈网络层"><a href="#基于位置的前馈网络层" class="headerlink" title="基于位置的前馈网络层"></a>基于位置的前馈网络层</h2><p>该层包含两个线性变换，在这两个线性变化之间有一个ReLU激活函数。</p><p>$$FFN(x)=max(0,xW_{1}+b_{1})W_{2}+b_{2}$$</p><h2 id="Embedding和softmax"><a href="#Embedding和softmax" class="headerlink" title="Embedding和softmax"></a>Embedding和softmax</h2><p>与其他序列转换模型类似，我们使用已经学习好的Embedding层将源序列和目标序列转换维度是$d_{model}$的向量。同时在Transformer Decoder的最后，使用线性变换和softmax函数将编码器输出转换为预测目标词汇的概率。</p><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>由于Transformer模型不包含递归和卷积操作，整个运行过程都是应用self-attention实现计算的平行化，因此Transformer没有考虑输入序列的先后顺序。为了让模型利用序列的顺序，我们需要给模型注入一些关于词汇在序列中相对或绝对位置的信息。为此，Transformer在编码器和解码器的输入加入了位置编码。位置编码和Embedding后的词向量具有相同的维度$d_{model}$，将这两个向量相加，就可以获得序列的位置资讯。</p><p>位置编码计算为：</p><p>$$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$$</p><p>$$PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$$</p><p>式中，$pos\in postion_{inputs},i\in (0,1,…,d_{model}/2)$</p><h2 id="训练和翻译"><a href="#训练和翻译" class="headerlink" title="训练和翻译"></a>训练和翻译</h2><p>假设有一个英文和其对应的中文元组：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'BOS'</span><span class="token punctuation">,</span><span class="token string">'machine'</span><span class="token punctuation">,</span><span class="token string">'learning'</span><span class="token punctuation">,</span><span class="token string">'EOS'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'BOS'</span><span class="token punctuation">,</span><span class="token string">'机器'</span><span class="token punctuation">,</span><span class="token string">'学习'</span><span class="token punctuation">,</span><span class="token string">'EOS'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>假设我们通过大量的数据训练好了Transformer，数据的格式如下：</p><ul><li>英文部分的输入为：BOS machine learning EOS；</li><li>中文部分的输入为：BOS 机器 学习；</li><li>标签为：机器 学习 EOS                     用于CrossEntropy更新模型参数</li></ul><p>翻译时：</p><ul><li>英文序列作为输入；</li><li>Encoder输出max_output_len个词向量;</li><li>将标志符号BOS作为中文的第一个tokens，结合Encoder的输出输入到Decoder中得到关于目标词汇的概率，取概率最大对应的词汇作为输出结果，再将该词汇对应的词向量作为新的中文输入词向量，这样循环下去一次得到max_output_len个输出结果，即得到输出的中文分词列表；</li><li>顺着列表检查分词，如果出现标志符号<code>EOS</code>就截取前面的分词组成中文结果。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em> 30 (2017).</p><p>[2] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[3] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Seq2Seq </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seq2Seq代码实现</title>
      <link href="/2022/04/11/seq2seq-dai-ma-shi-xian/"/>
      <url>/2022/04/11/seq2seq-dai-ma-shi-xian/</url>
      
        <content type="html"><![CDATA[<p>在这章节，我们将用RNN搭建一个seq2seq模型(sequences to sequences)，实现英文到中文的翻译，数据集应用的是由<a href="http://www.manythings.org/anki/">Tatoeba项⽬的双语句⼦对114</a>组成的“英-中文”数据集。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>原始语料需要进行预处理，所以导入必要的包和模块。注意初次安装nltk后，进行分词需要依赖punkt，因此需要对其进行下载</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> jieba<span class="token keyword">import</span> re<span class="token keyword">import</span> random<span class="token keyword">from</span> opencc <span class="token keyword">import</span> OpenCC<span class="token keyword">import</span> nltk<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenizenltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>[nltk_data] Downloading package punkt to[nltk_data]     C:\Users\kaxim\AppData\Roaming\nltk_data...[nltk_data]   Package punkt is already up-to-date!True</code></pre><h3 id="词元化"><a href="#词元化" class="headerlink" title="词元化"></a>词元化</h3><p>该部分的作用是将数据词元化，用en，cn两个列表分别用来保存源语言（英语）和目标语言（中文）。在这两个列表中，对应列表索引的内容分别表示英语和其对应的中文翻译。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">cc <span class="token operator">=</span> OpenCC<span class="token punctuation">(</span><span class="token string">'t2s'</span><span class="token punctuation">)</span>   <span class="token comment"># t2s -繁体转简体； s2t -简体转繁体</span>en<span class="token punctuation">,</span> cn <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>data_dir <span class="token operator">=</span> <span class="token string">'./data/cmn-eng/cmn.txt'</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>   <span class="token comment"># sentence[0]为英文句子，sentence[1]为中文句子</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        en_sentence <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            en_sentence <span class="token operator">+=</span> word<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span>        en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>en_sentence<span class="token punctuation">)</span>                cn_sentence <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>sentence<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            word <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[ \n\t\r]'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> word<span class="token punctuation">)</span>            <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">''</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            cn_sentence <span class="token operator">+=</span> cc<span class="token punctuation">.</span>convert<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span>        cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cn_sentence<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Building prefix dict from the default dictionary ...Loading model from cache C:\Users\kaxim\AppData\Local\Temp\jieba.cacheLoading model cost 0.429 seconds.Prefix dict has been built successfully.</code></pre><p>查看词元化后的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">en<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cn<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>('thanks for the memories . ', '感谢 那些 回忆 。 ')</code></pre><h3 id="构建字典"><a href="#构建字典" class="headerlink" title="构建字典"></a>构建字典</h3><p>由于机器翻译数据集由语言对组成，因此我们需分别为源语言和目标语言构建字典，这样就方便之后转为one-hot vector。在该字典中，我们将出现次数少于3的低频率词视为相同未知词元（“&lt;unk&gt;”）。除此之外，我们还指定了额外的特定词元，例如在小批量时⽤于将序列填充到相同⻓度的填充词元（“&lt;pad&gt;”），以及序列的开始词元（“&lt;bos&gt;”）和结束词元（“&lt;eos&gt;”）。这些特殊词元在⾃然语⾔处理任务中⽐较常⽤。<br>构建的字典有以下两种形式：<br>int2word: 将整数转为对应文字<br>word2int: 将文字转为对应整数，该字典和前一个字典是一一对应关系</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 英文</span>words <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> sentence <span class="token keyword">in</span> en<span class="token punctuation">:</span>    _sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r ]'</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    _sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> _sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> word <span class="token keyword">in</span> _sentence<span class="token punctuation">:</span>        words<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>words <span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>words<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> d<span class="token punctuation">:</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#排序</span>words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> count <span class="token keyword">in</span> words <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">]</span>words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> wordsword2int_en<span class="token punctuation">,</span> int2word_en <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> index<span class="token punctuation">,</span>word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>    word2int_en<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> index    int2word_en<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> word<span class="token comment"># 中文</span>words <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> sentence <span class="token keyword">in</span> cn<span class="token punctuation">:</span>    _sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r ]'</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    _sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> _sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> word <span class="token keyword">in</span> _sentence<span class="token punctuation">:</span>        words<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> words<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>words <span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>words<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> d<span class="token punctuation">:</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#排序</span>words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> count <span class="token keyword">in</span> words <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">]</span>words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> wordsword2int_cn<span class="token punctuation">,</span> int2word_cn <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>    word2int_cn<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> index    int2word_cn<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> word<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>部分字典展示，由于字典不支持切片功能，因此我们需构建一个函数，实现切片功能</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dict_slice</span><span class="token punctuation">(</span>adict<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>    keys <span class="token operator">=</span> adict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>    dict_slice <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>keys<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> index<span class="token punctuation">]</span><span class="token punctuation">:</span>        dict_slice<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> adict<span class="token punctuation">[</span>k<span class="token punctuation">]</span>    <span class="token keyword">return</span> dict_slice<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>英文字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dict_slice<span class="token punctuation">(</span>word2int_en<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dict_slice<span class="token punctuation">(</span>int2word_en<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>({'&lt;PAD&gt;': 0,  '&lt;BOS&gt;': 1,  '&lt;EOS&gt;': 2,  '&lt;UNK&gt;': 3,  '.': 4,  'i': 5,  'the': 6,  'to': 7,  'you': 8,  'a': 9,  '?': 10,  'is': 11,  'tom': 12,  "n't": 13,  'he': 14}, {0: '&lt;PAD&gt;',  1: '&lt;BOS&gt;',  2: '&lt;EOS&gt;',  3: '&lt;UNK&gt;',  4: '.',  5: 'i',  6: 'the',  7: 'to',  8: 'you',  9: 'a',  10: '?',  11: 'is',  12: 'tom',  13: "n't",  14: 'he'})</code></pre><p>中文字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dict_slice<span class="token punctuation">(</span>word2int_cn<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dict_slice<span class="token punctuation">(</span>int2word_cn<span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>({'&lt;PAD&gt;': 0,  '&lt;BOS&gt;': 1,  '&lt;EOS&gt;': 2,  '&lt;UNK&gt;': 3,  '。': 4,  '我': 5,  '的': 6,  '了': 7,  '你': 8,  '他': 9,  '？': 10,  '在': 11,  '汤姆': 12,  '是': 13,  '吗': 14}, {0: '&lt;PAD&gt;',  1: '&lt;BOS&gt;',  2: '&lt;EOS&gt;',  3: '&lt;UNK&gt;',  4: '。',  5: '我',  6: '的',  7: '了',  8: '你',  9: '他',  10: '？',  11: '在',  12: '汤姆',  13: '是',  14: '吗'})</code></pre><h3 id="构建训练资料"><a href="#构建训练资料" class="headerlink" title="构建训练资料"></a>构建训练资料</h3><p>将数据划分成训练集，验证集和测试集</p><ul><li>训练集：25000句</li><li>验证集：1000句</li><li>测试集：1965句</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> en_sentence<span class="token punctuation">,</span> cn_sentence <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>en<span class="token punctuation">,</span> cn<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 去除中英文种出现3个未知词汇以上的句子</span>    tokens <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r  ]'</span><span class="token punctuation">,</span> en_sentence<span class="token punctuation">)</span>    tokens <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>    count <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        index <span class="token operator">=</span> word2int_en<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> index <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>            count <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>        tokens <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[ \n\t\r  ]'</span><span class="token punctuation">,</span> cn_sentence<span class="token punctuation">)</span>    tokens <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>    count <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        Index <span class="token operator">=</span> word2int_cn<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> Index <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>            count <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">if</span> count <span class="token operator">&gt;=</span> <span class="token number">3</span><span class="token punctuation">:</span>        <span class="token keyword">continue</span>    sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>en_sentence <span class="token operator">+</span> <span class="token string">'\t'</span> <span class="token operator">+</span> cn_sentence<span class="token punctuation">)</span>    sentences <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">)</span>     <span class="token comment"># 去重</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">2022</span><span class="token punctuation">)</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>train_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">25000</span><span class="token punctuation">]</span>validation_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token number">25000</span><span class="token punctuation">:</span><span class="token number">26000</span><span class="token punctuation">]</span>test_set <span class="token operator">=</span> sentences<span class="token punctuation">[</span><span class="token number">26000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>test_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>1965</code></pre><h2 id="定义dataset"><a href="#定义dataset" class="headerlink" title="定义dataset"></a>定义dataset</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 首先定义一个函数，它可以将句子扩展到相同长度，以便模型训练</span><span class="token keyword">class</span> <span class="token class-name">LabelTransform</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> size<span class="token punctuation">,</span> pad<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>size <span class="token operator">=</span> size        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad            <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>        label <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>label<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>size <span class="token operator">-</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'constant'</span><span class="token punctuation">,</span> constant_values<span class="token operator">=</span>self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>        <span class="token keyword">return</span> label<span class="token comment"># dataset</span><span class="token keyword">class</span> <span class="token class-name">EN2CNDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_output_len<span class="token punctuation">,</span> set_name<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">,</span> self<span class="token punctuation">.</span>int2word_en <span class="token operator">=</span> word2int_en<span class="token punctuation">,</span> int2word_en        self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">,</span> self<span class="token punctuation">.</span>int2word_cn <span class="token operator">=</span> word2int_cn<span class="token punctuation">,</span> int2word_cn        self<span class="token punctuation">.</span>data <span class="token operator">=</span> set_name                self<span class="token punctuation">.</span>cn_vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>en_vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> LabelTransform<span class="token punctuation">(</span>max_output_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;PAD&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 先将中英文分开</span>        sentences <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        sentences <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'[\t\n]'</span><span class="token punctuation">,</span> sentences<span class="token punctuation">)</span>        sentences <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentences<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(sentences)</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span>                <span class="token comment"># 预备特殊字符</span>        BOS <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;BOS&gt;'</span><span class="token punctuation">]</span>        EOS <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">]</span>        UNK <span class="token operator">=</span> self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">[</span><span class="token string">'&lt;UNK&gt;'</span><span class="token punctuation">]</span>                <span class="token comment"># 在开头添加 &lt;BOS&gt;，在结尾添加 &lt;EOS&gt; ，不在字典里面的 subword （词）用 &lt;UNK&gt; 代替</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span> <span class="token punctuation">[</span>BOS<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>BOS<span class="token punctuation">]</span>        <span class="token comment"># 将句子拆解为 subword ，并用字典对应的整数取代</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> sentences<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(f'en: {sentence}')</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_en<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> UNK<span class="token punctuation">)</span><span class="token punctuation">)</span>        en<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS<span class="token punctuation">)</span>                <span class="token comment"># 中文</span>        sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> sentences<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        sentence <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># print(f'cn: {sentence}')</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2int_cn<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> UNK<span class="token punctuation">)</span><span class="token punctuation">)</span>        cn<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS<span class="token punctuation">)</span>                en<span class="token punctuation">,</span> cn <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>        <span class="token comment"># print(en, cn)</span>                <span class="token comment"># 用 &lt;PAD&gt; 将句子补到相同的长度</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>        <span class="token comment"># print(en, cn)</span>        en<span class="token punctuation">,</span> cn <span class="token operator">=</span>  torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>cn<span class="token punctuation">)</span>                <span class="token keyword">return</span> en<span class="token punctuation">,</span> cn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Encoder-Decoder模型"><a href="#Encoder-Decoder模型" class="headerlink" title="Encoder-Decoder模型"></a>Encoder-Decoder模型</h2><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>seq2seq模型的编码器为RNN。对于每个输入，Encoder会输出一个向量和一个隐状态（hidden state），并将隐状态作为Decoder的输入。换句话说，Encoder会逐步读取输入序列，并输出单个向量（最终隐状态）</p><p>参数：</p><ul><li>en_vocab_size是英文字典的大小，也就是英文的subword的个数</li><li>emb_dim是embedding的维度，主要将one-hot vector的单词向量压缩到指定的维度，主要是为了将维和浓缩资讯的功能，可以使用预先训练好的word embedding</li><li>hid_dim是RNN输出和隐状态的维度</li><li>n_layers是RNN要叠多少层</li><li>dropout是决定有多少的概率会将某个节点变为0，主要是为了防止过拟合，一般来说是在训练时使用，测试时则不适用</li></ul><p>Encoder的输入：</p><ul><li>英文的整数序列</li></ul><p>输出：</p><ul><li>outputs：最上层RNN全部的输出，可以用Attention进行处理</li><li>hidden：每层最后的隐状态，将传递到Decoder进行解码</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> en_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>en_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> hid_dim        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> n_layers        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input = [batch size, sequence len, vocab size]</span>        embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># outputs = [batch size, sequence len, hid dim * directions]</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]</span>        <span class="token comment"># outputs 是最上层RNN的输出</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> hidden<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder是另一个RNN，在最简单的seq2seq decoder中， 仅使用Encoder每一层最后的隐状态来进行解码，这个隐状态用作Decoder的初始隐状态，本节先做最简单的Decoder，你也可以尝试将Encoder的输出用于Attention机制加到Decoder的输入中。</p><p>参数：</p><ul><li>cn_vocab_size是中文字典的大小，也就是中文的subword的个数</li><li>emb_dim是embedding的维度，主要将one-hot vector的单词向量压缩到指定的维度，主要是为了将维和浓缩资讯的功能，可以使用预先训练好的word embedding</li><li>hid_dim是RNN输出和隐状态的维度</li><li>n_layers是RNN要叠多少层</li><li>dropout是决定有多少的概率会将某个节点变为0，主要是为了防止过拟合，一般来说是在训练时使用，测试时则不适用</li></ul><p>Decoder的输入：</p><ul><li>前一次解码出来的单词的整数表示</li></ul><p>输出：</p><ul><li>hidden：根据输入和前一次的隐状态，现在的隐状态更新的结果</li><li>output：每个字有多少概率是这次解码的结果</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cn_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cn_vocab_size <span class="token operator">=</span> cn_vocab_size        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> hid_dim <span class="token operator">*</span> <span class="token number">2</span>    <span class="token comment"># Encoder使用双向RNN的缘故</span>        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> n_layers        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>cn_vocab_size<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> emb_dim        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding2vocab <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hid_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hid_dim <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input = [batch size, vocab size]</span>        <span class="token comment"># hidden = [batch size, n layers * directions, hid dim]</span>        <span class="token comment"># Decoder 只会是单向的，所以 directions=1</span>        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>                       <span class="token comment"># input(batch_size, 1, vocab_size)</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># embedded(batch_size, 1, embed_dim)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embedded<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>              <span class="token comment"># output(batch_size, 1, hid_dim * 2)  hidden(batch_size, num_layers * 1, hid_dim * 2)</span>                <span class="token comment"># 将 RNN 的输出转为每个词出现的概率</span>        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding2vocab<span class="token punctuation">(</span>output<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># prediction(batch_size, cn_vocab_size)</span>        <span class="token keyword">return</span> prediction<span class="token punctuation">,</span> hidden<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h3><p>这部分是整个seq2seq模型的构建，实现Encoder和Decoder的联合。简单来说就是Encoder接受输入得到输出，将Encoder的输出传给Decoder，然后将Decoder得到的输出传回Decoder进行解码，解码完成后，将Decoder的输出传回，就这样一直到输出中解码出&lt;EOS&gt;</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Seq2Seq</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Seq2Seq<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> encoder        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> decoder        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input  = [batch size, input len, vocab size]</span>        <span class="token comment"># target = [batch size, target len, vocab size]</span>        <span class="token comment"># teacher_forcing_ratio 是有多少概率使用正确答案来计算</span>        batch_size <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_len <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        vocab_size <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>cn_vocab_size                <span class="token comment"># 准备一个储存空间来储存输出</span>        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> target_len<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 输入进入Encoder</span>        encoder_outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token comment"># Encoder 最后的隐状态（hidden state）用来初始化 Decoder</span>        <span class="token comment"># encoder_outputs 主要是使用在 Attention</span>        <span class="token comment"># 因为 Encoder 是双向的RNN，所以需要将同一层两个方向的 hidden state 连接在一起</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]  --&gt; [num_layers, directions, batch size  , hid dim]</span>        hidden <span class="token operator">=</span> hidden<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 取的 &lt;BOS&gt; token</span>        <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> target_len<span class="token punctuation">)</span><span class="token punctuation">:</span>            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>            outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">=</span> output            <span class="token comment"># 决定是否用正确答案来做训练</span>            teacher_force <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> teacher_forcing_ratio            <span class="token comment"># 取出概率最大的单词</span>            top1 <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment"># 如果是 teacher force 则用正解训练，反之用自己预测的单词训练</span>            <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token keyword">if</span> teacher_force <span class="token keyword">and</span> t <span class="token operator">&lt;</span> target_len <span class="token keyword">else</span> top1            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>top1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> preds        <span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input  = [batch size, input len, vocab size]</span>        <span class="token comment"># target = [batch size, target len, vocab size]</span>        batch_size <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_len <span class="token operator">=</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        vocab_size <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>cn_vocab_size                <span class="token comment"># 准备一个储存空间来储存输出</span>        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> target_len<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 输入进入Encoder</span>        encoder_outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        <span class="token comment"># Encoder 最后的隐状态（hidden state）用来初始化 Decoder</span>        <span class="token comment"># encoder_outputs 主要是使用在 Attention</span>        <span class="token comment"># 因为 Encoder 是双向的RNN，所以需要将同一层两个方向的 hidden state 连接在一起</span>        <span class="token comment"># hidden =  [num_layers * directions, batch size  , hid dim]  --&gt; [num_layers, directions, batch size  , hid dim]</span>        hidden <span class="token operator">=</span> hidden<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 取的 &lt;BOS&gt; token</span>        <span class="token builtin">input</span> <span class="token operator">=</span> target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> target_len<span class="token punctuation">)</span><span class="token punctuation">:</span>            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>            outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">=</span> output            <span class="token comment"># 取出概率最大的单词</span>            top1 <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token builtin">input</span> <span class="token operator">=</span> top1            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>top1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> preds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Utils"><a href="#Utils" class="headerlink" title="Utils"></a>Utils</h2><h3 id="储存模型"><a href="#储存模型" class="headerlink" title="储存模型"></a>储存模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> store_model_path<span class="token punctuation">,</span> step<span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>store_model_path<span class="token punctuation">}</span></span><span class="token string">/model_</span><span class="token interpolation"><span class="token punctuation">{</span>step<span class="token punctuation">}</span></span><span class="token string">.ckpt'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="载入模型"><a href="#载入模型" class="headerlink" title="载入模型"></a>载入模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> load_model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Load model from </span><span class="token interpolation"><span class="token punctuation">{</span>load_model_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>load_model_path<span class="token punctuation">}</span></span><span class="token string">.ckpt'</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_model</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> en_vocab_size<span class="token punctuation">,</span> cn_vocab_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 构建模型</span>    encoder <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>en_vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>    decoder <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>cn_vocab_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>emb_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hid_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>n_layers<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># optimizer</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>    <span class="token keyword">if</span> config<span class="token punctuation">.</span>load_model<span class="token punctuation">:</span>        model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> config<span class="token punctuation">.</span>load_model_path<span class="token punctuation">)</span>        model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optimizer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="数字转句子"><a href="#数字转句子" class="headerlink" title="数字转句子"></a>数字转句子</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokens2sentence</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> int2word<span class="token punctuation">)</span><span class="token punctuation">:</span>    sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> tokens <span class="token keyword">in</span> outputs<span class="token punctuation">:</span>        sentence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        word <span class="token operator">=</span> int2word<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> word <span class="token operator">==</span> <span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>        sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>    sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>    <span class="token keyword">return</span> sentences<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="计算BLEU-score"><a href="#计算BLEU-score" class="headerlink" title="计算BLEU score"></a>计算BLEU score</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> nltk<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> sentence_bleu<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> SmoothingFunction<span class="token keyword">def</span> <span class="token function">computebleu</span><span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>    score <span class="token operator">=</span> <span class="token number">0</span>     <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>targets<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">cut_token</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> token <span class="token keyword">in</span> sentence<span class="token punctuation">:</span>            <span class="token keyword">if</span> token <span class="token operator">==</span> <span class="token string">'&lt;UNK&gt;'</span> <span class="token keyword">or</span> token<span class="token punctuation">.</span>isdigit<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">bytes</span><span class="token punctuation">(</span>token<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                tmp <span class="token operator">+=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> token<span class="token punctuation">]</span>        <span class="token keyword">return</span> tmp     <span class="token keyword">for</span> sentence<span class="token punctuation">,</span> target <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>sentences<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>        sentence <span class="token operator">=</span> cut_token<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>        target <span class="token operator">=</span> cut_token<span class="token punctuation">(</span>target<span class="token punctuation">)</span>        score <span class="token operator">+=</span> sentence_bleu<span class="token punctuation">(</span><span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                                                                              <span class="token keyword">return</span> score<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="迭代dataloader"><a href="#迭代dataloader" class="headerlink" title="迭代dataloader"></a>迭代dataloader</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">infinite_iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>    it <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            ret <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>it<span class="token punctuation">)</span>            <span class="token keyword">yield</span> ret        <span class="token keyword">except</span> StopIteration<span class="token punctuation">:</span>            it <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h2><p>实际工作中，训练一个好的机器翻译模型需要大量的语料，训练的周期长。本次实验数据集简单，训练耗时短，定义的训练和测试函数如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss_function<span class="token punctuation">,</span> total_steps<span class="token punctuation">,</span> summary_steps<span class="token punctuation">,</span> train_dataset<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>summary_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> sources<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> preds <span class="token operator">=</span> model<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token punctuation">)</span>        <span class="token comment"># targets 的第一个 token 是 &lt;BOS&gt; 所以忽略</span>        outputs <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        grad_norm <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        loss_sum <span class="token operator">=</span> loss_sum <span class="token operator">/</span> <span class="token number">5</span>        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">"train [{}] loss: {:.3f}, Perplexity: {:.3f} "</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_steps <span class="token operator">+</span> step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> loss_sum<span class="token punctuation">,</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>loss_sum<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>        losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_sum<span class="token punctuation">)</span>        loss_sum <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> losses<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataloader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_sum<span class="token punctuation">,</span> bleu_score<span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>    n <span class="token operator">=</span> <span class="token number">0</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> sources<span class="token punctuation">,</span> targets <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        sources<span class="token punctuation">,</span> targets <span class="token operator">=</span> sources<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        batch_size <span class="token operator">=</span> sources<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> preds <span class="token operator">=</span> model<span class="token punctuation">.</span>inference<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        <span class="token comment"># targets 的第一個 token 是 &lt;BOS&gt; 所以忽略</span>        outputs <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        loss_sum <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 將預測結果轉為文字</span>        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>view<span class="token punctuation">(</span>sources<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_cn<span class="token punctuation">)</span>        sources <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>sources<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_en<span class="token punctuation">)</span>        targets <span class="token operator">=</span> tokens2sentence<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>int2word_cn<span class="token punctuation">)</span>        <span class="token keyword">for</span> source<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> target <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>sources<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>            result<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>source<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 計算 Bleu Score</span>        bleu_score <span class="token operator">+=</span> computebleu<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        n <span class="token operator">+=</span> batch_size    <span class="token keyword">return</span> loss_sum <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> bleu_score <span class="token operator">/</span> n<span class="token punctuation">,</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h3><p>先训练后测试</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_process</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 准备训练资料</span>    train_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> train_set<span class="token punctuation">)</span>    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    train_iter <span class="token operator">=</span> infinite_iter<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>    <span class="token comment"># 准备验证资料</span>    val_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> validation_set<span class="token punctuation">)</span>    val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 构建模型</span>    model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> build_model<span class="token punctuation">(</span>config<span class="token punctuation">,</span> train_dataset<span class="token punctuation">.</span>en_vocab_size<span class="token punctuation">,</span> train_dataset<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span>    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    total_steps <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>total_steps <span class="token operator">&lt;</span> config<span class="token punctuation">.</span>num_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 训练模型</span>        model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss_function<span class="token punctuation">,</span> total_steps<span class="token punctuation">,</span> config<span class="token punctuation">.</span>summary_steps<span class="token punctuation">,</span> train_dataset<span class="token punctuation">,</span> config<span class="token punctuation">.</span>teacher_forcing_ratio<span class="token punctuation">)</span>        train_losses <span class="token operator">+=</span> loss        <span class="token comment"># 验证模型</span>        val_loss<span class="token punctuation">,</span> bleu_score<span class="token punctuation">,</span> result <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> val_loader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span>        val_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span>        bleu_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>bleu_score<span class="token punctuation">)</span>        total_steps <span class="token operator">+=</span> config<span class="token punctuation">.</span>summary_steps        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}  "</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_steps<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span><span class="token punctuation">,</span> bleu_score<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 储存模型的结果</span>        <span class="token keyword">if</span> total_steps <span class="token operator">%</span> config<span class="token punctuation">.</span>store_steps <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> total_steps <span class="token operator">&gt;=</span> config<span class="token punctuation">.</span>num_steps<span class="token punctuation">:</span>            save_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> config<span class="token punctuation">.</span>store_model_path<span class="token punctuation">,</span> total_steps<span class="token punctuation">)</span>            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>config<span class="token punctuation">.</span>store_model_path<span class="token punctuation">}</span></span><span class="token string">/output_</span><span class="token interpolation"><span class="token punctuation">{</span>total_steps<span class="token punctuation">}</span></span><span class="token string">.txt'</span></span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>                <span class="token keyword">for</span> line <span class="token keyword">in</span> result<span class="token punctuation">:</span>                    <span class="token keyword">print</span> <span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>f<span class="token punctuation">)</span>    <span class="token keyword">return</span> train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test_process</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 准备测试资料</span>    test_dataset <span class="token operator">=</span> EN2CNDataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>max_output_len<span class="token punctuation">,</span> test_set<span class="token punctuation">)</span>    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 构建模型</span>    model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> build_model<span class="token punctuation">(</span>config<span class="token punctuation">,</span> test_dataset<span class="token punctuation">.</span>en_vocab_size<span class="token punctuation">,</span> test_dataset<span class="token punctuation">.</span>cn_vocab_size<span class="token punctuation">)</span>    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Finish build model"</span><span class="token punctuation">)</span>    loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 测试模型</span>    test_loss<span class="token punctuation">,</span> bleu_score<span class="token punctuation">,</span> result <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> loss_function<span class="token punctuation">)</span>    <span class="token comment"># 储存结果</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'./log/cmn-eng/test_output.txt'</span></span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> result<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>f<span class="token punctuation">)</span>    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> bleu_score<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><ul><li>实验的参数设定表</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">configurations</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>        self<span class="token punctuation">.</span>emb_dim <span class="token operator">=</span> <span class="token number">256</span>        self<span class="token punctuation">.</span>hid_dim <span class="token operator">=</span> <span class="token number">512</span>        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> <span class="token number">2</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> <span class="token number">0.5</span>        self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> <span class="token number">0.00005</span>        self<span class="token punctuation">.</span>teacher_forcing_ratio <span class="token operator">=</span> <span class="token number">0.8</span>        self<span class="token punctuation">.</span>max_output_len <span class="token operator">=</span> <span class="token number">40</span>              <span class="token comment"># 最后输出句子的最大长度</span>        self<span class="token punctuation">.</span>num_steps <span class="token operator">=</span> <span class="token number">12000</span>                <span class="token comment"># 总训练次数</span>        self<span class="token punctuation">.</span>store_steps <span class="token operator">=</span> <span class="token number">300</span>                <span class="token comment"># 训练多少次后需存模型</span>        self<span class="token punctuation">.</span>summary_steps <span class="token operator">=</span> <span class="token number">300</span>              <span class="token comment"># 训练多少次后需检验是否有过拟合</span>        self<span class="token punctuation">.</span>load_model <span class="token operator">=</span> <span class="token boolean">False</span>               <span class="token comment"># 是否需载入模型</span>        self<span class="token punctuation">.</span>store_model_path <span class="token operator">=</span> <span class="token string">"./log/ckpt"</span>      <span class="token comment"># 储存模型的位置</span>        self<span class="token punctuation">.</span>load_model_path <span class="token operator">=</span> <span class="token string">"./log/ckpt/model_12000"</span>           <span class="token comment"># 载入模型的位置 e.g. "./ckpt/model_{step}" </span>        self<span class="token punctuation">.</span>data_path <span class="token operator">=</span> <span class="token string">"./data/cmn-eng"</span>          <span class="token comment"># 资料存放的位置</span>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> <span class="token boolean">False</span>                <span class="token comment"># 是否使用 Attention Mechanism</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练模型:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">config <span class="token operator">=</span> configurations<span class="token punctuation">(</span><span class="token punctuation">)</span>train_losses<span class="token punctuation">,</span> val_losses<span class="token punctuation">,</span> bleu_scores <span class="token operator">=</span> train_process<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>Seq2Seq(  (encoder): Encoder(    (embedding): Embedding(4397, 256)    (rnn): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)    (dropout): Dropout(p=0.5, inplace=False)  )  (decoder): Decoder(    (embedding): Embedding(6798, 256)    (rnn): GRU(256, 1024, num_layers=2, batch_first=True, dropout=0.5)    (embedding2vocab): Sequential(      (0): Linear(in_features=1024, out_features=4096, bias=True)      (1): Linear(in_features=4096, out_features=6798, bias=True)    )    (dropout): Dropout(p=0.5, inplace=False)  ))Adam (Parameter Group 0    amsgrad: False    betas: (0.9, 0.999)    eps: 1e-08    lr: 5e-05    weight_decay: 0) train [300] loss: 0.911, Perplexity: 2.488   val [300] loss: 5.124, Perplexity: 168.024, blue score: 0.186   val [600] loss: 4.827, Perplexity: 124.873, blue score: 0.233   val [900] loss: 4.643, Perplexity: 103.901, blue score: 0.278   val [1200] loss: 4.538, Perplexity: 93.484, blue score: 0.291   val [1500] loss: 4.514, Perplexity: 91.273, blue score: 0.288   val [1800] loss: 4.457, Perplexity: 86.216, blue score: 0.307   val [2100] loss: 4.504, Perplexity: 90.364, blue score: 0.313   val [2400] loss: 4.392, Perplexity: 80.830, blue score: 0.333   val [2700] loss: 4.389, Perplexity: 80.539, blue score: 0.329   val [3000] loss: 4.380, Perplexity: 79.800, blue score: 0.342   val [3300] loss: 4.319, Perplexity: 75.126, blue score: 0.357   val [3600] loss: 4.245, Perplexity: 69.757, blue score: 0.358   val [3900] loss: 4.262, Perplexity: 70.927, blue score: 0.371   val [4200] loss: 4.241, Perplexity: 69.500, blue score: 0.375   val [4500] loss: 4.234, Perplexity: 68.983, blue score: 0.387   val [4800] loss: 4.186, Perplexity: 65.791, blue score: 0.385   val [5100] loss: 4.122, Perplexity: 61.675, blue score: 0.396   val [5400] loss: 4.162, Perplexity: 64.201, blue score: 0.399   val [5700] loss: 4.148, Perplexity: 63.323, blue score: 0.410   val [6000] loss: 4.065, Perplexity: 58.286, blue score: 0.404   val [6300] loss: 4.089, Perplexity: 59.695, blue score: 0.410   val [6600] loss: 4.076, Perplexity: 58.931, blue score: 0.417   val [6900] loss: 4.103, Perplexity: 60.544, blue score: 0.423   val [7200] loss: 4.102, Perplexity: 60.452, blue score: 0.426   val [7500] loss: 4.092, Perplexity: 59.838, blue score: 0.429   val [7800] loss: 4.029, Perplexity: 56.186, blue score: 0.433   val [8100] loss: 4.057, Perplexity: 57.809, blue score: 0.440   val [8400] loss: 4.023, Perplexity: 55.880, blue score: 0.440   val [8700] loss: 4.025, Perplexity: 55.962, blue score: 0.445   val [9000] loss: 4.043, Perplexity: 57.014, blue score: 0.450   val [9300] loss: 4.020, Perplexity: 55.690, blue score: 0.453   val [9600] loss: 4.030, Perplexity: 56.256, blue score: 0.460   val [9900] loss: 4.032, Perplexity: 56.365, blue score: 0.465   val [10200] loss: 4.056, Perplexity: 57.730, blue score: 0.454   val [10500] loss: 4.001, Perplexity: 54.639, blue score: 0.465   val [10800] loss: 4.055, Perplexity: 57.664, blue score: 0.461   val [11100] loss: 4.007, Perplexity: 55.003, blue score: 0.470   val [11400] loss: 4.063, Perplexity: 58.153, blue score: 0.468   val [11700] loss: 4.042, Perplexity: 56.917, blue score: 0.474   val [12000] loss: 4.072, Perplexity: 58.686, blue score: 0.475  </code></pre><p>测试模型：</p><p>在执行这步之前，请先去config设定所要载入模型的位置，并将load_model设置为True</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">config<span class="token punctuation">.</span>load_model <span class="token operator">=</span> <span class="token boolean">True</span>test_loss<span class="token punctuation">,</span> bleu_score <span class="token operator">=</span> test_process<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'test loss: </span><span class="token interpolation"><span class="token punctuation">{</span>test_loss<span class="token punctuation">}</span></span><span class="token string">, bleu_score: </span><span class="token interpolation"><span class="token punctuation">{</span>bleu_score<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>Seq2Seq(  (encoder): Encoder(    (embedding): Embedding(4397, 256)    (rnn): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)    (dropout): Dropout(p=0.5, inplace=False)  )  (decoder): Decoder(    (embedding): Embedding(6798, 256)    (rnn): GRU(256, 1024, num_layers=2, batch_first=True, dropout=0.5)    (embedding2vocab): Sequential(      (0): Linear(in_features=1024, out_features=4096, bias=True)      (1): Linear(in_features=4096, out_features=6798, bias=True)    )    (dropout): Dropout(p=0.5, inplace=False)  ))Adam (Parameter Group 0    amsgrad: False    betas: (0.9, 0.999)    eps: 1e-08    lr: 5e-05    weight_decay: 0)Load model from ./log/ckpt/model_12000Finish build modeltest loss: 4.043186987083377, bleu_score: 0.470621067287946</code></pre><h2 id="图形化训练过程"><a href="#图形化训练过程" class="headerlink" title="图形化训练过程"></a>图形化训练过程</h2><h3 id="训练的loss变化趋势"><a href="#训练的loss变化趋势" class="headerlink" title="训练的loss变化趋势"></a>训练的loss变化趋势</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'train loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_49_1.png" class="">    <h2 id="验证的loss变化趋势"><a href="#验证的loss变化趋势" class="headerlink" title="验证的loss变化趋势"></a>验证的loss变化趋势</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>val_losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'validation loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_51_0.png" class=""><h2 id="BLEU-score"><a href="#BLEU-score" class="headerlink" title="BLEU score"></a>BLEU score</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>bleu_scores<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'次数'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'BLEU score'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'BLEU score'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/04/11/seq2seq-dai-ma-shi-xian/output_53_0.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2020-spring.php">李宏毅 机器学习2020</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Seq2Seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于GAN的多水库径流序列的随机生成</title>
      <link href="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/"/>
      <url>/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="基于GAN的多水库径流序列的随机生成"><a href="#基于GAN的多水库径流序列的随机生成" class="headerlink" title="基于GAN的多水库径流序列的随机生成"></a>基于GAN的多水库径流序列的随机生成</h1><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404135935711-16490728909091.png" class=""><p>该文将DCGAN和WGAN结合起来组成一个新的方法DC-WGAN，并用于径流序列的随机生成。该方法可以同时捕捉径流序列在时间和空间维度上的相关性，解决了传统方法（如Copula等）在径流序列随机生成中时空相关性表现不足的问题。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>隐式随机优化(implicit stochastic optimization, ISO)模型是一种已广泛应用于水库系统中长期优化运行的方法。在实际工程中，水库历史序列的长度只有几十年，难以反映未来径流变化的随机性。因此径流序列的生成是弥补历史径流样本代表性和可靠性差的关键技术，是保证ISO模型准确性的前提。</p><p>对于单个水库，现有径流序列的样本时间长度能满足ISO的操作要求。但对于具有时空相关性的径流序列，当前样本的代表性和可靠性不足以满足。而具有时空相关性的径流序列的产生给水库系统联合优化运行的精细化管理带来了巨大的挑战。然而现有径流序列生成方法并没有体现水库间的时空相关性，它们有以下缺点：</p><ul><li>难以扩展到高维，不适合多时间尺度的多水库系统的径流随机生成</li><li>径流序列的概率分布应事先假定，这在实际中不适用</li><li>难于捕捉高维数据的非线性特点，无法满足水库系统径流生成的要求</li></ul><p>为解决上述问题，作者提出了一种基于GAN的径流序列的随机生成。GAN的特征有：①可以直接学习历史数据的分布，无需预先进行数据概率分布的假定；②无监督学习的模式避免繁琐的人工标注，适用于学习和生成大规模的数据集。作者将GAN的这些特点应用于径流系统的随机生成，创新点有：</p><ul><li>从模型学习能力和泛化能力两个方面探索DC-WGAN在水库系统径流随机生成领域的随机性</li><li>与Copula方法相比，分析DC-WGAN径流样本的时空相关性</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><p>生成式对抗网络(Generative adversarial network , GAN)在2014年被Goodfellow提出，已广泛用于计算机视觉和自然语言处理等领域。GAN通过生成器(generator)和判别器(discriminator)的对立实现了很好的生成效果。这两个网络的不同点在于，生成器的输入是一组随机噪音，作用是生成和目标数据分布相似的数据。而判别器的输入有真实数据和生成器生成的数据，输出是一个概率值，表示输入数据是历史数据的置信度。比如输出为1代表输入数据为真实数据，输出为0代表是生成数据。</p><p>假设我们有M个水库，每个水库拥有N年的历史径流数据，每年的径流数据被划分为T个时期。历史径流数据可以表示为</p><p>$${x^{t}_{i,j}},i=1,2,…,M;j=1,2,…,N;t=1,2,…,T$$</p><p>真实数据用$P_{data}(x)$表示，GAN的两个网络结构：生成器$G(z;\theta^{G})$，判别器$D(x;\theta^{D})$，其中$\theta^{G}$和$\theta^{D}$是这两个网络结构的权重参数（需要通过训练得到）,z是一个已知分布的随机噪音。生成器的目标是产生的数据的分布要尽可能和真实数据的分布相似，用于<strong>“欺骗”</strong>判别器。而判别器的目标是区分数据是来源于真实数据还是生成数据。这两个网络在迭代过程中相互竞争以提高模型性能，最终生成的数据与真实数据基本一致。</p><p>在确定网络训练的目标后，我们需要分别为生成器和判别器制定损失函数(loss function)来训练这个模型。生成器的目标是“欺骗”判别器，因此生成器的目标是最大化$D(G(z))$。判别器的目标是区分数据，因此我们最小化$D(G(z))$并最大化$D(x),x\in P_{data}(x)$。因此损失函数$L_{G}和L_{D}$可以表示为：</p><p>$$L_{G}=E_{z\in p_{z}(z)}[log(1-D(G(z)))]$$</p><p>$$L_{D}=-E_{z\in p_{z}(z)}[log(1-D(G(z)))]-E_{x\in p_{data}(x)}[log(D(x))]$$</p><p>结合以上两个式子，则整个模型变成一个minimax游戏，其目标函数变为：</p><p>$$\underset{\theta_{G}}{min}\underset{\theta_{D}}{max}V(G,D)=E_{z\in p_{z}(z)}[log(1-D(G(z)))]+E_{x\in p_{data}(x)}[log(D(x))]$$</p><h3 id="改进的GAN"><a href="#改进的GAN" class="headerlink" title="改进的GAN"></a>改进的GAN</h3><h4 id="原始生成式对抗网络存在的缺点"><a href="#原始生成式对抗网络存在的缺点" class="headerlink" title="原始生成式对抗网络存在的缺点"></a><strong>原始生成式对抗网络存在的缺点</strong></h4><ul><li>很难同时使两个网络同时收敛到最优，这就会影响模型训练的稳定性。举个简单例子，假设判别器的损失函数很短时间就收敛到0，那么生成器的参数就很难更新，这就导致生成器梯度消失的问题。</li><li>通过一定的数学假设，可以用JS散度来表示上面的目标函数，而JS散度存在一个问题，就是真实数据$P_{data}$和生成数据$P_{G}$没有数据重叠的话，不断真实数据和生成数据之间的距离多远，JS散度计算出来的值都是log2，这就导致了生成器梯度消失的问题。</li></ul><p>大部分改进的GAN都是为了解决上述两个问题，其中DCGAN和WGAN是最有效且使用较为广泛的。</p><h4 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h4><p>深度卷积生成式网络(deep convolutional generative adversarial network, DCGAN)在原始GAN模型的基础上，将生成器和判别器的网络结构换成了当时已经十分成熟的卷积神经网络结构，并对卷积神经网络结构进行一定的调整，克服了原始GAN训练不稳定和梯度消失的问题。具体改变有：</p><ul><li>取消所有的pooling层。生成器中使用fractionally strided convolution代替pooling层，判别器中使用strided convolution代替pooling层。</li><li>在生成器和判别器中都使用批量标准化</li><li>去除了全连接层</li><li>生成器中使用ReLU作为激活函数，最后一层使用tanh激活函数</li><li>判别器中使用LeakyReLU作为激活函数</li></ul><p>DCGAN的网络结构如下：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404182400171-16490728909102.png" class=""><h4 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h4><p>Wasserstein生成式对抗网络使用Wasserstein Distance来替换掉JS-Divergence，解决了当生成数据和真实数据没有重叠时，JS散度为log2，从而导致生成器梯度消失的问题。WGAN的优点有：</p><ul><li>判别器训练的越好，生成器就越好，这大大提高了原始GAN的稳定性</li><li>避免了模型在训练过程中崩溃，一定程度上提升了模型的鲁棒性</li></ul><h4 id="DC-WGAN"><a href="#DC-WGAN" class="headerlink" title="DC-WGAN"></a>DC-WGAN</h4><p>结合DCGAN和WGAN，作者提出了DC-WGAN模型，它的结构图如下：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404183358982-16490728909103.png" class=""><p>DC-WGAN的模型架构和算法流程分别看左图和右图：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404183813487-16490728909104.png" class=""><h2 id="研究区域"><a href="#研究区域" class="headerlink" title="研究区域"></a>研究区域</h2><p>作者以中国下游金沙江梯级水库和三峡梯级水库为研究案例，包括溪洛渡、向家坝、三峡和葛洲坝四个水库。它们的地理位置如下图所示：</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404184312072-16490728909106.png" class=""><p>DC-WGAN模型的实验数据为这四个水库从1940到2010的径流序列，其中90%的径流序列（64年）被用于模型训练，10%（10年）被用于模型的验证。径流序列的时间尺度为10天，模型经过训练后产生3000个10天径流序列。</p><p>同时，用相同的数据，作者还用copula方法产生对应的径流序列，并将结果与DC_WGAN进行比较。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="学习能力"><a href="#学习能力" class="headerlink" title="学习能力"></a>学习能力</h3><p>为了验证DC-WGAN的学习能力，原始径流序列和DC-WGAN生成的径流序列的频率曲线如下图所示。图中DC-WGAN生成的径流样本是随机从3000个生成样本随机选择了64个（和原始数据数量一样），频率曲线使用对数正态分布函数绘制。从图中可以看出两个频率曲线几乎完全重叠，说明DC-WGAN生成了正确分布的径流序列。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404190906074-16490728909105.png" class=""><h3 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h3><p>为了进一步验证DC-WGAN的泛化能力，作者使用欧几里得距离(Euclidean distance)在DC-WGAN生成的3000条径流数据中找出和7个验证数据最相似的。其中三个径流序列如下图所示。由图可以看出DC-WGAN可以生成与验证集相似形态的样本，说明模型具有很强的泛化能力，图中的自相关系数曲线也验证了DC-WGAN可以捕捉径流序列的时间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404191726339-16490728909107.png" class=""><h3 id="时间相关性"><a href="#时间相关性" class="headerlink" title="时间相关性"></a>时间相关性</h3><p>为了验证径流序列的时间相关性，作者分别绘制了原始样本和分别从DC-WGAN和Copula生成样本的相关系数热力图。从下图可以看出Copula生成序列的相关性弱于原始序列和DC-WGAN生成的序列，且基于Copula的生成方法无法捕捉到弱相关性，表明DC-WGAN可以更好地学习序列的时间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404192738463-16490728909108.png" class=""><h3 id="空间相关性"><a href="#空间相关性" class="headerlink" title="空间相关性"></a>空间相关性</h3><p>为了验证径流序列的空间相关性，基于原始样本、DC-WGAN和Copula生成样本，计算溪洛渡和三峡水库10天径流的空间相关系数，如下图所示。基于三种样本的平均年径流相关系数分别为0.67、0.65和-0.01。同时可以明显地看出，溪洛渡径流系列与三峡水库径流序列呈现出较强的空间相关性。DC-WGAN可以学习到水库间径流序列的空间相关性，但基于Copula的生成方法无法捕捉到不同水库间径流序列的空间相关性。</p><img src="/2022/04/04/ji-yu-gan-de-duo-shui-ku-jing-liu-xu-lie-de-sui-ji-sheng-cheng/image-20220404194104273-16490728909109.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022169421013767?via=ihub">Ma Y, Zhong P, Xu B, et al. Stochastic generation of runoff series for multiple reservoirs based on generative adversarial networks[J]. Journal of Hydrology, 2022, 605: 127326.</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> 径流序列的随机生成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自注意力模型</title>
      <link href="/2022/04/02/zi-zhu-yi-li-mo-xing/"/>
      <url>/2022/04/02/zi-zhu-yi-li-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>前面我们学习过LSTM、GRU，它们都可以挖掘序列之间的某种联系。举个简单的例子——I saw a saw（我看见了一把锯子），句中两个saw无论在词义还是词性中都有所不同。如果将这句话简单做词向量处理，然后丢进一个全连接模型的话，那么两个saw输出的结果是一样的。因为对于这种模型而言的话，它是挖掘不出词与词之间的关系。而对于LSTM，GRU来说，它通过一定的机制可以学习到句子和句子之间的联系。</p><p>那么注意力机制是怎么学习这种联系的呢？这还得从我们人类的视觉说起。当我们在看到图片或风景的时候，我们会将注意力集中到我们关注的那些事物上。比如你在绘画的过程中，你会持续地关注你构思到画板上的元素（比如蓝天，白云），而不会太多关注那些其他的元素，比如风，虫鸣，阳光等等。这种有意识的聚焦就被称为注意力机制。那么机器是怎么将这种机制应用到模型中呢？这也是这篇文章要学习的内容。</p><h2 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h2><p>仍然以I saw a saw为例，如下图所示，我们设置一个window，该window只考虑了周围三个输入，此时模型当前的输出就和周围三个输入有关。那么我们将window覆盖整个文本，是不是可以考虑整个句子中单词与单词之间的联系？</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402122749713-16488871089911.png" class=""><p>自注意力机制借鉴了这个想法，用一个结构实现上述Window中的操作，从而可以考虑句中每个单词之间的联系，进而区别出这两个saw。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402124424005-16488871089922.png" class=""><p>Attention机制通常有Bahdanau Attention（右图）与Luong Attention（左图），两种注意力的理论相似，Luong Attention的使用范围更广泛，因此本文主要讲解Luong Attention。在讲解Luong Attention前，我们先来讲解三个概念——查询、键和值。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402125443414-16488871089923.png" class=""><h3 id="查询、键和值"><a href="#查询、键和值" class="headerlink" title="查询、键和值"></a>查询、键和值</h3><p>在注意力机制的背景下，我们将自主性提示称为查询（query）。给定任何查询，注意力机制通过注意力汇聚将选择引导至感官输入。在注意力机制中，这些感官输入被称为值（value）。对于每个值都有一个键（key）与之配对，这可以想象成感官输入的非自主提示。通过注意力汇聚，每个查询（自主性提示）都可以与键（非自主性提示）进行匹配，这将引导得出最匹配的值（感官输入）。下面我们来看看查询、键和值是怎样在self-attention中运作的。</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402132249578-16488871089924.png" class=""><p>  假设输入是：${a^{1},a^{2},a^{3},a^{4}}$。每个输入都对应查询、键和值。查询$q^{i}=W^{q}a^{i}$，键$k^{i}=W^{k}a^{i}$以及值$v^{i}=W^{v}a^{i}$。对于查询query，我们需要找所对应的键与之进行匹配，这样就可以得出那些信息比较重要。对应计算$a_{1,i}=q^{1}k^{i}$，再经过softmax层就可以算出每个信息对应的比重:</p><p>$$a_{1,i}^{‘}=exp(a_{1,i}/ \sum_{j}{a_{1,j}})$$</p><p>进而可以求出$a^{1}$对应的输出$b^{1}=\sum_{i}a^{‘}_{1,i}v^{i}$，同理我们可以计算出$b^{2},b^{3},b^{4}$。如果计算机也这样一个接一个计算，那计算效率太低。其实我们可以通过矩阵运算实现平行运算，具体操作如下：</p><p>查询：$$q^{i}=W^{q}a^{i}\Rightarrow (q^{1},q^{2},q^{3},q^{4})=W^{q}(a^{1},a^{2},a^{3},a^{4})$$</p><p>键：$$k^{i}=W^{k}a^{i}\Rightarrow (k^{1},k^{2},k^{3},k^{4})=W^{k}(a^{1},a^{2},a^{3},a^{4})$$</p><p>值：$$v^{i}=W^{v}a^{i}\Rightarrow (v^{1},v^{2},v^{3},v^{4})=W^{v}(a^{1},a^{2},a^{3},a^{4})$$</p><p>对于中间部分的计算可以用下图表示：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402144505171-16488871089925.png" class=""><p>从而可以得到输出：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402144618597-16488871089926.png" class=""><p>整理一下可得：</p><p>查询、键和值：$$Q,K,v=W^{q}I,W^{k}I,W^{v}I$$</p><p>注意力矩阵：$$A^{‘}\Leftarrow A=K^{T}Q$$</p><p>输出：$$O=VA^{‘}$$</p><p>由此可以看出 self-attention 需要率定的参数有$W^{q},W^{k},W^{v}$</p><h3 id="多头自注意力模型"><a href="#多头自注意力模型" class="headerlink" title="多头自注意力模型"></a>多头自注意力模型</h3><p>多头注意力（Multi-head Self-attention）模型是建立在自注意力模型的基础上。它模拟的是序列中存在不止一种的联系，这时单靠一个head是无法捕捉序列中的完整信息。以2 head为例，利用两组$W^{q},W^{k},W^{v}$对应输入$a^{i}$分别单独计算出两个输出$b^{i,1},b^{i,2}$，然后通过一个输出矩阵可以得出$b^{i}$：</p><p>$$b^{i}=W^{o}(b^{i,1},b^{i,2})^{T}$$</p><p>由此可以看出2 head带来了两倍以上的参数，虽然模型的准确度得到了提升，但是以损失计算能力为代价。</p><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>self-attention虽然考虑了输入序列中每个成分之间的联系，但并没考虑输入序列的先后顺序。这是因为self-attention中的计算是平行计算，无论序列中两个成分相隔多远，对self-attention的整个计算没有什么影响。而对于某些实际应用，序列的顺序对模型影响很大或者可以一定程度上提升模型性能。举个例子，在词性标注中，我们知道动词是很少出现在一个句子的开头。所以当一个单词出现在句子的开头时，我们有很大的把握判断这个单词不是动词。</p><p>为了改进self-attention这个弱点，我们可以对输入进行一定的操作——位置编码，从而使得self-attention考虑到序列的顺序。这个操作其实很简单，我们只需在每个输入对应的位置加一个独一无二的位置向量即可实现：</p><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402153801462-16488871089927.png" class=""><p>这时你就会有一个疑问，位置编码是怎么确定的？具体可以看这篇论文：<a href="https://arxiv.org/abs/2003.09229">Learning to Encode Position for Transformer with Continuous Dynamical Model</a></p><h2 id="Self-attention-vs-RNN"><a href="#Self-attention-vs-RNN" class="headerlink" title="Self-attention vs RNN"></a>Self-attention vs RNN</h2><img src="/2022/04/02/zi-zhu-yi-li-mo-xing/image-20220402155319292-16488871089928.png" class=""><p>上图展示的是循环神经网络和自注意力模型的简易结构，由此可以看出self-attention相对RNN的结构优点：</p><ul><li>self-attention是平行计算，单次迭代计算速度块</li><li>self-attention可以方便地考虑两个相隔较远的单词之间的联系，而RNN虽然也能考虑到，但RNN在传递的过程中，这种联系会消失。因此self-attention在处理序列中含有较大关联的模型中更有优势。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅 机器学习2021</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Seq2Seq</title>
      <link href="/2022/03/29/seq2seq/"/>
      <url>/2022/03/29/seq2seq/</url>
      
        <content type="html"><![CDATA[<p><strong>写在前面：</strong>这个部分主要记录一些关于深度学习相关论文的阅读，由于个人还是刚接触深度学习不久，所以前面需要补充一些很早的论文以巩固自己知识的不足。今天记录最近学的一篇论文<a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>。这篇论文研究的是机器翻译领域，作者使用的方法是利用一个多层的 LSTM 将输入文本编码成一个向量，这个向量可以视为整个输入句子的抽象表示。然后用另一个 LSTM 将前面编码的向量解码成目标句子。作者将其应用在 WMT’14 数据集上英语到法语的翻译任务，并在整个测试集上得到的 BLEU score 为34.8。下面我门结合<a href="https://d2l.ai/">Dive into Deep Learning</a>这本书的相关章节和这篇论文了解 seq2seq 的一般概念，并陈述构建模型时需要用的一些方法。</p><h2 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h2><p>最常用的 seq2seq 模型其实就是encoder-decoder模型。encoder-decoder模型通常使用 RNN 将一段文本作为输入编码（encoder）成一个向量，这个向量可以视为整个输入句子的抽象表示。然后，该向量通过第二个 RNN 解码（decoder），该 RNN 通过一次生成一个单词来学习目标句子（也就是另一种语言的句子）。下图演示了将 seq2seq 模型用于英文到中文的翻译。</p><img src="/2022/03/29/seq2seq/seq2seq.png" class=""><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>图中展示了一个简单的翻译模型，模型中用&lt;bos&gt;和&lt;eos&gt;分别表示开始词元和结束词元。它的输入句子是”good morning“，它首先通过embedding层转换为对应的词向量，然后再进入编码器（encoder）。在每一个时间步，进入编码器RNN含有embedding$x_{t}$和上一时间步隐状态$h_{t-1}$，然后编码器RNN产生新的隐状态$h_{t}$。我们可以抽象地把这个隐状态代表为前面的词元。该时间步的计算可以用以下公式表达：<br>$$h_{t}=EncoderRNN(e(x_{t},h_{t-1}))$$</p><p>在这里，我们通常使用LSTM或GRU这样的term RNN。假设，输入$X={x_{1},x_{2},…,x_{T}}$，式中 $x_{1}$=&lt;bos&gt;，$x_{2}$=good，etc 。编码器初始的隐状态 $h_{0}$ 通常初始化为0或者已经学习好的参数。一旦最后的词元 $x_{T}$ 通过embedding层进入编码器RNN，我们利用最后的隐状态 $h_{T}$ 来作为文本向量，并把它赋值给z :$h_{T}=z$</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>现在我们拥有文本向量z，我们可以开始将其解码成目标句子——”早上好“。同样我们用<sos>和<eos>分别表示目标句子的开始词元和结束词元。在每一个时间步，解码器RNN的输入是当前词元$y_{t}$的embedding $d$和上一时间步的隐状态$s_{t-1}$。在解码器RNN，初始隐状态$s_{0}=z=h_{T}$，即解码器初始隐状态就是编码器的最终隐状态。我们同样用一个公式表示该时间步解码器的操作：<br>$$s_{t}=DecoderRNN(d(y_{t},s_{t-1}))$$<br>在解码器中，我们需要将隐状态转换为对应的单词，因此在每一个时间步，我们通过一个线性层通过$s_{t}$去预测下一个在文本出现的单词$\overset{-}{y_{t}}$<br>$$\overset{-}{y_{t}}=f(s_{t})$$<br>解码器中的单词是随着时间步一个接一个地生成。我们通常使用&lt;bos&gt;作为解码器的第一个输入$y_{1}$，但是对于接下来的输入$y_{t&gt;1}$，我们有时使用在目标句子中下一个单词，有时也会使用经解码器预测的下一个单词$\overset{-}{y_{t}}$，这在机器翻译中被叫做teacher forcing。使用teacher-forcing，在训练过程中，可以加快模型的训练，使得模型会有较好的效果。但是在测试的时候因为不能得到目标句子的支持，存在训练测试偏差，模型会变得脆弱。<br>训练模型时，我们通常知道目标句子有多少单词，一旦解码器输入目标单词，模型就会停止生成单词。但在测试模型时，解码器会不断生成单词，直到模型输出&lt;eos&gt;或生成一定数量的单词之后，模型就停止生成单词。</eos></sos></p><p>一旦模型得到了预测目标句子$\overset{-}{Y}={\overset{-}{y_{1}},\overset{-}{y_{2}},…,\overset{-}{y_{t}}}$，我们将其和目标句子$Y={y_{1},y_{2},…,y_{t}}$进行比较，计算出误差，利用该误差就可以更新模型的所有参数。</p><h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ul><li>将文本词元化，在机器翻译中我们更喜欢单词级词元化。对训练数据的文本序列进行词元，其中每个词元要么是一个词，要么是一个标点符号。</li><li>分别为源语言和目标语言构建两个字典——int2word 和 word2int （这两个字典将单词和整数一一对应）。同时为了减少数据噪声的影响，我们将出现次数少于2次的低频率词元视为未知 &lt;unk&gt; 词元。除此之外，我们还指定一些额外的特定词元，例如在小批量时用于将序列填充到相同长度的填充词元 &lt;pad&gt; ，以及序列的开始词元 &lt;bos&gt; 和结束词元 &lt;eos&gt; 。</li><li>为了提高计算效率，我们可以通过截断和填充方式实现每个序列都具有相同的长度。当文本序列词元数目少于规定数据时，我们将继续在其末尾添加特定的 &lt;pad&gt; 词元。反之，我们将截断文本序列，只取前指定数目个词元，丢弃剩余词元。</li></ul><h3 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h3><p>这一部分可以参考论文</p><img src="/2022/03/29/seq2seq/1.png" class=""><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>门控循环单元</title>
      <link href="/2022/03/25/men-kong-xun-huan-dan-yuan/"/>
      <url>/2022/03/25/men-kong-xun-huan-dan-yuan/</url>
      
        <content type="html"><![CDATA[<p>门控循环单元（gated recurrent units, GRU）于2014被Cho等人提出。GRU和LSTM一样有专门的机制来确定应该何时更新隐状态，以及应该何时重置隐状态，但GRU没有单独的存储单元，即LSTM的记忆元。GRU是LSTM的一个变体，它结构更加简单，却能够提供和LSTM同等的效果，并且计算的速度明显更快。</p><p>现在我们从GRU的内部结构开始解读：</p><h2 id="重置门和更新门"><a href="#重置门和更新门" class="headerlink" title="重置门和更新门"></a>重置门和更新门</h2><p>我们首先介绍重置门（reset gate）和更新门（update gate）。重置门控制着我们还想记住过去状态的数量；更新门决定着新状态保存旧状态信息的程度。这两个门的输入和LSTM一样，是当前时间步的输入和上一时间步的隐状态，它们的输出是由使用sigmoid激活函数的两个全连接层给出。因此它们的数学表达为：</p><p>$$R_{t}=\sigma({X_{t}W_{xr}+H_{t-1}W_{hr}+b_{r}})$$</p><p>$$Z_{t}=\sigma({X_{t}W_{xz}+H_{t-1}W_{hz}+b_{z}})$$</p><p>式中：$X_{t}\in R^{nxd}$是输入（样本个数：n，维度：d）；$H_{t-1}\in R^{nxh}$是上一时间步的隐状态；$R_{t}\in R^{nxd}$和$Z_{t}\in R^{nxd}$分别是重置门和更新门；$W_{xr},W_{xz}\in R^{dxh}$和$W_{hr},W_{hz}\in R^{hxh}$是权重参数，$b_{r},b_{z}\in R^{1xh}$是偏置项。</p><h2 id="候选隐状态"><a href="#候选隐状态" class="headerlink" title="候选隐状态"></a>候选隐状态</h2><p>候选隐状态（candidate hidden state）$\overset{-}{H_{t}}\in R^{nxh}$的计算公式如下：</p><p>$$\overset{-}{H_{t}}=tanh(X_{t}W_{xh}+(R_{t}\bigodot H_{t-1})W_{hh}+b_{h})$$</p><p>式中$W_{xh}\in R^{dxh}$和$W_{hh}\in R^{hxh}$是权重参数，$b_{h}\in R^{1xh}$是偏置项，符号$\bigodot$是Hadamard积（按元素乘积）运算符。</p><p>重置门$R_{t}$可以控制以往状态的影响程度， 当$R_{t}$中所有项接近1时，保留前一隐状态所有影响。当$R_{t}$中所有项接近0时，候选隐状态是以$X_{t}$作为输入的多层感知机的结果。</p><p>以上计算流程可以用下图表示：</p><img src="/2022/03/25/men-kong-xun-huan-dan-yuan/1.png" class=""><h2 id="隐状态"><a href="#隐状态" class="headerlink" title="隐状态"></a>隐状态</h2><p>隐状态$H_{t}\in R^{nxh}$通过更新门$Z_{t}$来确定它多大程度上来自与旧的状态$H_{t-1}$和当前候选状态$\overset{-}{H_{t}}$，它的具体公式为：</p><p>$$H_{t}=Z_{t}\bigodot H_{t-1}+(1-Z_{t})\bigodot \overset{-}{H_{t}}$$</p><p>每当更新门$Z_{t}$中所有项接近1时，模型就倾向于只保存旧状态。此时，来自$X_{t}$的信息基本上被忽略。相反，当$Z_{t}$中所有项接近0时，新的隐状态$H_{t}$就会接近候选隐状态$\overset{-}{H_{t}}$这些设计可以帮助我们处理循环神经⽹络中的梯度消失问题，并更好地捕获时间步距离很⻓的序列的依赖关系。 </p><p>此时GRU一个神经元一个完整的内部结构就可以用下图表示：</p><img src="/2022/03/25/men-kong-xun-huan-dan-yuan/2.png" class=""><p>用LSTM，我们最后将最新的隐状态作为输入进入另一个网络，则可实现分类或回归等模型。</p><h2 id="GRU网络代码"><a href="#GRU网络代码" class="headerlink" title="GRU网络代码"></a>GRU网络代码</h2><p>同LSTM我们可以调用pytorch里面的API实现一个简单的GRU网络</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">GRU_Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        embedding: 词典        embedding_dim: 词向量的维度        hidden_dim: GRU神经元个数        num_layers: GRU的层数        output_dim: 隐藏层输出的维度(分类的数量)        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU_Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 制作 embedding layer</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span>        <span class="token comment"># 如果 fix_embedding 为 False，在训练过程中，embedding 也会跟着被训练</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token keyword">if</span> fix_embedding <span class="token keyword">else</span> <span class="token boolean">True</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 句子最后时刻的hidden state</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用LSTM同样的例子，经过这个网络得出在验证集中准确率最高为0.9024，和LSTM模型的准确度差不多，但运行时间个人明显感觉短了很多。</p><h2 id="与LSTM间的异同"><a href="#与LSTM间的异同" class="headerlink" title="与LSTM间的异同"></a>与LSTM间的异同</h2><p>两者相似之处：引用了门结构，并在t-１时刻到ｔ时刻信息的传递引用了新的成分（候选隐状态，在LSTM中是记忆元），不再像传统RNN只利用了当前时刻的输入和上一时刻的隐状态。这个相同之处带来了两个好处：</p><p>①能够保存长期序列中的信息，且不会随时间而清除或因为与预测不相关而移除。</p><p>②有效创建了绕过多个时间步骤的快捷路径。这些捷径允许误差更容易反向传播，不至于像传统RNN那样迅速消散，从而解决了梯度消失的问题。</p><p>两者不同之处：</p><p>①对记忆内容传递程度的控制。LSTM用output gate控制传递程度，传递给下一个unit；而GRU是完全传递给下一个unit，不做任何控制。</p><p>②对候选内容的控制；LSTM计算候选记忆元不对上一信息做任何控制；而GRU计算候选隐状态时利用reset gate对上一时刻的信息进行控制。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1412.3555">Chung J, Gulcehre C, Cho K H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling[J]. arXiv preprint arXiv:1412.3555, 2014.</a></p><p>[2] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>长短期记忆网络</title>
      <link href="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/"/>
      <url>/2022/03/22/chang-duan-qi-ji-yi-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p><strong>长短期记忆神经网路</strong>（long short-term memory，LSTM）是一种RNN特殊类型，现在我们见到的RNN模型除了特别强调，一般都是LSTM。LSTM的设计灵感来源于计算机的逻辑门，它引入了记忆元（memory cell），记忆元的作用是用于记录附加的信息。为了控制记忆元，我们需要许多门。其中一个门用来从单元中输出条目，我们将其称为输出门（output gate）。另一个门用来决定何时将数据读入单元，我们将其称为输入门（input gate）。我们还需要一个门来决定什么时候记忆或忽略隐状态中的输入，我们将其称为遗忘门（forget gate）。除此之外还有一个候选记忆元（candidate memory cell），它用来控制输入门的状态。现在让我们看看这在实践中是怎么运作的。<br>LSTM当前时间步的输⼊和前⼀个时间步的隐状态作为数据送⼊⻓短期记忆⽹络的⻔中，它们由三个具有sigmiod激活函数的全连接层处理，以计算输入门、输出门和遗忘门的值。候选记忆元的结构与前面三个门相似，只是使用tanh函数来作为激活函数。</p><img src="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/1.png" class=""><p>现在我们来细化一下长短期记忆网络的数学表达。假设输入为$X_{t}\in R^{nxd}$，隐藏单元的个数是h，则前一时间步的隐状态为$H_{t-1}\in R^{nxh}$。相应地，输入门是$I_{t}\in R^{nxh}$，遗忘门是$F_{t}\in R^{nxh}$，输出们是$O_{t}\in R^{nxh}$，候选记忆元是$\overset{-}{C_{t}}\in R^{nxh}$。它们的计算方法如下：<br>$$I_{t}=\sigma(X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i}),$$<br>$$F_{t}=\sigma(X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f}),$$<br>$$O_{t}=\sigma(X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o}),$$<br>$$\overset{-}{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c}),$$<br>式中$W_{xi},W_{xf},W_{xo},W_{xc}\in R^{dxh}$和$W_{hi},W_{hf},W_{ho},W_{hc}\in R^{hxh}$是权重参数，$b_{i},b_{f},b_{o},b_{c}\in R^{1xh}$是偏置参数。<br>在LSTM中，有两个来控制输入或遗忘：输入门$I_{t}$控制采用多少来自$\overset{-}{C_{t}}$的新数据，而遗忘门$F_{t}$控制保留多少过去的记忆元$C_{t-1}\in R^{nxh}$的内容。它们之间使用Hadamard积，有：<br>$$C_{t}=F_{t}\bigodot C_{t-1}+I_{t}\bigodot \overset{-}{C_{t}}$$<br>如果遗忘⻔始终为1且输⼊⻔始终为0，则过去的记忆元$C_{t}$将随时间被保存并传递到当前时间步。引⼊这种设计是为了缓解梯度消失问题，并更好地捕获序列中的⻓距离依赖关系。<br>现在，我们还需要定义如何计算隐状态$H_{t}\in R_{nxh}$，这就是输出门发挥作用的地方。在LSTM中，它将记忆元经过tanh激活函数，并于输出之间做Hadamard积：<br>$$H_{t}=O_{t}\bigodot tanh(C_{t})$$<br>这样我们就得到LSTM一个神经元完整的内部结构：</p><img src="/2022/03/22/chang-duan-qi-ji-yi-wang-luo/2.png" class=""><p>最后只需将最新的隐状态作为输入经过另一个网络，则可实现分类或回归等模型。</p><p>这只是LSTM单个神经元的内部结构，而事实上LSTM可以将多层网络结构堆叠在一起，每层网络结构含有多个神经元结构。通过对几个层进行组合，我们就可以产生一个灵活的网络结构。</p><h2 id="LSTM应用"><a href="#LSTM应用" class="headerlink" title="LSTM应用"></a>LSTM应用</h2><p>现在我们以一个新闻标题分类的例子来实现LSTM，本次实验应用的是清华NLP组提供的THUCNews文本分类数据集，它包含十个新闻主题，分别是财经、房产、股票、教育、科技、社会、时政、体育、游戏。训练集中总共有180000条数据，每个类别有200000条数据。验证集中总共有10000条数据，每个类别有1000条数据。</p><h3 id="分词及去除停用词"><a href="#分词及去除停用词" class="headerlink" title="分词及去除停用词"></a>分词及去除停用词</h3><p>由于训练数据是中文，因此需要对文本进行分词处理，分词采用的是python中的jieba工具。同时为了减少停用词对文本有效信息造成噪音干扰，减少模型复杂程度，我们对文本进行去除停用词处理。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> jieba<span class="token keyword">import</span> os<span class="token keyword">import</span> re<span class="token comment"># 数据所在路径</span>data_dir <span class="token operator">=</span> <span class="token string">'E:\软件包\Chrome\机器学习数据\THUCNews'</span><span class="token comment"># 停用词表对应路径</span>stopwords_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'中文停用词库.txt'</span><span class="token punctuation">)</span><span class="token comment"># 将停用词转换为python列表</span>stopwords_list <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">open</span><span class="token punctuation">(</span>stopwords_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 定义一个函数，用于对文本分词和去除停用词处理</span><span class="token keyword">def</span> <span class="token function">text_preprocessing</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 去除文本额外信息</span>    text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'(图)'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>    <span class="token comment"># 只保留数字、字母、中文</span>    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[^a-zA-Z0-9\u3002\uff1b\uff0c\uff1a\u201c\u201d\uff08\uff09\u3001\uff1f\u300a\u300b\u4e00-\u9fa5]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>    <span class="token comment"># 分词</span>    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    text_list <span class="token operator">=</span> <span class="token punctuation">[</span>word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> words <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords_list <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> text_list<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 把 training 时需要的资料读进来</span>    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>    lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>    lines <span class="token operator">=</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    x <span class="token operator">=</span> <span class="token punctuation">[</span>text_preprocessing<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding</h3><p>这里采用的时gensim中word2vec的skip-gram，相关使用请看<a href="https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Text8Corpus">官网</a>，关于Gensim 4.0的相关更新请看<a href="https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4">这里</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec<span class="token keyword">def</span> <span class="token function">train_word2vec</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 训练 word to vector 的 word embedding</span>    model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>x<span class="token punctuation">,</span> vector_size<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> sg<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading training data ..."</span><span class="token punctuation">)</span>    train_x<span class="token punctuation">,</span> train_y <span class="token operator">=</span> load_data<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'train.txt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading testing data ..."</span><span class="token punctuation">)</span>    test_x<span class="token punctuation">,</span> test_y <span class="token operator">=</span> load_data<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">'test.txt'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># model</span>    model <span class="token operator">=</span> train_word2vec<span class="token punctuation">(</span>train_x <span class="token operator">+</span> test_x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"saving model ..."</span><span class="token punctuation">)</span>    save_path <span class="token operator">=</span> <span class="token string">'./logs/w2v.model'</span>    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>loading training data ...loading testing data ...saving model ...</code></pre><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">Preprocess</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentences<span class="token punctuation">,</span> sen_len<span class="token punctuation">,</span> w2v_path<span class="token operator">=</span><span class="token string">'w2v.model'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>w2v_path <span class="token operator">=</span> w2v_path        self<span class="token punctuation">.</span>sentences <span class="token operator">=</span> sentences        self<span class="token punctuation">.</span>sen_len <span class="token operator">=</span> sen_len        self<span class="token punctuation">.</span>idx2word <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>word2idx <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">get_w2v_model</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把之前训练好的 word to vector 模型读进来</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w2v_path<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>vector_size            <span class="token keyword">def</span> <span class="token function">add_embedding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把 word 加进 embedding，并赋予它一个随机生成的具有代表性的 vector</span>        <span class="token comment"># word 只会是 "&lt;PAD&gt;" 或 "&lt;UNK&gt;"</span>        vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>embedding_dim<span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>vector<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">,</span> vector<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">make_embedding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> load<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Get embedding ..."</span><span class="token punctuation">)</span>        <span class="token comment"># 取出训练好的 Word2vec word embedding</span>        <span class="token keyword">if</span> load<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading word to vec model ..."</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>get_w2v_model<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> NotImplementedError                <span class="token comment"># 制作一个 word2idx 的 dictionary</span>        <span class="token comment"># 制作一个 idx2word 的 list</span>        <span class="token comment"># 制作一个 word2vector 的 list</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>key_to_index<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>get_vector<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">)</span>        <span class="token comment"># 将 "&lt;PAD&gt;" 跟 "&lt;UNK&gt;" 加进 embedding 里面</span>        self<span class="token punctuation">.</span>add_embedding<span class="token punctuation">(</span><span class="token string">"&lt;PAD&gt;"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_embedding<span class="token punctuation">(</span><span class="token string">"&lt;UNK&gt;"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"total words: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_matrix<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>embedding_matrix        <span class="token keyword">def</span> <span class="token function">pad_sequence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 将每个句子变成一样的长度</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>sen_len<span class="token punctuation">:</span>            sentence <span class="token operator">=</span> sentence<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>sen_len<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            pad_len <span class="token operator">=</span> self<span class="token punctuation">.</span>sen_len <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pad_len<span class="token punctuation">)</span><span class="token punctuation">:</span>                sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span><span class="token string">"&lt;PAD&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>sen_len        <span class="token keyword">return</span> sentence        <span class="token keyword">def</span> <span class="token function">sentence_word2idx</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 把句子里面的字转成对应的 index</span>        sentence_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> sen <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sentences<span class="token punctuation">)</span><span class="token punctuation">:</span>            sentence_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> word <span class="token keyword">in</span> sen<span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>word <span class="token keyword">in</span> self<span class="token punctuation">.</span>idx2word<span class="token punctuation">)</span><span class="token punctuation">:</span>                    sentence_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    sentence_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span><span class="token string">"&lt;UNK&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token comment"># 将每个句子变成一样的长度</span>            sentence_idx <span class="token operator">=</span> self<span class="token punctuation">.</span>pad_sequence<span class="token punctuation">(</span>sentence_idx<span class="token punctuation">)</span>            sentence_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence_idx<span class="token punctuation">)</span>        <span class="token keyword">return</span> sentence_list<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">class</span> <span class="token class-name">LSTM_Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        embedding: 词典        embedding_dim: 词向量的维度        hidden_dim: GRU神经元个数        num_layers: GRU的层数        output_dim: 隐藏层输出的维度(分类的数量)        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM_Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 制作 embedding layer</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span>        <span class="token comment"># 如果 fix_embedding 为 False，在训练过程中，embedding 也会跟着被训练</span>        self<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token keyword">if</span> fix_embedding <span class="token keyword">else</span> <span class="token boolean">True</span>        self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 句子最后时刻的hidden state</span>        <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>制作dataset以便dataloader能够使用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">class</span> <span class="token class-name">NewsTitleDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>在定义dataloder前我们先定义一些模型超参数，该参数可以自行调节</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sen_len <span class="token operator">=</span> <span class="token number">12</span>batch_size <span class="token operator">=</span> <span class="token number">128</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">0.001</span>train_preprocess <span class="token operator">=</span> Preprocess<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> sen_len<span class="token punctuation">,</span> w2v_path<span class="token operator">=</span>save_path<span class="token punctuation">)</span>embedding <span class="token operator">=</span> train_preprocess<span class="token punctuation">.</span>make_embedding<span class="token punctuation">(</span>load<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_x <span class="token operator">=</span> train_preprocess<span class="token punctuation">.</span>sentence_word2idx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 将 data 划分为 training data 和 validation data</span>X_train<span class="token punctuation">,</span> X_val<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_val <span class="token operator">=</span> train_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">180000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_x<span class="token punctuation">[</span><span class="token number">180000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">180000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train_y<span class="token punctuation">[</span><span class="token number">180000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 将 data 做成 dataset 供 dataloader 使用</span>train_dataset <span class="token operator">=</span> NewsTitleDataset<span class="token punctuation">(</span>X<span class="token operator">=</span>X_train<span class="token punctuation">,</span> y<span class="token operator">=</span>y_train<span class="token punctuation">)</span>val_dataset <span class="token operator">=</span> NewsTitleDataset<span class="token punctuation">(</span>X<span class="token operator">=</span>X_val<span class="token punctuation">,</span> y<span class="token operator">=</span>y_val<span class="token punctuation">)</span><span class="token comment"># 将 data 转成 batch of tensor</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Get embedding ...loading word to vec model ...total words: 30360</code></pre><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 加载模型</span>model <span class="token operator">=</span> LSTM_Net<span class="token punctuation">(</span>embedding<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> fix_embedding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># optimizer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment"># Training</span>best_acc <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    epoch_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    val_acc<span class="token punctuation">,</span> val_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 训练模式</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 前向传播</span>        train_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 后向传播</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>train_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>           model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 评估模型</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>val_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            val_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>val_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                        val_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>val_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            val_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 展示结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>epoch_start_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> sec(s) Train Acc: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span>train_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span>train_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string"> | Val Acc: </span><span class="token interpolation"><span class="token punctuation">{</span>val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>val_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>        best_acc <span class="token operator">=</span> val_acc <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_val<span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'./logs/lstm_cl.model'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'saving model with acc </span><span class="token interpolation"><span class="token punctuation">{</span>best_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Epoch [1/10] 12.5952 sec(s) Train Acc: 0.8458 Loss: 0.003683 | Val Acc: 0.8786 Loss: 0.003035saving model with acc 0.8786Epoch [2/10] 12.6020 sec(s) Train Acc: 0.8907 Loss: 0.002629 | Val Acc: 0.8906 Loss: 0.002654saving model with acc 0.8906Epoch [3/10] 12.5632 sec(s) Train Acc: 0.8991 Loss: 0.002396 | Val Acc: 0.8902 Loss: 0.002658Epoch [4/10] 12.5930 sec(s) Train Acc: 0.9050 Loss: 0.002251 | Val Acc: 0.8951 Loss: 0.002480saving model with acc 0.8951Epoch [5/10] 12.5931 sec(s) Train Acc: 0.9102 Loss: 0.002110 | Val Acc: 0.8978 Loss: 0.002456saving model with acc 0.8978Epoch [6/10] 12.7861 sec(s) Train Acc: 0.9154 Loss: 0.001967 | Val Acc: 0.8989 Loss: 0.002452saving model with acc 0.8989Epoch [7/10] 12.8262 sec(s) Train Acc: 0.9212 Loss: 0.001838 | Val Acc: 0.9004 Loss: 0.002465saving model with acc 0.9004Epoch [8/10] 12.7670 sec(s) Train Acc: 0.9252 Loss: 0.001716 | Val Acc: 0.9012 Loss: 0.002431saving model with acc 0.9012Epoch [9/10] 14.5936 sec(s) Train Acc: 0.9303 Loss: 0.001590 | Val Acc: 0.9006 Loss: 0.002502Epoch [10/10] 19.8384 sec(s) Train Acc: 0.9358 Loss: 0.001462 | Val Acc: 0.9018 Loss: 0.002567saving model with acc 0.9018</code></pre><p>经过10次迭代后，模型在验证集中的准确度达到0.9018，说明模型还不错，大家可以尝试改动模型参数，看看预测准确度会不会进一步提高。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LSTM </tag>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>序列模型</title>
      <link href="/2022/03/20/xu-lie-mo-xing/"/>
      <url>/2022/03/20/xu-lie-mo-xing/</url>
      
        <content type="html"><![CDATA[<p>假设某个序列我们可以使用$x_{t-1},…,x_{t-\tau}$而不是$x_{t-1},…,x_{1}$来估计$x_{t}$，我们就说该序列满足马尔可夫条件。用数学公式表示为：<br>$$P(x_{1},…,x_{T})=\underset{t=1}{\overset{T}{\Pi}}P(x_{t}|x_{t-1},…,x_{t-\tau})$$<br>而$\tau=1$，我们就得到一个一阶马尔可夫模型，则上式变为：<br>$$P(x_{1},…,x_{T})=\underset{t=1}{\overset{T}{\Pi}}P(x_{t}|x_{t-1})$$<br>利用这一事实，我们只需要考虑过去观察中的一个非常短的历史：$P(x_{t}|x_{t-1},…,x_{1})=P(x_{t}|x_{t-1})$就能近似得出当前状态。</p><p>现在我们做一个简单的实验，来探讨一下满足马尔可夫条件的模型预测的准确性，以及它的最大预测能力。</p><h2 id="生成数据"><a href="#生成数据" class="headerlink" title="生成数据"></a>生成数据</h2><p>首先，我们生成一些数据：使用正弦函数和一些可加性噪声来生成序列模型，时间步长为1000。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchT <span class="token operator">=</span> <span class="token number">1000</span>    <span class="token comment"># 总共产生1000个点</span>time_epoch <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> T <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token number">0.01</span> <span class="token operator">*</span> time_epoch<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>T<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>绘制图片</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_3_1.png" class=""><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>接下来我们对序列进行一定的处理，使这个序列转换为模型的“特征-标签”对，这里我们使用的$\tau=4$，由于前4个数据没有历史数据来描述它们，因此我们将其舍去。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset<span class="token keyword">class</span> <span class="token class-name">DigitDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y    tau <span class="token operator">=</span> <span class="token number">4</span>features <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>T <span class="token operator">-</span> tau<span class="token punctuation">,</span> tau<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span>i<span class="token punctuation">:</span> T <span class="token operator">-</span> tau <span class="token operator">+</span> i<span class="token punctuation">]</span>labels <span class="token operator">=</span> y<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># print(features.shape, labels.shape)</span>batch_size<span class="token punctuation">,</span> n_train <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">600</span>          <span class="token comment"># 仅使用前600个数据进行模型训练</span>train_set <span class="token operator">=</span> DigitDataset<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train<span class="token punctuation">]</span><span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><p>在这里我们构建一个十分简单的网络来训练模型：一个拥有两个全连接层的多层感知机，ReLU激活函数，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token comment"># 初始化网络权重参数</span><span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>设置超参数以及optimizer， criterion，并进行训练</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型</span>model <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>n_epoch <span class="token operator">=</span> <span class="token number">10</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token comment"># optimizer</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment"># criterion</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Training</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 前向传播</span>        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment"># 后向传播</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                total_loss <span class="token operator">+=</span> loss <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token comment"># 结果展示</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>n_epoch<span class="token punctuation">:</span><span class="token format-spec">02d</span><span class="token punctuation">}</span></span><span class="token string">] Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>total_loss <span class="token operator">/</span> n_train<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Epoch [1/10] Loss: 0.054475486278533936Epoch [2/10] Loss: 0.015365694649517536Epoch [3/10] Loss: 0.011502934619784355Epoch [4/10] Loss: 0.006994950119405985Epoch [5/10] Loss: 0.007959885522723198Epoch [6/10] Loss: 0.008115933276712894Epoch [7/10] Loss: 0.009392841719090939Epoch [8/10] Loss: 0.008084502071142197Epoch [9/10] Loss: 0.0074587250128388405Epoch [10/10] Loss: 0.006592489313334227</code></pre><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>由训练误差可知，模型运行的效果不错，现在让我们检验模型的预测能力，首先检验模型预测下一个时间步的能力</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">onestep_preds <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> onestep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">'r'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'1-step preds'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_11_1.png" class=""><p>由图可以看出。单步预测效果不错。即使预测的时间步超过了600+4（n_train + tau)，其预测结果看起来仍然不错。但如果数据观察序列只到了604，后面的都需要我们进行预测，那么这个模型的结果将会成为什么样子？还会有这么好的预测效果吗？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">multistep_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>T<span class="token punctuation">)</span>multistep_preds<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train <span class="token operator">+</span> tau<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token punctuation">:</span> n_train <span class="token operator">+</span> tau<span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_train <span class="token operator">+</span> tau<span class="token punctuation">,</span> T<span class="token punctuation">)</span><span class="token punctuation">:</span>    multistep_preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">(</span>multistep_preds<span class="token punctuation">[</span>i <span class="token operator">-</span> tau<span class="token punctuation">:</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># 绘图</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> onestep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">,</span> multistep_preds<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'1-step preds'</span><span class="token punctuation">,</span> <span class="token string">'multistep preds'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_13_1.png" class=""><p>由图可以看出绿线的预测显然不是很理想，经过几个预测步骤之后，预测的结果很快就会衰减到一个常数。这其实是错误累积的结果，因此后面误差会相当快地偏离真实的观测结果。<br>现在我们将预测步数分别设置为1，4，16，64，通过对比比较，看看k步预测的困难。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">max_steps <span class="token operator">=</span> <span class="token number">64</span>features <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>T <span class="token operator">-</span> tau <span class="token operator">-</span> max_steps <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> tau <span class="token operator">+</span> max_steps<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 列i（i&lt;tau）是来⾃x的观测，其时间步从（i+1）到（i+T-tau-max_steps+1）</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> y<span class="token punctuation">[</span>i <span class="token punctuation">:</span> T <span class="token operator">-</span> tau <span class="token operator">-</span>max_steps <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> i<span class="token punctuation">]</span><span class="token comment"># 列i（i&gt;=tau）是来⾃（i-tau+1）步的预测，其时间步从（i+1）到（i+T-tau-max_steps+1）</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tau<span class="token punctuation">,</span> tau <span class="token operator">+</span> max_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>    features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i <span class="token operator">-</span> tau<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>steps <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token comment"># 绘图</span><span class="token keyword">for</span> i <span class="token keyword">in</span> steps<span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>time_epoch<span class="token punctuation">[</span>tau <span class="token operator">+</span> i <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span> T <span class="token operator">-</span> max_steps <span class="token operator">+</span> i<span class="token punctuation">]</span> <span class="token punctuation">,</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> tau <span class="token operator">+</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'time_epoch'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">-step preds'</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> steps<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="/2022/03/20/xu-lie-mo-xing/output_15_1.png" class=""><p>以上例子清楚地说明随着预测步数的增加，预测的结果逐渐变坏。虽然“4步预测”看起来仍然不错，但超过这个跨度的任何预测几乎都是无用的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 序列模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据操作</title>
      <link href="/2022/03/18/shu-ju-cao-zuo/"/>
      <url>/2022/03/18/shu-ju-cao-zuo/</url>
      
        <content type="html"><![CDATA[<p>首先，我们介绍n维数组，也称为张量（tensor）。在python中数组通过调用Numpy计算包实现，但在pyTorch中为Tensor。虽然这两者相似，但Tensor比Numpy多一些重要的功能：①GPU算力比CPU高，而Numpy仅支持CPU计算；②Tensor类支持自动微分，更适合深度学习。</p><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><p>这节主要介绍一个基本数值计算工具torch的一些操作，首先我们导入torch，并使用arange创建一个行向量。这个⾏向量包含以0开始的前12个整数，它们默认创建为整数。张量中的每个值都称为张量的 元素（element）。例如，张量 x 中有 12 个元素。除⾮额外指定，新的张量将存储在内存中，并采⽤基于CPU的计算。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</code></pre><p>可以通过张量的shape属性来访问张量的形状。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>torch.Size([12])</code></pre><p>下面通过numel()函数获取张量中元素的数量</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>12</code></pre><p>在一些场景中，我们需要改变一个张量的形状而不改变元素数量和元素值，这可以通过reshape()函数实现。例如，可以把张量x从形状为(12,)的行向量转换为形状为(3,4)的矩阵。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11]])</code></pre><p>如果在改变张量形状前，我们知道目标矩阵的行数或列数，那么可以通过-1来调用reshape()函数自动计算出维度的功能。即我们可以⽤x.reshape(-1,4)或x.reshape(3,-1)来取x.reshape(3,4)。</p><p>有时，我们希望使⽤全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。我们可以创建⼀个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],        [[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]]])</code></pre><p>同样，我们可以创建⼀个形状为(2,3,4)的张量，其中所有元素都设置为1。代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]],        [[1., 1., 1., 1.],         [1., 1., 1., 1.],         [1., 1., 1., 1.]]])</code></pre><p>有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值，可以通过randn()函数实现。如以下代码创建⼀个形状为（3,4）的张量，其中的每个元素都从均值为0、标准差为1的标准正态分布中随机采样。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[ 1.1445,  0.5344,  1.7990,  0.1128],        [-0.5328,  0.4657,  0.7276,  0.2435],        [ 0.0553,  0.2340,  0.8917, -0.5017]])</code></pre><p>我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[2, 1, 4, 3],        [1, 2, 3, 4],        [4, 3, 2, 1]])</code></pre><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><p>常⻅的标准算术运算符（+、 -、 *、 /和**），该运算符用于任意具有相同形状的张量间的计算。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x <span class="token operator">+</span> y<span class="token punctuation">,</span> x <span class="token operator">-</span> y<span class="token punctuation">,</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> x <span class="token operator">/</span> y<span class="token punctuation">,</span> x <span class="token operator">**</span> y <span class="token comment"># **运算符是求幂运算</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([ 3.,  4.,  6., 10.]), tensor([-1.,  0.,  2.,  6.]), tensor([ 2.,  4.,  8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1.,  4., 16., 64.]))</code></pre><p>“按元素”⽅式可以应⽤更多的计算，包括像求幂这样的⼀元运算符torch.exp(x)，求正弦值torch.sin(x)等等。</p><p>除按元素计算外，还可以执行线性代数运算，包括向量点积和矩阵乘法。我们也可以把多个张量连接（concatenate）在一起形成一个更大的张量。我们只需要提供张量列表，并给出沿哪个轴连接（沿行轴用dim=0，沿列轴用dim=1），这里需要注意张量的形状。下面我们用代码实现张量连接操作：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[ 0.,  1.,  2.,  3.],         [ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.],         [ 2.,  1.,  4.,  3.],         [ 1.,  2.,  3.,  4.],         [ 4.,  3.,  2.,  1.]]), tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</code></pre><p>通过sum()函数对张量中的所有元素进⾏求和，会产⽣⼀个单元素张量。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor(66.)</code></pre><h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p>在上⾯的部分中，我们看到了如何在相同形状的两个张量上执⾏按元素操作。在某些情况下，即使形状不同，我们仍然可以通过调⽤ ⼴播机制（broadcasting mechanism）来执⾏按元素操作。这种机制的⼯作⽅式如下：⾸先，通过适当复制元素来扩展⼀个或两个数组，以便在转换之后，两个张量具有相同的形状。其次，对⽣成的数组执⾏按元素操作。如下：a和b分别是3 × 1和1 × 2矩阵，如果让它们相加，它们的形状不匹配。我们将两个矩阵⼴播为⼀个更⼤的3 × 2矩阵，矩阵a将复制列，矩阵b将复制⾏，然后再按元素相加。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>a<span class="token punctuation">,</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(tensor([[0],         [1],         [2]]), tensor([[0, 1]]))</code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">+</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>tensor([[0, 1],        [1, 2],        [2, 3]])</code></pre><h2 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h2><p>就像python数组一样，张量中的元素可以通过索引访问。与python数组一样，张量中第一个元素的索引是0，最后一个元素的索引是-1。<br>如下所⽰，我们可以⽤[-1]选择最后⼀个元素，可以⽤[1:3]选择第⼆个和第三个元素（对于矩阵是默认对行进行操作）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor([ 8.,  9., 10., 11.]), tensor([[ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.]]))</code></pre><p>如果你想实现矩阵中列的索引，可以通过X[:, a:b]实现，同样对行索引可以通过X[a:b, :]实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>(tensor([[ 1.,  2.],         [ 5.,  6.],         [ 9., 10.]]), tensor([[ 4.,  5.,  6.,  7.],         [ 8.,  9., 10., 11.]]))</code></pre><p>除读取外，我们还可以通过指定索引来将元素写入矩阵</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">9</span>X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>tensor([[ 0.,  1.,  2.,  3.],        [ 4.,  5.,  9.,  7.],        [ 8.,  9., 10., 11.]])</code></pre><h2 id="转换为其他python对象"><a href="#转换为其他python对象" class="headerlink" title="转换为其他python对象"></a>转换为其他python对象</h2><p>将深度学习框架定义的张量转换为Numpy很容易，反之也同样容易。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> X<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>B <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token builtin">type</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>(numpy.ndarray, torch.Tensor)</code></pre><p>要将⼤小为1的张量转换为Python标量，我们可以调⽤item函数或Python的内置函数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>a<span class="token punctuation">,</span> a<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>(tensor([3.5000]), 3.5, 3.5, 3)</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://d2l.ai/">Dive into Deep Learning</a></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo插入图片</title>
      <link href="/2022/03/17/hexo-cha-ru-tu-pian/"/>
      <url>/2022/03/17/hexo-cha-ru-tu-pian/</url>
      
        <content type="html"><![CDATA[<h2 id="typora设置"><a href="#typora设置" class="headerlink" title="typora设置"></a>typora设置</h2><p>打开typora，选择：文件 - 偏好设置 - 图像 - 插入图片，做如下更改：</p><img src="/2022/03/17/hexo-cha-ru-tu-pian/image-20220331152841489.png" class=""><p>该设置会使得当你插入图片时，会生成一个和文件名相同的文件夹，并将图片存入这个文件夹内。</p><h2 id="Hexo设置"><a href="#Hexo设置" class="headerlink" title="Hexo设置"></a>Hexo设置</h2><ul><li>更换插件</li></ul><p>用插件 <code>Hexo-renderer-markdown-it</code> （推荐）代替 <code>Hexo-renderer-marked</code>，执行以下代码：</p><pre class="line-numbers language-none"><code class="language-none">npm uninstall hexo-renderer-marker --save  #卸载 markednpm install hexo-renderer-markdown-it --save  #安装markdown-it<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>更改根目录下的_config.yml 配置</li></ul><pre class="line-numbers language-none"><code class="language-none">post_asset_folder: true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>安装插件<code>hexo-image-link</code></li></ul><pre class="line-numbers language-none"><code class="language-none">npm install hexo-image-link --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该插件可以实现路径转换，假设：</p><p>文件名: <code>./test.md</code></p><p>图片路径: <code>./test/test.jpg</code></p><p>当插入图片 test.jpg 到 test.md 中时，typora 的引用路径为：</p><pre class="line-numbers language-none"><code class="language-none">![](test/test.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>而在Hexo发布后的引用路径为：</p><pre class="line-numbers language-none"><code class="language-none">![](test.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此，typora的md文件引入hexo时，应转换路径，即删掉图片路径中的 <code>"test/"</code>部分。若在md文件做上述操作，则md文件不能正常显示图片，而</p><p>hexo部署后可正常显示。为了书写方便，引入插件<code>hexo-image-link</code>即可帮助实现了这种路径转换。实现typora 文件中正常显示的图片，在hexo发布后依旧能正常显示。</p>]]></content>
      
      
      <categories>
          
          <category> 生命在于折腾 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生成式对抗网络</title>
      <link href="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/"/>
      <url>/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>GAN的全称为Generative Adversarial Network，翻译成中文就是生成式对抗网络。 在github有个<a href="https://github.com/hindupuravinash/the-gan-zoo">GAN Zoo</a>，它记录了GAN的发展并提供了相关GAN的论文来源和部分GAN模型的实现。下图为GAN的论文数量随时间的变化，由图可以看出自2014年第一篇GAN的论文问世，GAN的数量就以指数增长形式迅速壮大。虽然GAN的种类千变万化，但它们的结构类似，都含有一个生成器（generator）和一个判别器（discriminator）。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313134629440.jpg" class=""><p>判别器和生成器都是一个神经网络结构，也就是一个黑箱模型。判别器相对比较好理解，就像一个二分类模型，有一个判别界限去区分样本，从概率的角度分析就是获得样本x属于类别y的概率，是一个条件概率P(y|x)。而生成器是需要生成数据的概率分布，就像高斯分布一样，需要去拟合整个分布，从概率角度分析就是样本x在整个分布中对应的概率。</p><h2 id="GAN的相关理论"><a href="#GAN的相关理论" class="headerlink" title="GAN的相关理论"></a>GAN的相关理论</h2><p>GAN本质上是在做什么事情呢？</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313134650100.png" class=""><p>以图像生成为例，我们假设吧每一个图片看作二维空间中的一个点，并且现有图片会满足于某个数据分布，我们记作$P_{data}(x)$。那么在这个图像分布空间中，实际上只有很小一部分的区域是人脸图像。如上图所示，只有在蓝色区域采样出的点才会看起来像人脸，而在蓝色区域外采样出来的点就不是人脸。而在GAN中我们需要做的就是让机器找到人脸的分布函数，这也是GAN本质上做的事情。</p><h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p>如下图所示，我们需要训练出这样一个生成器，对于一个已知分布的数据z，我们可以通过生成器把数据转化成一个高维向量，它可以表示为一个图片、文本、声音等。只要我们随机输入多个z，就可以生成一个关于数据x的分布，我们把它称作$P_{G}(x)$。而真实数据也对应一个分布$P_{data}(x)$，生成器的目标是使$P_{G}(x)$和$P_{data}(x)$这两个分布越相似越好。我们知道对于回归和分类模型，都有对应的目标函数，我们只需使这个目标函数达到最优，即可得出一个比较好的回归或分类模型。那么对于两个分布，我们可以利用散度（Divergence，简称Div）这个评价指标来衡量两个分布之间的相似性。Div越小就表示两个分布越相似。那么我们可以将Div作为训练G的目标函数，我们的目标是使Div最小。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135023130.png" class=""><h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>现在有一个最关键的问题是，两个分布之间的Div要如何计算出来呢？理论上来说我们不知道$P_{G}(x)$和$P_{data}(x)$是什么，因此Div我们是无法计算的。因此我们需要构建一个新的网络，它的作用是衡量$P_{G}(x)$和$P_{data}(x)$之间的Div，因此我们有了这样一个网络——判别器。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135053706.png" class=""><p>图中，蓝色星星是从$P_{data}$（真实数据）中采样出的数据，黄色星星是从$P_{G}$（生成的数据）中采样出的数据，现在我们将这两组数据交给判别器，判别器的功能是判别读入的数据是来自$P_{data}$还是$P_{G}$。如果输入数据是$P_{data}$，那么经过判别器后就输出一个较大的值（可以近似理解为输出1）。如果输入数据是$P_{G}$，那么经过判别器后就输出一个较小的值（可以近似理解为输出0）。熟悉分类模型的同学可能就会说判别器不就相当于是一个二分类模型吗？而前面不是说我们是以Div的大小来判断两个分布之间的相似程度。现在我们就用公式推导出Div和二分类模型的目标函数之间的相关性。<br>我们先来看一下判别器的目标函数：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135121210.png" class=""><p>从式子本身理解的话，数据来源于$P_{data}$，D(x)要尽可能大，数据来源于$P_{G}$，D(x)要尽可能小。这样的话$V(G,D)$就越大。以最大化$V(G,D)$为目标函数，就可以使得输入数据是$P_{G}$，经过判别器后就输出一个较小的值，相反则输入一个较大的值。这样就达到了区分读入的数据是来自$P_{data}$还是$P_{G}$的目的。接下来我们将目标函数展开：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135206860.png" class=""><p>假设判别器十分强大，它模拟出的D(x)可以表示任何函数，给定一个x，都有一个D(x)使得表达式$P_{data}(x)logD(x)+P_{G}(x)log(1-D(x))$最大，求导令其为0可以得出：<br>$$D^{<em>}(x)=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}$$<br>现在把$D^{</em>}(x)$带入到目标函数中得到：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135318679.png" class=""><p>将表达式中分子分母都除于2可得：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135338407.png" class=""><p>这个表达式等价为：</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135404583.png" class=""><p>至此我们可以得知通过一定的假设，得出散度的计算类似于二分类器的目标函数的计算。因此可以看出判别器的本质就是一个二分类器，这样就有利于我们后面代码的实现。<br>现在我们再回到生成器，生成器的目的是让生成数据$P_{G}$和真实数据$P_{data}$之间的Div最小，本来Div是没办法计算的，但是现在有了判别器之后，Div变得可以计算了，于是生成器新的目标函数变为：<br> $$G^{*}=arg\underset{G}{min}\underset{D}{V(G,D)}$$<br>至此，GAN就变成了一个求解最小最大值的问题，接下来就可以用最基本的梯度下降法求解这个问题。<br>下面我们用一个完整的伪算法来回顾一下GAN模型训练的整个流程。</p><img src="/2022/03/16/sheng-cheng-shi-dui-kang-wang-luo/image-20220313135516142.png" class=""><p>这段伪代码的意思是，首先我们初始化生成器和判别器的参数，接下来规定一个总迭代次数，每轮训练的迭代次数也确定（这个根据数据量大小确定，一般是3-5次为一轮），在每轮训练中，我们先训练判别器，先从真实数据分布$P_{data}(x)$中抽样x，然后从先验分布中抽样z，并通过生成器产生数据$\overset{-}{x}$，接着把x和$\overset{-}{x}$丢入判别器中训练，使得目标函数$\overset{-}{V}$最大；接下来我们训练生成器，从先验分布中抽样新的z，接下来把z丢进生成器中训练，使得目标函数$\overset{-}{V}$最小，其实这一步就是让这一轮训练好的判别器认为生成器生成的是真实的数据。这样循环交替，最终生成器产生的数据$\overset{-}{x}$就会越来越接近真实数据x。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="https://arxiv.org/abs/1406.2661">Goodfellow, Ian, et al. “Generative adversarial nets.”Advances in neural information processing systems27 (2014).</a></p><p>[2] <a href="https://www.youtube.com/watch?v=DMA4MrNieWo">李宏毅youtube课程</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
